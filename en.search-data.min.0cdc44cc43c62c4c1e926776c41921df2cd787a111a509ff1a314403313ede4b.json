[{"id":0,"href":"/auditoria/","title":"Auditoria Governamental","section":"Estudo para Concursos","content":"Selecione um tópico de Auditoria Governamental para estudar.\n"},{"id":1,"href":"/infra/","title":"Infraestrutura de TI","section":"Estudo para Concursos","content":"Selecione um tópico de Infraestrutura de TI para estudar.\n"},{"id":2,"href":"/dados/","title":"Engenharia de Dados","section":"Estudo para Concursos","content":"Selecione um tópico de Engenharia de Dados para estudar.\n"},{"id":3,"href":"/software/","title":"Engenharia de Software","section":"Estudo para Concursos","content":"Selecione um tópico de Engenharia de Software para estudar.\n"},{"id":4,"href":"/seguranca/","title":"Segurança da Informação","section":"Estudo para Concursos","content":"Selecione um tópico de Segurança da Informação para estudar.\n"},{"id":5,"href":"/cloud/","title":"Computação em Nuvem","section":"Estudo para Concursos","content":"Selecione um tópico de Computação em Nuvem para estudar.\n"},{"id":6,"href":"/ia/","title":"Inteligência Artificial","section":"Estudo para Concursos","content":"Selecione um tópico de Inteligência Artificial para estudar.\n"},{"id":7,"href":"/contratacoes/","title":"Contratações de TI","section":"Estudo para Concursos","content":"Selecione um tópico de Contratações de TI para estudar.\n"},{"id":8,"href":"/gestao_ti/","title":"Gestão de Tecnologia da Informação","section":"Estudo para Concursos","content":"Selecione um tópico de Gestão de Tecnologia da Informação para estudar.\n"},{"id":9,"href":"/gestao_ti/3-metodologias-ageis/","title":"3. Metodologias ágeis","section":"Gestão de Tecnologia da Informação","content":"Erro ao gerar conteúdo.\n"},{"id":10,"href":"/gestao_ti/2-governanca-de-ti-cobit-5-/","title":"2. Governança de TI (COBIT 5)","section":"Gestão de Tecnologia da Informação","content":"Erro ao gerar conteúdo.\n"},{"id":11,"href":"/gestao_ti/1-gerenciamento-de-servicos-itil-v4-/","title":"1. Gerenciamento de serviços (ITIL v4)","section":"Gestão de Tecnologia da Informação","content":"Erro ao gerar conteúdo.\n"},{"id":12,"href":"/contratacoes/6-legislacao-e-normativos/","title":"6. Legislação e Normativos","section":"Contratações de TI","content":"Erro ao gerar conteúdo.\n"},{"id":13,"href":"/contratacoes/5-aspectos-tecnicos-e-estrategicos/","title":"5. Aspectos Técnicos e Estratégicos","section":"Contratações de TI","content":"Erro ao gerar conteúdo.\n"},{"id":14,"href":"/contratacoes/4-riscos-e-controles/","title":"4. Riscos e Controles","section":"Contratações de TI","content":"Erro ao gerar conteúdo.\n"},{"id":15,"href":"/contratacoes/3-governanca-e-fiscalizacao/","title":"3. Governança e Fiscalização","section":"Contratações de TI","content":"Erro ao gerar conteúdo.\n"},{"id":16,"href":"/contratacoes/2-tipos-de-solucoes-e-modelos/","title":"2. Tipos de Soluções e Modelos","section":"Contratações de TI","content":"Erro ao gerar conteúdo.\n"},{"id":17,"href":"/contratacoes/1-etapas-da-contratacao/","title":"1. Etapas da Contratação","section":"Contratações de TI","content":"Erro ao gerar conteúdo.\n"},{"id":18,"href":"/ia/6-etica-transparencia-e-responsabilidade/","title":"6. Ética, Transparência e Responsabilidade","section":"Inteligência Artificial","content":"Erro ao gerar conteúdo.\n"},{"id":19,"href":"/ia/5-arquitetura-e-engenharia-de-sistemas-de-ia/","title":"5. Arquitetura e engenharia de sistemas de IA","section":"Inteligência Artificial","content":"Erro ao gerar conteúdo.\n"},{"id":20,"href":"/ia/4-inteligencia-artificial-generativa/","title":"4. Inteligência Artificial Generativa","section":"Inteligência Artificial","content":"Erro ao gerar conteúdo.\n"},{"id":21,"href":"/ia/3-processamento-de-linguagem-natural-pln-/","title":"3. Processamento de linguagem natural (PLN)","section":"Inteligência Artificial","content":"Erro ao gerar conteúdo.\n"},{"id":22,"href":"/ia/2-redes-neurais-e-deep-learning/","title":"2. Redes Neurais e Deep Learning","section":"Inteligência Artificial","content":"Erro ao gerar conteúdo.\n"},{"id":23,"href":"/ia/1-aprendizado-de-maquina/","title":"1. Aprendizado de Máquina","section":"Inteligência Artificial","content":"Erro ao gerar conteúdo.\n"},{"id":24,"href":"/cloud/10-normas-governamentais/","title":"10. Normas governamentais","section":"Computação em Nuvem","content":"Erro ao gerar conteúdo.\n"},{"id":25,"href":"/cloud/9-multicloud/","title":"9. Multicloud","section":"Computação em Nuvem","content":"Erro ao gerar conteúdo.\n"},{"id":26,"href":"/cloud/8-migracao-e-modernizacao/","title":"8. Migração e Modernização","section":"Computação em Nuvem","content":"Erro ao gerar conteúdo.\n"},{"id":27,"href":"/cloud/7-armazenamento-e-processamento/","title":"7. Armazenamento e Processamento","section":"Computação em Nuvem","content":"7. Armazenamento e Processamento# 1. Especificações Técnicas e Arquitetura# Armazenamento e processamento em computação em nuvem envolvem a utilização de diversos serviços e tecnologias para armazenar, gerenciar e processar grandes volumes de dados. Os principais tipos de armazenamento são: objetos, blocos e arquivos. Data Lakes e plataformas de Big Data e AI são fundamentais para o processamento e análise de dados em larga escala.\nObjetos: Armazenam dados como objetos em um sistema de armazenamento distribuído. Cada objeto inclui o dado, um ID globalmente único e metadados. Blocos: Armazenam dados em volumes de blocos, sendo ideal para sistemas de arquivos e bancos de dados que exigem desempenho de I/O. Arquivos: Oferecem um sistema de arquivos hierárquico para armazenar dados em arquivos, acessíveis por múltiplos clientes. Data Lakes são repositórios que permitem armazenar grandes volumes de dados em seu formato nativo, facilitando a análise de Big Data. Big Data e AI envolvem o processamento e análise de grandes volumes de dados para insights e inteligência artificial.\n2. Detalhamento Técnico Avançado (Deep Dive)# Objetos: Utilizam uma arquitetura flat, onde cada objeto é independente. Isso permite escalabilidade e durabilidade, mas não é ideal para dados que exigem transações ou bloqueios. Blocos: Cada bloco é tratado como um volume independente, o que permite alto desempenho de I/O. São ideais para bancos de dados e aplicações que exigem leitura/escrita intensiva. Arquivos: Suportam o compartilhamento de arquivos em rede, permitindo acesso simultâneo. São menos escaláveis que o armazenamento de objetos. Data Lakes suportam a ingestão de dados em tempo real e batch, armazenando dados não estruturados e estruturados. Big Data envolve tecnologias como Hadoop e Spark para processamento distribuído.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nAWS S3 (Objetos): aws s3 cp myFile.txt s3://mybucket/myFile.txt Azure Blob Storage (Objetos): az storage blob upload --container-name mycontainer --file myFile.txt --name myBlob Hadoop HDFS (Arquivos): hdfs dfs -put localfile.txt /user/hadoop/hadoopfile.txt Protocolos e Regras:\nS3: Utiliza o protocolo HTTP/S para transferência de dados. Suporta ACLs para controle de acesso. HDFS: Utiliza o protocolo próprio do Hadoop para comunicação entre os nós. Suporta replicação de dados para garantir durabilidade. Exemplos de Output/Logs:\nUpload S3: upload: ./myFile.txt to s3://mybucket/myFile.txt 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das diferenças entre os tipos de armazenamento e suas aplicações práticas. Uma pegadinha comum é afirmar que o armazenamento de blocos é o mais adequado para análise de Big Data, quando na verdade, Data Lakes e sistemas de arquivos distribuídos como HDFS são mais apropriados.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica aws s3 cp Copia arquivos para o S3 Usado para armazenamento de objetos az storage blob upload Faz upload de blobs para Azure Usado para armazenamento de objetos hdfs dfs -put Copia arquivos para HDFS Usado para armazenamento de arquivos 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# O armazenamento de objetos é ideal para sistemas de arquivos e bancos de dados que exigem alto desempenho de I/O. (Errado) Data Lakes permitem armazenar dados estruturados e não estruturados, facilitando a análise de Big Data. (Certo) O armazenamento de blocos trata cada bloco como um volume independente, o que não é adequado para aplicações que exigem leitura/escrita intensiva. (Errado) Hadoop HDFS é um exemplo de sistema que suporta o armazenamento de arquivos em um ambiente distribuído. (Certo) Azure Blob Storage utiliza o protocolo FTP para transferência de dados. (Errado) 7. Bibliografia e Documentação Oficial# AWS S3 Documentation: https://docs.aws.amazon.com/s3/ Azure Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ Hadoop HDFS Documentation: https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html "},{"id":28,"href":"/cloud/6-governanca-compliance-e-custos/","title":"6. Governança, Compliance e Custos","section":"Computação em Nuvem","content":"6. Governança, Compliance e Custos# 1. Especificações Técnicas e Arquitetura# Governança, compliance e custos em computação em nuvem envolvem a implementação de políticas, procedimentos e tecnologias para gerenciar e monitorar o uso de recursos de nuvem, garantindo a conformidade com leis, normas e melhores práticas, além de otimizar custos. As normas ISO 27001, NIST e LGPD são fundamentais para estabelecer os requisitos de segurança e privacidade. O FinOps é uma prática de gestão financeira para a nuvem que busca otimizar e controlar os custos.\n2. Detalhamento Técnico Avançado (Deep Dive)# FinOps: Prática que combina sistemas, melhores práticas e cultura para aumentar a capacidade das organizações de entender os custos de nuvem e tomar decisões baseadas em dados. Otimização de Recursos: Inclui a identificação de recursos subutilizados ou desnecessários, a aplicação de descontos de compromisso e a escolha de tipos de instâncias ou serviços mais eficientes. Tagueamento e Cotas: Técnicas para atribuir metadados aos recursos para facilitar a alocação de custos, monitoramento e gestão de limites de uso. Normas de Compliance: ISO 27001 foca na gestão de segurança da informação; NIST fornece um framework de segurança cibernética; LGPD regula a proteção de dados pessoais no Brasil. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts: # Exemplo de tagueamento de recursos na AWS CLI aws ec2 create-tags --resources i-1234567890abcdef0 --tags Key=Environment,Value=Production Protocolos e Regras: ISO 27001: Implementação de um Sistema de Gestão de Segurança da Informação (SGSI). NIST: Adoção do Framework de Cibersegurança para identificar, proteger, detectar, responder e recuperar de incidentes cibernéticos. LGPD: Necessidade de consentimento explícito para coleta e uso de dados pessoais, além da nomeação de um DPO (Data Protection Officer). 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar a aplicação prática de normas de compliance em cenários de computação em nuvem, como a implementação de políticas de segurança da informação conforme a ISO 27001 ou a gestão de dados pessoais segundo a LGPD. Uma pegadinha comum é confundir o escopo de aplicação das normas NIST e ISO, ou subestimar a importância do tagueamento e cotas na gestão de custos.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova aws ec2 create-tags Atribui tags a recursos na AWS Importante para a alocação de custos e gestão de recursos ISO 27001 Sistema de Gestão de Segurança Foco na proteção de informações confidenciais NIST Framework de Cibersegurança Aplicável a organizações para melhorar a resiliência LGPD Proteção de dados pessoais Consentimento e transparência são chaves 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# A prática de FinOps não se aplica a modelos de nuvem pública, sendo exclusiva de ambientes de nuvem privada. (Errado) O tagueamento de recursos é uma estratégia eficaz apenas para a identificação de recursos, sem impacto significativo na gestão de custos. (Errado) A ISO 27001 requer a implementação de um Sistema de Gestão de Segurança da Informação (SGSI), incluindo políticas, procedimentos e controles adequados. (Certo) Segundo a LGPD, é obrigatória a nomeação de um DPO (Data Protection Officer) para todas as empresas, independentemente do tamanho ou do volume de dados processados. (Errado) O framework NIST é exclusivo para organizações governamentais dos EUA, não sendo aplicável a empresas privadas ou em outros países. (Errado) 7. Bibliografia e Documentação Oficial# AWS CLI Command Reference: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-tags.html ISO 27001: https://www.iso.org/isoiec-27001-information-security.html NIST Cybersecurity Framework: https://www.nist.gov/cyberframework Lei Geral de Proteção de Dados (LGPD): http://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/L13709.htm "},{"id":29,"href":"/cloud/5-devops-ci-cd-e-iac/","title":"5. DevOps, CI/CD e IaC","section":"Computação em Nuvem","content":"5. DevOps, CI/CD e IaC# 1. Especificações Técnicas e Arquitetura# DevOps, CI/CD (Continuous Integration/Continuous Deployment), e IaC (Infrastructure as Code) são práticas fundamentais para a automação e eficiência no desenvolvimento de software e gerenciamento de infraestrutura. Terraform permite a criação, modificação e versionamento seguro e eficiente de infraestrutura na nuvem usando código. Jenkins e GitHub Actions são ferramentas de integração contínua que automatizam o processo de build e deploy de aplicações. Observabilidade, através de ferramentas como CloudWatch (AWS), Azure Monitor e GCloud Monitoring, permite o monitoramento e análise de aplicações e infraestrutura na nuvem.\n2. Detalhamento Técnico Avançado (Deep Dive)# Terraform utiliza uma linguagem declarativa para definir infraestrutura como código, permitindo a criação de recursos de forma idempotente. Jenkins, baseado em Java, utiliza pipelines definidos em Jenkinsfiles para automação de CI/CD. GitHub Actions utiliza workflows definidos em arquivos YAML para automação baseada em eventos. Observabilidade combina logs, métricas e traces para fornecer insights sobre o desempenho e saúde das aplicações e infraestrutura.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Terraform:\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-0c55b159cbfafe1f0\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; }Jenkins Pipeline:\npipeline { agent any stages { stage(\u0026#39;Build\u0026#39;) { steps { sh \u0026#39;echo \u0026#34;Building...\u0026#34;\u0026#39; } } stage(\u0026#39;Test\u0026#39;) { steps { sh \u0026#39;echo \u0026#34;Testing...\u0026#34;\u0026#39; } } stage(\u0026#39;Deploy\u0026#39;) { steps { sh \u0026#39;echo \u0026#34;Deploying...\u0026#34;\u0026#39; } } } }GitHub Actions Workflow:\nname: CI on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Build run: echo \u0026#34;Building...\u0026#34;Observabilidade com CloudWatch:\naws cloudwatch put-metric-data --metric-name MyMetrics --namespace MyNamespace --value 1234. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão da sintaxe específica e o entendimento profundo dos conceitos de Terraform, Jenkins, GitHub Actions e ferramentas de observabilidade. É comum haver pegadinhas relacionadas à sintaxe específica de declaração de recursos no Terraform, a configuração de pipelines no Jenkins e GitHub Actions, e a interpretação de métricas e logs nas ferramentas de observabilidade.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica terraform apply Aplica as configurações do Terraform Requer revisão do plano antes da execução Jenkinsfile Define um pipeline Jenkins Sintaxe Groovy actions/checkout@v2 Checkout de código no GitHub Actions Versão pode variar aws cloudwatch put-metric-data Envia métricas personalizadas para CloudWatch Requer permissões adequadas 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# Terraform permite a alteração da infraestrutura em tempo real sem a necessidade de aplicar as mudanças previamente em um ambiente de teste. (Errado)\nJenkins e GitHub Actions podem ser utilizados simultaneamente em um projeto para otimizar o processo de CI/CD. (Certo)\nCloudWatch, Azure Monitor e GCloud Monitoring são capazes de coletar automaticamente todos os tipos de logs sem configuração prévia. (Errado)\nÉ possível definir políticas de retenção de logs e métricas específicas diretamente nas configurações do Terraform para serviços de observabilidade na nuvem. (Certo)\nGitHub Actions não suporta a execução de workflows em máquinas virtuais privadas ou em ambientes on-premise. (Errado)\n7. Bibliografia e Documentação Oficial# Terraform: Terraform Documentation Jenkins: Jenkins User Documentation GitHub Actions: GitHub Actions Documentation AWS CloudWatch: Amazon CloudWatch Documentation Azure Monitor: Azure Monitor Documentation Google Cloud Monitoring: Google Cloud Monitoring Documentation "},{"id":30,"href":"/cloud/4-redes-e-seguranca-em-nuvem/","title":"4. Redes e Segurança em Nuvem","section":"Computação em Nuvem","content":"4. Redes e Segurança em Nuvem# 1. Especificações Técnicas e Arquitetura# Redes e segurança em nuvem abrangem a implementação e gerenciamento de redes virtuais, controle de acesso, proteção de dados e conexões seguras entre ambientes on-premises e na nuvem. Principais componentes incluem VPNs, sub-redes, gateways, IAM (Identity and Access Management), RBAC (Role-Based Access Control), MFA (Multi-Factor Authentication), criptografia (TLS, KMS), e modelos de segurança como Zero Trust. Conexões dedicadas como VPN site-to-site, AWS Direct Connect e Azure ExpressRoute facilitam a integração segura e de alta performance entre a infraestrutura da empresa e a nuvem.\n2. Detalhamento Técnico Avançado (Deep Dive)# VPNs e Sub-redes: VPNs criam túneis seguros sobre a internet, enquanto sub-redes dividem redes maiores em segmentos menores para melhor gerenciamento e segurança. IAM e RBAC: IAM permite gerenciar usuários e suas permissões, enquanto RBAC atribui direitos baseados no papel do usuário na organização. MFA: Adiciona uma camada extra de segurança exigindo dois ou mais métodos de verificação. Criptografia TLS e KMS: TLS protege a comunicação entre cliente e servidor. KMS gerencia chaves de criptografia, permitindo criptografar e descriptografar dados. Zero Trust: Modelo de segurança que não assume confiança em nenhum elemento, exigindo verificação constante de todos os dispositivos e usuários. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# AWS CLI para criar uma VPN Site-to-Site: aws ec2 create-vpn-connection --type ipsec.1 --customer-gateway-id cgw-abc123 --vpn-gateway-id vgw-abc123Protocolos e Regras# Handshake TLS: Processo pelo qual duas partes estabelecem comunicação segura, negociando criptografia e verificando identidades antes da transferência de dados. Exemplos de Output/Logs# Log de conexão VPN: Dec 1 12:00:00 vpn-instance [IKE] INFO: IKE_SA aws-vpn[1] established between 203.0.113.1[203.0.113.1] and 198.51.100.1[198.51.100.1]Contexto TCU# A aplicação dessas tecnologias no TCU envolve garantir a segurança e eficiência na transferência e acesso a dados entre diferentes entidades e infraestruturas, seguindo diretrizes de compliance e governança.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE enfatiza a compreensão detalhada das configurações e implicações de segurança, podendo questionar sobre a aplicabilidade e limitações de cada tecnologia em cenários específicos. Pegadinhas comuns incluem confundir características de VPN site-to-site com conexões dedicadas como Direct Connect e ExpressRoute.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante aws ec2 create-vpn-connection Cria uma conexão VPN site-to-site. Requer IDs de gateway de cliente e VPN. Handshake TLS Estabelece comunicação segura. Verifica identidades e negocia criptografia. RBAC Atribui direitos baseados em papéis. Importante para controle de acesso granular. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) A criptografia TLS é utilizada para proteger a comunicação entre um usuário e um banco de dados na nuvem, mesmo que o banco de dados não ofereça suporte nativo a TLS.\nErrado. TLS é usado para proteger a comunicação entre cliente e servidor, mas ambos devem suportar TLS. (Certo ou Errado) IAM permite gerenciar não apenas as identidades dos usuários, mas também as políticas de rede e firewall.\nErrado. IAM é focado na gestão de identidades e acessos, não diretamente em políticas de rede e firewall. (Certo ou Errado) Uma VPN site-to-site é capaz de conectar múltiplas sub-redes em diferentes locais como se estivessem na mesma rede local.\nCerto. VPN site-to-site conecta redes em locais distintos, permitindo que operem como uma única rede. (Certo ou Errado) O modelo Zero Trust exige a verificação constante de todos os dispositivos, mas confia nos usuários uma vez autenticados.\nErrado. Zero Trust não assume confiança em nenhum elemento, exigindo verificação constante tanto de dispositivos quanto de usuários. (Certo ou Errado) AWS Direct Connect e Azure ExpressRoute permitem a criação de conexões dedicadas entre a infraestrutura on-premises e a nuvem, reduzindo a latência em comparação com conexões VPN tradicionais.\nCerto. Ambos proporcionam conexões dedicadas que podem oferecer menor latência e maior segurança. 7. Bibliografia e Documentação Oficial# AWS Documentation: https://docs.aws.amazon.com/ Azure Documentation: https://docs.microsoft.com/en-us/azure/ RFC 5246 (TLS 1.2): https://tools.ietf.org/html/rfc5246 NIST Special Publication 800-207 (Zero Trust Architecture): https://csrc.nist.gov/publications/detail/sp/800-207/final "},{"id":31,"href":"/cloud/3-arquitetura-de-solucoes/","title":"3. Arquitetura de Soluções","section":"Computação em Nuvem","content":"3. Arquitetura de Soluções# 1. Especificações Técnicas e Arquitetura# Sistemas Distribuídos Resilientes: Utilizam múltiplas instâncias de aplicativos em diferentes servidores para garantir alta disponibilidade e tolerância a falhas. A comunicação entre serviços é feita através de APIs REST ou mensageria.\nServerless: Modelo de execução de computação em nuvem onde o provedor de nuvem gerencia a alocação de recursos. O código é executado em resposta a eventos. AWS Lambda e Azure Functions são exemplos.\nEvent-Driven Architecture (EDA): Arquitetura que promove a produção, detecção, consumo e reação a eventos. Os serviços são acoplados de forma solta, aumentando a flexibilidade e escalabilidade.\nLoad Balancing: Distribuição automática de tráfego de rede ou aplicativos entre vários servidores para otimizar a utilização de recursos, maximizar a throughput, reduzir a latência e garantir a alta disponibilidade.\nAuto Scaling: Ajusta automaticamente a quantidade de recursos computacionais em um sistema de aplicativo em resposta à demanda. É crucial para manter a performance e otimizar custos.\nContainers (Docker, Kubernetes): Docker permite a criação de containers para isolar aplicações. Kubernetes é um orquestrador de containers que facilita a implantação, escalabilidade e gerenciamento de aplicações containerizadas.\n2. Detalhamento Técnico Avançado (Deep Dive)# Docker: Utiliza o Dockerfile para criar imagens de container que podem ser executadas de forma isolada. Comandos como docker build e docker run são essenciais.\nKubernetes: Gerencia clusters de containers. Utiliza objetos como Pods, Services, Deployments para organizar a execução de containers. Comandos importantes incluem kubectl apply para aplicar configurações e kubectl get pods para listar pods em execução.\nResiliência em Sistemas Distribuídos: Implementada através de padrões como Circuit Breaker, Bulkhead e Retry Patterns. Estes padrões ajudam a prevenir falhas em cascata e garantem a estabilidade do sistema.\nAuto Scaling: Pode ser configurado com base em métricas de utilização ou agendas. AWS Auto Scaling e Kubernetes Horizontal Pod Autoscaler são exemplos de implementações.\nLoad Balancing: Algoritmos como Round Robin, Least Connections e IP Hash são usados para distribuir o tráfego. Em Kubernetes, o Service do tipo LoadBalancer pode ser usado para expor aplicações ao tráfego externo.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nDocker:\ndocker build -t minha-imagem . docker run -d -p 8080:80 minha-imagem Kubernetes:\napiVersion: apps/v1 kind: Deployment metadata: name: meu-app spec: replicas: 3 selector: matchLabels: app: meu-app template: metadata: labels: app: meu-app spec: containers: - name: meu-app image: minha-imagem ports: - containerPort: 80 Protocolos e Regras:\nAuto Scaling: Configuração baseada em métricas de CPU ou memória. Em Kubernetes, o Horizontal Pod Autoscaler ajusta o número de pods em um Deployment com base na utilização.\nLoad Balancing: O algoritmo Round Robin distribui as solicitações de forma igual entre os servidores disponíveis, enquanto o Least Connections prioriza servidores com menos conexões ativas.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode apresentar questões que exigem conhecimento específico sobre comandos e suas sintaxes exatas. Por exemplo, confundir comandos de Docker com Kubernetes pode ser uma pegadinha comum.\nOutra nuance é a diferenciação entre conceitos de auto scaling vertical e horizontal, onde o primeiro se refere ao aumento de recursos em uma única instância e o segundo à adição de mais instâncias.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante docker build -t minha-imagem . Constrói uma imagem Docker a partir de um Dockerfile. Verifique o contexto do build (pasta atual). kubectl apply -f deployment.yaml Aplica uma configuração a um recurso no Kubernetes. deployment.yaml deve estar bem-formado e válido. Horizontal Pod Autoscaler Ajusta automaticamente o número de pods em um deployment do Kubernetes. Requer métricas de utilização (CPU/memória). 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# Certo ou Errado? No Kubernetes, o comando kubectl scale deployment meu-app --replicas=3 pode ser utilizado para implementar manualmente o auto scaling de um aplicativo.\nCerto ou Errado? Serverless implica que não há servidores envolvidos na execução de aplicações.\nCerto ou Errado? Em arquiteturas event-driven, um componente pode consumir e reagir a eventos sem conhecer a identidade do emissor.\nCerto ou Errado? Docker e Kubernetes não podem ser usados juntos, pois servem a propósitos completamente diferentes.\nCerto ou Errado? Load balancing é uma técnica que pode ser aplicada apenas ao nível de aplicação, não ao nível de rede.\nGabarito Comentado:\nCerto. O comando especificado é uma forma válida de ajustar o número de réplicas de um deployment no Kubernetes, embora o auto scaling automático seja preferível para ajustes dinâmicos.\nErrado. Serverless não significa a ausência de servidores, mas sim que a gestão dos servidores é abstraída do desenvolvedor.\nCerto. Esta é uma característica chave das arquiteturas event-driven, promovendo o desacoplamento entre produtores e consumidores de eventos.\nErrado. Docker e Kubernetes são frequentemente usados juntos; Docker para containerização e Kubernetes para orquestração desses containers.\nErrado. Load balancing pode ser aplicado tanto ao nível de aplicação quanto ao nível de rede, ajudando a distribuir o tráfego de forma eficaz.\n7. Bibliografia e Documentação Oficial# Docker Docs: https://docs.docker.com/ Kubernetes Documentation: https://kubernetes.io/docs/home/ AWS Lambda Developer Guide: https://docs.aws.amazon.com/lambda/latest/dg/welcome.html Azure Functions Documentation: https://docs.microsoft.com/en-us/azure/azure-functions/ Google Cloud Pub/Sub Documentation: https://cloud.google.com/pubsub/docs "},{"id":32,"href":"/cloud/2-plataformas-e-servicos/","title":"2. Plataformas e Serviços","section":"Computação em Nuvem","content":"2. Plataformas e Serviços# 1. Especificações Técnicas e Arquitetura# AWS, Microsoft Azure e Google Cloud Platform (GCP) são as principais plataformas de computação em nuvem, oferecendo uma ampla gama de serviços que permitem a execução de aplicações e o armazenamento de dados na nuvem. Cada uma dessas plataformas tem sua própria arquitetura, conjunto de serviços e modelo de gerenciamento.\nAWS: Amazon Web Services oferece serviços como EC2 para computação, S3 para armazenamento, e RDS para bancos de dados. Utiliza a AWS Management Console para gerenciamento.\nAzure: Microsoft Azure fornece serviços como Virtual Machines, Azure SQL Database, e Blob Storage. Gerenciado através do Azure Portal.\nGCP: Google Cloud Platform disponibiliza serviços como Compute Engine, Cloud Storage e BigQuery. Usa o Google Cloud Console para gerenciamento.\n2. Detalhamento Técnico Avançado (Deep Dive)# AWS# EC2: Permite escalar capacidade computacional usando virtualização. S3: Armazenamento de objetos com alta disponibilidade e durabilidade. RDS: Serviço de banco de dados relacional que facilita configuração, operação e escalabilidade. Azure# Virtual Machines: Para implementação de servidores virtuais. Azure SQL Database: Banco de dados como serviço baseado no SQL Server. Blob Storage: Armazenamento de objetos para grandes quantidades de dados não estruturados. GCP# Compute Engine: VMs que rodam em data centers do Google. Cloud Storage: Armazenamento de objetos altamente escalável. BigQuery: Armazenamento de dados para análise em larga escala. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# AWS CLI# # Criar uma instância EC2 aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro # Listar buckets S3 aws s3 ls # Criar um banco de dados RDS PostgreSQL aws rds create-db-instance --db-instance-identifier MeuPostgres --db-instance-class db.t2.micro --engine postgres --allocated-storage 20 --master-username admin --master-user-password senha123Azure CLI# # Criar uma VM az vm create --resource-group MeuGrupoDeRecursos --name MinhaVM --image UbuntuLTS --generate-ssh-keys # Criar um banco de dados SQL az sql db create --resource-group MeuGrupoDeRecursos --server meuServidor --name MeuBancoDeDados --service-objective S0 # Criar um container no Blob Storage az storage container create --account-name minhaconta --name meucontainerGCP CLI (gcloud)# # Criar uma VM no Compute Engine gcloud compute instances create minha-vm --zone us-central1-a # Criar um bucket no Cloud Storage gsutil mb gs://meu-bucket # Carregar dados para o BigQuery bq load --source_format=CSV meu_dataset.minha_tabela gs://meu-bucket/arquivo.csv4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar o entendimento prático dos serviços em nuvem, focando em comandos específicos e suas sintaxes. É comum encontrar questões que testam o conhecimento sobre a seleção correta do serviço para determinado cenário, além de pegadinhas relacionadas à nomenclatura e funcionalidades específicas de cada plataforma.\n5. Tabela de Referência Técnica (Quick Lookup)# Comando/Regra O que faz/O que valida Observação Técnica importante para a prova aws ec2 run-instances Cria uma instância EC2 na AWS Verificar a AMI e o tipo de instância az vm create Cria uma VM no Azure Necessário grupo de recursos e imagem gcloud compute instances create Cria uma VM no GCP Zona deve ser especificada aws s3 ls Lista buckets S3 Comando básico de listagem no S3 az storage container create Cria um container no Azure Blob Storage Conta de armazenamento necessária gsutil mb Cria um bucket no Cloud Storage Prefixo gs:// é obrigatório 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# O comando aws rds create-db-instance permite especificar o tipo de instância para um banco de dados não relacional no AWS RDS. (Errado) No Azure, o comando az sql db create pode ser utilizado para criar uma instância de banco de dados SQL Server, incluindo a definição do tamanho do serviço. (Certo) O GCP não oferece um serviço equivalente ao AWS S3 e Azure Blob Storage para armazenamento de objetos. (Errado) Utilizar o comando gsutil mb sem o prefixo gs:// é válido para criar um bucket no Google Cloud Storage. (Errado) A criação de uma máquina virtual no Azure requer, obrigatoriamente, a geração de chaves SSH através do comando az vm create. (Errado) 7. Bibliografia e Documentação Oficial# AWS CLI Command Reference: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/index.html Azure CLI Documentation: https://docs.microsoft.com/en-us/cli/azure/ Google Cloud CLI (gcloud) Reference: https://cloud.google.com/sdk/gcloud/reference Documentação oficial AWS: https://docs.aws.amazon.com/ Documentação oficial Azure: https://docs.microsoft.com/en-us/azure/ Documentação oficial GCP: https://cloud.google.com/docs "},{"id":33,"href":"/cloud/1-fundamentos/","title":"1. Fundamentos","section":"Computação em Nuvem","content":"1. Fundamentos de Computação em Nuvem# 1. Especificações Técnicas e Arquitetura# A computação em nuvem oferece recursos de TI sob demanda através da internet, com pagamento conforme o uso. Existem três principais modelos de serviço: Infraestrutura como Serviço (IaaS), Plataforma como Serviço (PaaS) e Software como Serviço (SaaS). As arquiteturas de nuvem podem ser públicas, privadas ou híbridas, e os serviços podem ser orquestrados seguindo o paradigma da Arquitetura Orientada a Serviços (SOA) ou através de microsserviços. Conceitos chave incluem elasticidade, escalabilidade e alta disponibilidade (HA).\n2. Detalhamento Técnico Avançado (Deep Dive)# IaaS fornece recursos de computação virtualizados, como VMs, armazenamento e redes. Usuários gerenciam o SO, mas não o hardware. PaaS oferece um ambiente de desenvolvimento e implantação, gerenciando o hardware e o sistema operacional, permitindo aos usuários focar no desenvolvimento de aplicativos. SaaS disponibiliza software como um serviço acessível via navegador, sem necessidade de instalação ou manutenção pelo usuário. Nuvem pública é operada por terceiros, privada é exclusiva de uma organização, e híbrida combina ambos, otimizando recursos e segurança.\nSOA é um estilo de arquitetura de software que permite a integração e a interoperabilidade entre serviços distintos. Microsserviços são uma abordagem para desenvolver uma única aplicação como um conjunto de pequenos serviços, cada um executando em seu próprio processo e se comunicando com mecanismos leves.\nElasticidade permite a um sistema adaptar-se automaticamente à carga de trabalho, adicionando ou removendo recursos conforme necessário. Escalabilidade refere-se à capacidade de um sistema em lidar com um aumento de carga. HA envolve sistemas e componentes configurados de forma redundante para garantir disponibilidade contínua.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\n# Exemplo de comando para criar uma instância EC2 na AWS (IaaS) aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro # Exemplo de comando para escalar um serviço no Azure (PaaS) az appservice plan update --name myAppServicePlan --resource-group myResourceGroup --number-of-workers 4 # Exemplo de comando para verificar a saúde de um serviço (HA) kubectl get componentstatusContexto TCU: A fiscalização de contratações de serviços em nuvem pelo TCU envolve a verificação da conformidade com os princípios de economicidade, eficiência e eficácia. A escolha entre IaaS, PaaS e SaaS deve ser justificada com base nas necessidades específicas da entidade e na análise de custo-benefício.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar o entendimento das diferenças sutis entre elasticidade e escalabilidade, ou entre nuvem privada e híbrida. Uma pegadinha comum é afirmar que PaaS não permite controle algum sobre o ambiente de execução, quando na verdade permite algum grau de configuração.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante aws ec2 run-instances Cria instância EC2 na AWS IaaS, Elasticidade az appservice plan update Escala serviço no Azure PaaS, Escalabilidade kubectl get componentstatus Verifica saúde do serviço HA, Microsserviços 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo/Errado) A escalabilidade é uma característica exclusiva da nuvem pública. (Certo/Errado) Em um modelo PaaS, o usuário tem controle total sobre o sistema operacional da instância. (Certo/Errado) Microsserviços podem ser considerados uma evolução da arquitetura SOA. (Certo/Errado) Elasticidade refere-se exclusivamente à capacidade de reduzir recursos em resposta a uma diminuição da demanda. (Certo/Errado) Uma arquitetura de nuvem híbrida não pode utilizar serviços SaaS de um provedor de nuvem pública. Gabarito:\nErrado. A escalabilidade também pode ser alcançada em nuvens privadas e híbridas. Errado. O controle sobre o sistema operacional é limitado em PaaS. Certo. Microsserviços são uma forma de implementar SOA com serviços mais granulares e independentes. Errado. Elasticidade também envolve aumentar recursos em resposta a um aumento da demanda. Errado. Uma arquitetura híbrida pode integrar serviços SaaS de provedores de nuvem pública com infraestruturas privadas. 7. Bibliografia e Documentação Oficial# AWS Documentation: https://aws.amazon.com/documentation/ Azure Documentation: https://docs.microsoft.com/en-us/azure/ Kubernetes Documentation: https://kubernetes.io/docs/ NIST Definition of Cloud Computing: https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf "},{"id":34,"href":"/seguranca/11-ataques-a-redes/","title":"11. Ataques a redes","section":"Segurança da Informação","content":"11. Ataques a redes# 1. Especificações Técnicas e Arquitetura# Ataques a redes são ações maliciosas destinadas a interromper a normalidade dos serviços de rede, roubar dados, ou de outra forma prejudicar indivíduos ou organizações. Eles podem variar desde simples inconveniências até graves violações de segurança.\nDoS e DDoS (Denial of Service e Distributed Denial of Service): visam sobrecarregar recursos de rede, tornando-os indisponíveis. Botnets: redes de computadores infectados controlados remotamente para executar ataques em larga escala. Phishing: tentativas de enganar usuários para roubar credenciais ou informações sensíveis. Zero-day: explora vulnerabilidades desconhecidas dos desenvolvedores ou fabricantes. Ping da morte: envio de pacotes malformados para desestabilizar ou derrubar sistemas. UDP Flood: inundação da rede com pacotes UDP para esgotar recursos do servidor. MAC/IP/ARP Spoofing: falsificação de endereços para interceptar ou redirecionar o tráfego de rede. Buffer Overflow: exploração de um excesso de dados em um buffer para executar código malicioso. SQL Injection: inserção de código SQL malicioso em consultas para manipular ou acessar dados não autorizados. XSS (Cross-Site Scripting): injeção de scripts maliciosos em sites para executar no navegador do usuário. DNS Poisoning: corrompimento da resolução de nomes de domínio para redirecionar usuários para sites maliciosos. 2. Detalhamento Técnico Avançado (Deep Dive)# DoS/DDoS: Utiliza múltiplos sistemas comprometidos (botnets) para gerar um volume de tráfego insustentável para o alvo. Botnets: Operam através do controle de um \u0026ldquo;botmaster\u0026rdquo; que comanda a rede de bots infectados, muitas vezes para realizar ataques DDoS. Phishing: Emprega técnicas de engenharia social, frequentemente através de emails ou mensagens que imitam entidades confiáveis. Zero-day: Requer uma vigilância constante e uma rápida resposta às ameaças emergentes, dado que não existem correções ou mitigação conhecidas no momento da descoberta. UDP Flood: Não requer uma conexão estabelecida, tornando-o mais difícil de filtrar e rastrear. MAC/IP/ARP Spoofing: Explora a confiança inerente nos protocolos de rede, permitindo ataques como \u0026ldquo;man-in-the-middle\u0026rdquo;. Buffer Overflow: Pode ser mitigado através da programação defensiva, como a verificação de limites em buffers. SQL Injection: Prevenível através do uso de consultas parametrizadas e práticas de codificação segura. XSS: Mitigado por meio da validação e sanitização de entrada de dados do usuário e implementação de políticas de segurança de conteúdo. DNS Poisoning: Requer a implementação de segurança adicional, como DNSSEC, para garantir a autenticidade das respostas DNS. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nDetecção de ARP Spoofing:\narp -aVerifique entradas duplicadas com diferentes endereços IP, indicando possível spoofing.\nMitigação de SQL Injection (Exemplo em SQL):\nSELECT * FROM users WHERE username = ? AND password = ?Utilize placeholders (?) para prevenir injeção.\nProtocolos e Regras:\nTLS Handshake: Processo de negociação criptográfica entre cliente e servidor para estabelecer uma comunicação segura. Normalização de Dados: Aplicação de regras de 1FN, 2FN, e 3FN para organizar dados em um banco de dados relacional. Exemplos de Output/Logs:\nLog de tentativa de SQL Injection: \u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1Tentativa de login ou acesso a dados através da injeção. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão dos candidatos sobre a natureza e a mitigação de ataques específicos, muitas vezes focando em detalhes técnicos ou na aplicabilidade de medidas de segurança. É comum encontrar questões que testam o conhecimento sobre a implementação de práticas de segurança e a capacidade de identificar vulnerabilidades em cenários dados.\nDicas de prova:\nEsteja atento a questões que pedem a identificação do tipo de ataque com base em descrições de cenários. Questões sobre mitigação de ataques frequentemente requerem conhecimento de configurações específicas ou práticas de codificação segura. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova arp -a Verifica entradas ARP Útil para detecção de ARP Spoofing Consultas parametrizadas SQL Prevenção contra SQL Injection Evita a execução de código SQL malicioso Validação de entrada Mitiga XSS e Injeção SQL Sanitização de dados do usuário DNSSEC Segurança de DNS Previne DNS Poisoning TLS Handshake Estabelece comunicação segura Importante para a segurança de transmissões 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) O ataque de Ping da Morte é eficaz contra sistemas modernos, pois a maioria ainda não implementa limites de tamanho para pacotes ICMP.\nResposta: Errado. Sistemas modernos geralmente implementam proteções contra esse tipo de ataque. (Certo ou Errado) A utilização de consultas parametrizadas é uma técnica eficaz na prevenção de ataques de injeção de SQL.\nResposta: Certo. Consultas parametrizadas ajudam a prevenir a execução de comandos SQL maliciosos. (Certo ou Errado) Botnets são principalmente utilizadas para realizar ataques de phishing.\nResposta: Errado. Botnets são redes de computadores infectados usadas para uma variedade de ataques maliciosos, incluindo, mas não limitado a, DDoS. (Certo ou Errado) DNS Poisoning pode ser mitigado com a implementação de HTTPS em todos os sites.\nResposta: Errado. DNS Poisoning é mitigado através de medidas como DNSSEC, não apenas HTTPS. (Certo ou Errado) ARP Spoofing pode ser detectado pela observação de múltiplas respostas ARP para o mesmo endereço IP.\nResposta: Certo. Isso pode indicar uma tentativa de ARP Spoofing. 7. Bibliografia e Documentação Oficial# RFC 2827 - Network Ingress Filtering: Defeating Denial of Service Attacks which employ IP Source Address Spoofing. OWASP Top 10 - A lista das 10 principais vulnerabilidades de segurança em aplicações web, incluindo SQL Injection e XSS. NIST Special Publication 800-61 - Guia para tratamento de incidentes de segurança cibernética, incluindo detecção e resposta a ataques. Documentação oficial do DNSSEC no site da IANA (Internet Assigned Numbers Authority). Este material foi elaborado com base nas especificações técnicas e arquitetônicas dos ataques a redes, focando em detalhes operacionais e implementações práticas, conforme exigido pelo contexto de TI e fiscalização do TCU, e seguindo as diretrizes de cobrança da banca CEBRASPE.\n"},{"id":35,"href":"/seguranca/10-seguranca-em-nuvens-e-conteineres/","title":"10. Segurança em nuvens e contêineres","section":"Segurança da Informação","content":"10. Segurança em nuvens e contêineres# 1. Especificações Técnicas e Arquitetura# A segurança em ambientes de nuvens e contêineres abrange a proteção de dados, aplicações, infraestrutura e plataformas operando em ambientes de cloud computing e contêineres. Componentes principais incluem a orquestração de contêineres (ex: Kubernetes), serviços de computação em nuvem (ex: AWS EC2, Google Cloud Compute Engine), e ferramentas de segurança específicas para estes ambientes.\nOrquestração de Contêineres: Gerencia a vida útil de contêineres em ambientes de nuvem. Serviços de Computação em Nuvem: Provisão de recursos computacionais escaláveis. Ferramentas de Segurança: Soluções para gerenciamento de identidade e acesso, proteção de dados, monitoramento e conformidade. 2. Detalhamento Técnico Avançado (Deep Dive)# Isolamento de Recursos: Fundamental para a segurança em nuvens e contêineres, o isolamento previne que processos maliciosos afetem outros contêineres ou a própria infraestrutura da nuvem. Gerenciamento de Identidade e Acesso (IAM): Políticas rigorosas de IAM são essenciais para controlar o acesso a recursos na nuvem e contêineres. Criptografia de Dados: Tanto em repouso quanto em trânsito, a criptografia protege dados sensíveis. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\n# Exemplo de comando para listar buckets S3 na AWS com a CLI aws s3 ls # Exemplo de comando para criar um pod no Kubernetes kubectl run nginx --image=nginxProtocolos e Regras:\nTLS para Criptografia em Trânsito: Garante a segurança da comunicação entre serviços. Políticas de Segurança de Rede: Implementadas via grupos de segurança ou listas de controle de acesso. Exemplos de Output/Logs:\n# Exemplo de output da AWS CLI ao listar buckets S3 2023-01-01 12:34:56 my-bucket-nameContexto TCU:\nA aplicação de práticas de segurança em ambientes cloud e contêineres é crucial para a conformidade com normativas e diretrizes do TCU, especialmente no que tange à proteção de dados públicos e a eficiência na gestão de recursos de TI.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar o entendimento prático e teórico das tecnologias, com ênfase em detalhes de implementação e configuração. É comum encontrar questões que testam o conhecimento sobre nuances específicas de segurança em ambientes de nuvem e contêineres, como a diferença entre responsabilidades compartilhadas em modelos de serviço de nuvem (IaaS, PaaS, SaaS).\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova aws s3 ls Lista buckets S3 na AWS Verificar acesso e inventário de dados kubectl run Cria um pod no Kubernetes Fundamentos de orquestração de contêineres Políticas de IAM Gerencia acesso a recursos Importância do princípio do menor privilégio 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) A criptografia de dados em repouso em um ambiente de nuvem é opcional para dados não sensíveis.\nResposta: Errado. A criptografia de dados em repouso é uma prática recomendada para todos os tipos de dados. (Certo ou Errado) Kubernetes é uma ferramenta exclusiva para a orquestração de contêineres na nuvem AWS.\nResposta: Errado. Kubernetes é uma ferramenta de orquestração de contêineres de código aberto que pode ser usada em qualquer ambiente de nuvem. (Certo ou Errado) Políticas rigorosas de IAM não são necessárias para contêineres, visto que eles são isolados por padrão.\nResposta: Errado. Políticas rigorosas de IAM são essenciais, mesmo em ambientes de contêineres, para controlar o acesso a recursos e garantir a segurança. (Certo ou Errado) A responsabilidade pela segurança em modelos de serviço de nuvem (IaaS, PaaS, SaaS) é inteiramente do provedor de nuvem.\nResposta: Errado. A segurança em modelos de serviço de nuvem é uma responsabilidade compartilhada entre o provedor e o cliente. (Certo ou Errado) O uso de TLS para criptografia em trânsito é uma prática recomendada apenas para ambientes de nuvem pública.\nResposta: Errado. O uso de TLS é recomendado para qualquer ambiente, seja nuvem pública, privada ou híbrida, para garantir a segurança da comunicação. 7. Bibliografia e Documentação Oficial# AWS Documentation: https://docs.aws.amazon.com/ Kubernetes Documentation: https://kubernetes.io/docs/ NIST Cloud Computing Security: https://csrc.nist.gov/publications/detail/sp/800-144/final Manual de Boas Práticas em Segurança da Informação para Uso do TCU: https://portal.tcu.gov.br/ "},{"id":36,"href":"/seguranca/9-criptografia/","title":"9. Criptografia","section":"Segurança da Informação","content":"9. Criptografia# 1. Especificações Técnicas e Arquitetura# Criptografia é o estudo e aplicação de técnicas matemáticas para garantir a segurança da informação, especialmente na proteção de dados em trânsito e em repouso, e na implementação de assinaturas digitais. Os componentes principais incluem algoritmos de criptografia, chaves criptográficas e sistemas de gerenciamento de chaves. A criptografia se baseia em conceitos fundamentais como confidencialidade, integridade, autenticação e não repúdio.\n2. Detalhamento Técnico Avançado (Deep Dive)# Assinatura Digital: Utiliza um par de chaves assimétricas para garantir a autenticidade e a integridade de uma mensagem. O remetente assina a mensagem com sua chave privada, e o receptor verifica a assinatura com a chave pública do remetente. Proteção de Dados em Trânsito: Utiliza protocolos como TLS (Transport Layer Security) para criptografar dados que estão sendo transferidos por uma rede, prevenindo interceptações maliciosas. Proteção de Dados em Repouso: Envolve a criptografia de dados armazenados em dispositivos ou na nuvem, utilizando algoritmos como AES (Advanced Encryption Standard) para garantir que os dados sejam inacessíveis sem a chave de criptografia correta. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nGerar um par de chaves RSA para assinatura digital: openssl genpkey -algorithm RSA -out private_key.pem openssl rsa -pubout -in private_key.pem -out public_key.pem Assinar um documento: openssl dgst -sha256 -sign private_key.pem -out document.sig document.txt Verificar a assinatura de um documento: openssl dgst -sha256 -verify public_key.pem -signature document.sig document.txt Protocolos e Regras:\nTLS Handshake: Processo pelo qual as partes negociam a versão do protocolo, selecionam algoritmos criptográficos, autenticam-se mutuamente e estabelecem chaves de sessão criptografadas. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a aplicação prática e teórica da criptografia com foco na segurança da informação, especialmente em contextos governamentais. É comum encontrar questões que testam o entendimento sobre a diferença entre criptografia simétrica e assimétrica, além da aplicação de assinaturas digitais e a importância da gestão de chaves. Uma pegadinha comum é confundir a função de hash com criptografia, ou não entender a diferença entre criptografia em repouso e em trânsito.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova openssl genpkey -algorithm RSA Gera um par de chaves RSA Importante para assinatura digital openssl dgst -sha256 -sign Assina digitalmente um documento SHA-256 é um algoritmo de hash seguro openssl dgst -sha256 -verify Verifica a assinatura de um documento Garante a integridade e autenticidade do documento TLS Handshake Estabelece uma conexão segura Fundamental para a proteção de dados em trânsito AES Algoritmo de criptografia para dados em repouso Segurança de dados armazenados 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) A criptografia assimétrica utiliza o mesmo par de chaves para criptografar e descriptografar uma mensagem.\nErrado. A criptografia assimétrica utiliza um par de chaves, uma pública e uma privada, onde a chave pública é usada para criptografar e a privada para descriptografar. (Certo ou Errado) O protocolo TLS é utilizado para garantir a segurança de dados em repouso.\nErrado. O TLS (Transport Layer Security) é utilizado para proteger dados em trânsito, não em repouso. (Certo ou Errado) A assinatura digital garante a confidencialidade da mensagem assinada.\nErrado. A assinatura digital garante a autenticidade e integridade da mensagem, mas não sua confidencialidade. (Certo ou Errado) O uso de funções de hash é suficiente para garantir a segurança de dados armazenados.\nErrado. Funções de hash garantem a integridade dos dados, mas não a confidencialidade. Para proteger dados em repouso, é necessária a criptografia. (Certo ou Errado) A gestão de chaves é um componente crítico na infraestrutura de criptografia, requerendo processos seguros de geração, armazenamento, distribuição e destruição de chaves.\nCerto. A gestão de chaves é fundamental para a segurança da criptografia, pois as chaves são o elemento que permite a criptografia e descriptografia dos dados. 7. Bibliografia e Documentação Oficial# RFC 8446 - The Transport Layer Security (TLS) Protocol Version 1.3: https://tools.ietf.org/html/rfc8446 OpenSSL Documentation: https://www.openssl.org/docs/ NIST Special Publication 800-57 - Recommendation for Key Management: https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-57pt1r4.pdf "},{"id":37,"href":"/seguranca/8-tratamento-de-incidentes-ciberneticos/","title":"8. Tratamento de Incidentes Cibernéticos","section":"Segurança da Informação","content":"8. Tratamento de Incidentes Cibernéticos# 1. Especificações Técnicas e Arquitetura# O tratamento de incidentes cibernéticos envolve a identificação, análise, contenção, erradicação e recuperação de incidentes que ameacem a segurança da informação. Componentes principais incluem:\nSistema de Detecção de Intrusões (IDS): Monitora o tráfego de rede para atividades suspeitas. Sistema de Gerenciamento de Incidentes: Ferramenta para registro e gestão de incidentes. Equipe de Resposta a Incidentes (CERT ou CSIRT): Grupo especializado na resposta e análise de incidentes. Conceitos fundamentais:\nIdentificação: Detectar e reportar o incidente. Contenção: Limitar o impacto do incidente. Erradicação: Remover a causa raiz do incidente. Recuperação: Restaurar os sistemas afetados à operação normal. Aprendizado: Analisar o incidente para prevenir futuras ocorrências. 2. Detalhamento Técnico Avançado (Deep Dive)# Identificação de Incidentes: Uso de SIEM (Security Information and Event Management) para correlacionar eventos e identificar incidentes. Análise Forense: Utilização de ferramentas como Volatility para análise de memória e Wireshark para análise de tráfego de rede. Comunicação: Protocolo de comunicação deve seguir o RFC 2350, definindo procedimentos e contatos. Boas práticas:\nImplementação de uma política de resposta a incidentes. Treinamento regular da equipe de resposta a incidentes. Simulações periódicas de incidentes para aprimoramento das habilidades e processos. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nWireshark: tshark -i eth0 -f 'port 80' para capturar tráfego HTTP na interface eth0. Volatility: vol.py -f memory.dmp --profile=Win7SP1x64 pslist para listar processos em uma imagem de memória do Windows 7. Protocolos e Regras:\nRFC 2350: Define expectativas para provedores de resposta a incidentes. NIST SP 800-61: Guia para tratamento de incidentes. Exemplos de Output/Logs:\nLogs de IDS: Alerta de tentativa de SQL Injection: ALERT: SQL Injection attempt detected from IP 192.168.1.100. Contexto TCU:\nAdoção de políticas de resposta a incidentes conforme melhores práticas do NIST e orientações do GSI/PR. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar:\nDetalhes sobre procedimentos específicos de resposta a incidentes. Diferenciação entre termos como \u0026ldquo;mitigação\u0026rdquo; e \u0026ldquo;contenção\u0026rdquo;. Importância da documentação e análise post-mortem de incidentes. Pegadinhas comuns:\nConfundir etapas de resposta a incidentes. Subestimar a importância da comunicação durante um incidente. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica tshark -i eth0 -f 'port 80' Captura tráfego HTTP na interface eth0 Útil para análise inicial de tráfego. RFC 2350 Protocolo de comunicação para CSIRTs Importante para padronização da resposta. NIST SP 800-61 Guia para tratamento de incidentes Base para políticas de resposta a incidentes. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) O NIST SP 800-61 recomenda a realização de simulações de incidentes como parte do treinamento da equipe de resposta. (Certo ou Errado) A análise forense digital deve ser iniciada imediatamente após a identificação de um incidente, sem a necessidade de preservação de evidências. (Certo ou Errado) A comunicação durante um incidente cibernético deve ser restrita à equipe de TI para evitar pânico. (Certo ou Errado) A erradicação de um incidente envolve a remoção do agente da ameaça e a recuperação dos sistemas afetados para o estado operacional normal. (Certo ou Errado) A documentação detalhada de um incidente cibernético é opcional se o incidente for resolvido rapidamente. Gabarito Comentado:\nCerto. O NIST SP 800-61 de fato recomenda simulações de incidentes como método de treinamento. Errado. A preservação de evidências é crucial antes de iniciar qualquer análise forense para garantir a integridade da investigação. Errado. A comunicação eficaz durante um incidente deve incluir partes relevantes além da equipe de TI, seguindo o plano de comunicação estabelecido. Certo. A erradicação envolve a remoção da causa raiz do incidente, enquanto a recuperação foca na restauração dos sistemas. Errado. A documentação é uma parte essencial do processo de resposta a incidentes, independentemente da rapidez da resolução. 7. Bibliografia e Documentação Oficial# NIST SP 800-61: Computer Security Incident Handling Guide RFC 2350: Expectations for Computer Security Incident Response GSI/PR: Guia de Segurança para Internet "},{"id":38,"href":"/seguranca/7-frameworks/","title":"7. Frameworks","section":"Segurança da Informação","content":"7. Frameworks# 1. Especificações Técnicas e Arquitetura# MITRE ATT\u0026amp;CK# Tecnologia/Norma: Framework de conhecimento globalmente acessível que é usado para descrever as táticas e técnicas usadas por cibercriminosos e APTs. Componentes Principais: Táticas, Técnicas, Subtécnicas. Conceitos Fundamentais: Fornece uma linguagem comum para a comunidade de segurança cibernética para descrever as ações dos adversários. CIS Controls# Tecnologia/Norma: Conjunto de práticas de segurança cibernética recomendadas para organizações destinadas a prevenir, detectar e responder a ameaças cibernéticas. Componentes Principais: Controles e Subcontroles. Conceitos Fundamentais: Divididos em controles básicos, fundamentais e organizacionais, visam a proteção eficaz através de práticas bem estabelecidas. NIST CSF# Tecnologia/Norma: Framework voluntário consistindo em padrões, diretrizes e práticas para ajudar organizações a gerenciar e reduzir riscos de cibersegurança. Componentes Principais: Funções (Identificar, Proteger, Detectar, Responder, Recuperar). Conceitos Fundamentais: Promove a proteção e resiliência de infraestruturas críticas através de um conjunto de atividades alinhadas ao risco. 2. Detalhamento Técnico Avançado (Deep Dive)# MITRE ATT\u0026amp;CK: Detalha técnicas específicas como \u0026ldquo;Spear Phishing\u0026rdquo; (T1566) sob a tática \u0026ldquo;Initial Access\u0026rdquo; (TA0001), permitindo organizações a simular ataques e preparar defesas específicas.\nCIS Controls: O controle 1, \u0026ldquo;Inventário e Controle de Ativos de Hardware\u0026rdquo;, exige que todas as organizações mantenham um inventário preciso e atualizado de todos os dispositivos autorizados e não autorizados dentro da rede.\nNIST CSF: A função \u0026ldquo;Identificar\u0026rdquo; inclui atividades como a categorização de ativos de informação com base em seu valor para a organização e a identificação de ameaças relevantes.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Contexto TCU# MITRE ATT\u0026amp;CK: Utilizado para avaliar a postura de segurança de entidades fiscalizadas, identificando lacunas na detecção e resposta a ataques simulados. CIS Controls: Adotado como um benchmark para avaliar a maturidade da segurança cibernética em órgãos governamentais, com ênfase nos controles básicos para uma fundação sólida de segurança. NIST CSF: Serve como um guia para o desenvolvimento de políticas de segurança cibernética dentro de agências governamentais, alinhando práticas de segurança com objetivos estratégicos. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode apresentar questões que exigem a distinção entre as funções e categorias dos frameworks, como confundir técnicas do MITRE ATT\u0026amp;CK com controles do CIS. Pode haver questões que testem o entendimento do candidato sobre a aplicabilidade dos frameworks em cenários específicos, como a implementação de controles CIS em infraestruturas cloud. 5. Tabela de Referência Técnica (Quick Lookup)# Framework Função/Controle Observação Técnica MITRE ATT\u0026amp;CK T1566 - Spear Phishing Técnica de \u0026ldquo;Initial Access\u0026rdquo; CIS Controls Controle 1 Inventário de Ativos de Hardware NIST CSF Identificar Categorização de ativos e identificação de ameaças 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) O framework MITRE ATT\u0026amp;CK pode ser utilizado para criar um inventário de ativos de hardware dentro de uma organização.\nResposta: Errado. O MITRE ATT\u0026amp;CK é utilizado para descrever as táticas e técnicas de adversários, não para inventariar ativos. (Certo ou Errado) Os CIS Controls são divididos em três categorias: básicos, fundamentais e organizacionais, cada um focando em aspectos diferentes da segurança cibernética.\nResposta: Certo. Essa é a divisão correta dos CIS Controls. (Certo ou Errado) A função \u0026ldquo;Proteger\u0026rdquo; do NIST CSF inclui a implementação de firewalls e sistemas de detecção de intrusão.\nResposta: Certo. A função \u0026ldquo;Proteger\u0026rdquo; abrange atividades destinadas a garantir a capacidade de uma organização de limitar ou conter o impacto de um potencial incidente de segurança. (Certo ou Errado) O NIST CSF é um conjunto obrigatório de práticas de segurança cibernética para todas as organizações governamentais dos Estados Unidos.\nResposta: Errado. O NIST CSF é voluntário, mesmo que amplamente adotado. (Certo ou Errado) Uma técnica listada sob a tática \u0026ldquo;Execution\u0026rdquo; no MITRE ATT\u0026amp;CK é diretamente comparável a um controle do CIS focado em \u0026ldquo;Data Protection\u0026rdquo;.\nResposta: Errado. Técnicas do MITRE ATT\u0026amp;CK e controles do CIS servem a propósitos diferentes, com o primeiro descrevendo métodos de ataque e o segundo recomendando práticas de segurança. 7. Bibliografia e Documentação Oficial# MITRE ATT\u0026amp;CK: https://attack.mitre.org CIS Controls: https://www.cisecurity.org/controls/ NIST CSF: https://www.nist.gov/cyberframework "},{"id":39,"href":"/seguranca/6-solucoes-de-seguranca/","title":"6. Soluções de Segurança","section":"Segurança da Informação","content":"6. Soluções de Segurança# 1. Especificações Técnicas e Arquitetura# Firewall# Componentes Principais: Regras de filtragem, NAT, VPN, Logging. Conceitos Fundamentais: Filtragem de pacotes baseada em IP/porta, estado da conexão. IDS (Intrusion Detection System)# Componentes Principais: Sensores, Console de Gerenciamento, Base de Dados de Assinaturas. Conceitos Fundamentais: Detecção de padrões de ataque, análise de tráfego. IPS (Intrusion Prevention System)# Componentes Principais: Sensores, Bloqueio de Tráfego, Base de Dados de Assinaturas. Conceitos Fundamentais: Prevenção ativa de ataques, integração com firewall. SIEM (Security Information and Event Management)# Componentes Principais: Coleta de Logs, Correlação de Eventos, Alertas. Conceitos Fundamentais: Centralização de logs, detecção de ameaças por correlação. Proxy# Componentes Principais: Cache, Filtragem de Conteúdo, Autenticação. Conceitos Fundamentais: Intermediário para requisições web, controle de acesso. IAM (Identity and Access Management)# Componentes Principais: Diretório de Usuários, Autenticação, Autorização. Conceitos Fundamentais: Gerenciamento de identidades, controle de acesso baseado em políticas. PAM (Privileged Access Management)# Componentes Principais: Gestão de Credenciais, Sessão de Monitoramento, Auditoria. Conceitos Fundamentais: Controle de acesso a contas privilegiadas, auditoria de sessões. Antivírus# Componentes Principais: Motor de Análise, Base de Dados de Assinaturas, Quarentena. Conceitos Fundamentais: Detecção e remoção de malware, análise heurística. Antispam# Componentes Principais: Filtragem de Conteúdo, Listas Negras, Autenticação de Email. Conceitos Fundamentais: Redução de spam, análise de conteúdo de emails. 2. Detalhamento Técnico Avançado (Deep Dive)# Firewall: Utilização de ACLs (Access Control Lists) para definir regras específicas de tráfego. Importante entender a diferença entre stateful e stateless.\nIDS/IPS: Diferença na atuação; enquanto IDS apenas detecta e alerta, o IPS atua bloqueando o tráfego suspeito. Importância da atualização constante da base de dados de assinaturas.\nSIEM: Correlação de eventos para detecção de ameaças complexas. Importância da configuração de regras de correlação e do ajuste fino para reduzir falsos positivos.\nProxy: Diferença entre proxy transparente e não transparente. Uso de proxies em cadeia para aumentar a segurança e controle.\nIAM/PAM: Importância da segregação de funções e do princípio do menor privilégio. Uso de Multi-Fator de Autenticação (MFA) para aumentar a segurança.\nAntivírus/Antispam: Mecanismos de detecção baseados em assinaturas versus heurística. Importância da sandbox para análise de ameaças desconhecidas.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Firewall (iptables):\niptables -A INPUT -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT SIEM (Elasticsearch Query para detecção de tentativas de login falhas):\n{ \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;message\u0026#34;: \u0026#34;login failed\u0026#34; } } } Protocolos e Regras# TLS Handshake: Processo de negociação de criptografia entre cliente e servidor para estabelecer uma comunicação segura. Exemplos de Output/Logs# IPS (Snort Alert): [**] [1:2010935:3] ET SCAN Suspicious inbound to MSSQL port 1433 [**] [Classification: Potentially Bad Traffic] [Priority: 2] Contexto TCU# Implementação de PAM para garantir a segurança no acesso a sistemas críticos do TCU, seguindo as diretrizes de auditoria e conformidade. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# CEBRASPE costuma confundir candidatos com questões que misturam conceitos de IDS e IPS, enfatizando a importância de entender a diferença entre detecção e prevenção. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante iptables -A INPUT -p tcp Adiciona regra de filtragem de entrada para TCP Utilizado em configurações de firewall match: \u0026quot;login failed\u0026quot; Busca por falhas de login nos logs Usado em SIEM para detecção de ameaças 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (C) A configuração de um firewall stateful permite a análise do estado da conexão, facilitando a filtragem de pacotes. (E) Um sistema de detecção de intrusão (IDS) pode bloquear ativamente o tráfego de rede considerado malicioso. (C) No contexto de IAM, a implementação de MFA é uma prática recomendada para aumentar a segurança das autenticações. (E) Proxies transparentes requerem configuração manual no navegador do usuário para redirecionar o tráfego. (C) SIEM utiliza a correlação de eventos para identificar atividades suspeitas que podem indicar uma ameaça à segurança. Gabarito Comentado# Certo. Firewalls stateful analisam o estado da conexão, o que permite uma filtragem mais eficiente. Errado. IDS apenas detecta e alerta sobre atividades suspeitas, enquanto o IPS é que possui capacidade de bloqueio. Certo. MFA adiciona uma camada extra de segurança, sendo uma prática recomendada em IAM. Errado. Proxies transparentes não requerem configuração manual no navegador, pois interceptam o tráfego automaticamente. Certo. SIEM efetivamente utiliza correlação de eventos para detectar ameaças, combinando dados de diferentes fontes. 7. Bibliografia e Documentação Oficial# RFC 5246 - The Transport Layer Security (TLS) Protocol Version 1.2 Elasticsearch Documentation Snort User Manual TCU - Manual de Auditoria de TI NIST Special Publication 800-53 (Security and Privacy Controls for Federal Information Systems and Organizations) "},{"id":40,"href":"/seguranca/5-multiplos-fatores-de-autenticacao-mfa-/","title":"5. Múltiplos Fatores de Autenticação (MFA)","section":"Segurança da Informação","content":"5. Múltiplos Fatores de Autenticação (MFA)# 1. Especificações Técnicas e Arquitetura# Múltiplos Fatores de Autenticação (MFA) é uma abordagem de segurança que requer que o usuário forneça dois ou mais fatores de verificação antes de obter acesso a um recurso. Os fatores são categorizados em algo que o usuário sabe (senha, PIN), algo que o usuário tem (token, smartphone), e algo que o usuário é (biometria).\n2. Detalhamento Técnico Avançado (Deep Dive)# Conceitos Técnicos Aprofundados: MFA aumenta a segurança exigindo múltiplas formas de evidência para autenticar. Isso dificulta que atacantes obtenham acesso apenas com uma senha. Regras Operacionais, Limitações, Exceções: Alguns métodos de MFA, como SMS ou e-mails, são considerados menos seguros devido à possibilidade de interceptação. Métodos como tokens físicos ou biometria são preferidos. Boas Práticas: Utilizar MFA em todos os pontos de acesso críticos, especialmente em ambientes de nuvem e sistemas de administração pública. Modelos e Diagramas Conceituais: Não aplicável diretamente a MFA, mas importante entender a integração em sistemas de identidade e acesso. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts: Não aplicável diretamente a MFA, pois depende da solução específica (ex: AWS MFA setup via CLI). Protocolos e Regras: Importante entender os protocolos de autenticação como OAuth2 e OpenID Connect, que podem ser configurados para exigir MFA. Exemplos de Output/Logs: Logs de tentativas de acesso devem mostrar claramente se a autenticação MFA foi solicitada e se foi bem-sucedida. Contexto TCU: O uso de MFA é crucial para a segurança das informações e deve ser implementado em todos os sistemas críticos, conforme as melhores práticas de segurança da informação. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar o entendimento dos tipos de fatores de autenticação, suas aplicações e limitações. É comum haver questões que testem o conhecimento sobre a eficácia relativa dos diferentes métodos de MFA e sobre as políticas de segurança recomendadas.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova N/A N/A MFA não se aplica diretamente a comandos ou regras específicas, mas ao entendimento de sua implementação e melhores práticas. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# ( ) A autenticação multifator (MFA) é menos segura que a autenticação baseada em senha única, pois introduz mais vetores de ataque.\nResposta: Errado. MFA aumenta a segurança ao exigir múltiplas evidências de identidade. ( ) O uso de SMS como um dos fatores em um sistema MFA é considerado o método mais seguro devido à sua conveniência e facilidade de uso.\nResposta: Errado. SMS é considerado menos seguro devido à possibilidade de interceptação ou sim swap. ( ) Implementar MFA em sistemas críticos é uma recomendação de segurança, mas não é obrigatório segundo as diretrizes de segurança da informação do TCU.\nResposta: Errado. Embora a afirmação específica sobre a obrigatoriedade possa variar, é amplamente reconhecido e recomendado que MFA seja implementado em sistemas críticos para aumentar a segurança. ( ) Tokens de hardware são um exemplo de algo que o usuário tem, um dos possíveis fatores em uma configuração MFA.\nResposta: Certo. Tokens de hardware são um fator de posse comum em MFA. ( ) A biometria é considerada um método de autenticação de fator único e não pode ser utilizada em sistemas de MFA.\nResposta: Errado. A biometria é um exemplo de algo que o usuário é, e pode ser usada como um dos fatores em MFA. 7. Bibliografia e Documentação Oficial# RFC 8176: Authentication Method Reference Values NIST Special Publication 800-63B: Digital Identity Guidelines AWS Documentation on MFA: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html Microsoft Azure MFA Documentation: https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks Este material foi preparado com foco na precisão técnica e relevância para o contexto de concursos públicos, especialmente aqueles organizados pela CEBRASPE, com ênfase em Segurança da Informação e, mais especificamente, em Múltiplos Fatores de Autenticação (MFA).\n"},{"id":41,"href":"/seguranca/4-controles-e-testes/","title":"4. Controles e testes","section":"Segurança da Informação","content":"4. Controles e testes# 1. Especificações Técnicas e Arquitetura# Resumo direto da tecnologia/norma# Segurança para aplicações Web e Web Services envolve a implementação de medidas para proteger sistemas web contra vulnerabilidades e ataques, englobando aspectos como autenticação, autorização, gestão de sessões, validação de entrada, e criptografia.\nComponentes principais e interconexões# Firewalls de Aplicação Web (WAF): Protegem aplicações web filtrando e monitorando o tráfego HTTP entre a aplicação e a Internet. TLS/SSL: Protocolos para criptografar a comunicação entre o cliente e o servidor, protegendo a integridade e a confidencialidade dos dados. OWASP Top 10: Lista das 10 principais vulnerabilidades em aplicações web, servindo como um guia para segurança de aplicações. Conceitos fundamentais# Validação de Entrada: Processo de verificar se a entrada dos usuários é válida antes de processá-la. Autenticação e Autorização: Verificação da identidade do usuário e controle de acesso aos recursos. Gestão de Sessões: Manutenção do estado do usuário através de múltiplas requisições. 2. Detalhamento Técnico Avançado (Deep Dive)# Conceitos técnicos aprofundados# Cross-Site Scripting (XSS): Ataque que injeta scripts maliciosos em páginas web vistas por outros usuários. SQL Injection: Ataque que explora vulnerabilidades de validação de entrada para executar comandos SQL maliciosos. Regras operacionais, limitações, exceções e edge cases# Content Security Policy (CSP): Política de segurança que ajuda a detectar e mitigar ataques XSS. Same-Origin Policy (SOP): Política de segurança que restringe como documentos ou scripts carregados de uma origem podem interagir com recursos de outra origem. Boas práticas e padrões aplicáveis# HTTPS em todo o site: Utilizar HTTPS para proteger todas as páginas do site, não apenas as que lidam com informações sensíveis. Utilização de headers de segurança: Como Strict-Transport-Security, X-Content-Type-Options, X-Frame-Options, e X-XSS-Protection. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# # Forçar HTTPS através do .htaccess RewriteEngine On RewriteCond %{HTTPS} off RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [L,R=301]Protocolos e Regras# Handshake TLS: Processo pelo qual duas partes estabelecem comunicação usando TLS, envolvendo a troca de certificados e a geração de chaves de sessão. Exemplos de Output/Logs# # Exemplo de log de tentativa de SQL Injection \u0026#39; UNION SELECT username, password FROM users--Contexto TCU# A fiscalização de segurança em aplicações Web e Web Services pelo TCU pode envolver a verificação da implementação de práticas recomendadas pela OWASP, o uso de HTTPS em todo o site, e a presença de WAFs.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# Como a banca costuma cobrar# A CEBRASPE enfatiza a aplicação de conceitos de segurança em cenários práticos, como a configuração de headers de segurança ou a implementação de políticas CSP. Dicas de prova# Atenção para questões que misturam conceitos de segurança de rede com segurança de aplicações web, como a diferença entre firewalls de rede e WAFs. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante RewriteCond %{HTTPS} off Força o uso de HTTPS Uso comum em .htaccess Content-Security-Policy Define políticas de segurança Mitiga ataques XSS X-Frame-Options: DENY Previne clickjacking Header de segurança 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) A política Same-Origin Policy permite que scripts carregados de uma origem acessem recursos de qualquer outra origem sem restrições.\nErrado. A SOP restringe como documentos ou scripts de uma origem podem interagir com recursos de outra origem. (Certo ou Errado) O uso exclusivo de HTTPS em um site garante a proteção contra todos os tipos de ataques de injeção SQL.\nErrado. HTTPS protege a integridade e a confidencialidade dos dados em trânsito, mas não previne ataques de injeção SQL, que são mitigados por validação de entrada e parametrização de consultas. (Certo ou Errado) Configurar o header X-Content-Type-Options para nosniff ajuda a prevenir ataques baseados em MIME type sniffing.\nCerto. Este header instrui o navegador a não tentar deduzir o MIME type, o que pode ajudar a prevenir certos tipos de ataques. (Certo ou Errado) A implementação de uma Content Security Policy (CSP) é suficiente para garantir a segurança de uma aplicação web contra qualquer tipo de ataque XSS.\nErrado. Embora a CSP seja uma ferramenta poderosa contra XSS, sua eficácia depende da correta configuração e da complementação com outras medidas de segurança. (Certo ou Errado) Utilizar cookies com a flag Secure é uma prática recomendada para garantir que o cookie seja enviado apenas em requisições HTTPS.\nCerto. A flag Secure nos cookies assegura que eles sejam transmitidos apenas através de conexões seguras (HTTPS). 7. Bibliografia e Documentação Oficial# OWASP Top 10: https://owasp.org/www-project-top-ten/ RFC 5246 (The Transport Layer Security (TLS) Protocol Version 1.2): https://tools.ietf.org/html/rfc5246 Content Security Policy (CSP): https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP Same-Origin Policy: https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy "},{"id":42,"href":"/seguranca/3-malware/","title":"3. Malware","section":"Segurança da Informação","content":"3. Malware# 1. Especificações Técnicas e Arquitetura# Malwares são softwares maliciosos projetados para infiltrar, danificar ou realizar ações não autorizadas em sistemas de computador. Eles variam desde vírus, worms, trojans, keyloggers, spyware, adware, rootkits, ransomware até malwares fileless. Cada tipo possui características e métodos de ataque distintos, mas todos compartilham o objetivo comum de comprometer a integridade, confidencialidade ou disponibilidade dos recursos de TI.\n2. Detalhamento Técnico Avançado (Deep Dive)# Vírus: Programa que se replica e se espalha inserindo cópias de si mesmo em outros programas ou documentos. Worms: Similar ao vírus, mas se propaga automaticamente através de redes, explorando vulnerabilidades. Trojan (Cavalo de Troia): Disfarça-se como software legítimo para ganhar acesso ao sistema. Spyware: Projetado para coletar informações do sistema ou usuário sem consentimento. Keylogger: Captura e registra as teclas digitadas pelo usuário. Backdoor: Fornece acesso remoto ao sistema, contornando os mecanismos de segurança normais. Rootkit: Conjunto de ferramentas que esconde a presença do malware e dá controle remoto ao atacante. Adware: Exibe publicidade indesejada ao usuário, muitas vezes acompanhada de spyware. Ransomware: Criptografa os dados do usuário, exigindo pagamento para a descriptografia. Fileless Malware: Utiliza ferramentas e processos legítimos do sistema para executar atividades maliciosas sem escrever arquivos no disco. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts: Não aplicável diretamente, pois o foco é prevenir a execução de malware. Ferramentas como antivírus e EDRs (Endpoint Detection and Response) são essenciais. Protocolos e Regras: Implementação de políticas de segurança, como o princípio de menor privilégio e segmentação de rede, pode limitar a propagação de malware. Exemplos de Output/Logs: Monitoramento de logs de sistemas e aplicações para detecção de atividades suspeitas que podem indicar a presença de malware. Contexto TCU: Avaliação de controles internos e políticas de segurança para prevenir e detectar a presença de malware em sistemas governamentais. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das diferenças entre os tipos de malware e suas características operacionais. Uma pegadinha comum é confundir as funções de um trojan com as de um worm, por exemplo, ou não reconhecer que um keylogger é uma forma de spyware.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica Vírus Auto-replicação em outros programas Requer ação do usuário para se propagar Worms Propagação automática através de redes Explora vulnerabilidades sem interação humana Trojan Disfarce como software legítimo Não se replica, mas abre brechas de segurança Spyware Coleta informações sem consentimento Pode ser combinado com adware Keylogger Registra teclas digitadas Forma de spyware Backdoor Acesso remoto oculto Contorno de segurança Rootkit Oculta atividades maliciosas Difícil detecção e remoção Adware Exibe publicidade indesejada Frequentemente vem com spyware Ransomware Criptografa dados para resgate Backup regular é medida preventiva crítica Fileless Malware Usa ferramentas do sistema para ataque Não deixa arquivos no disco 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) Um rootkit é um tipo de malware que, ao infectar um sistema, se propaga automaticamente através de e-mails para outros sistemas.\nErrado. Rootkits são projetados para ocultar a presença de malware e não se propagam automaticamente por e-mail. (Certo ou Errado) Ransomware é um tipo de malware que exige pagamento para não divulgar informações sensíveis coletadas do sistema infectado.\nErrado. Ransomware criptografa os dados do usuário e exige pagamento para a descriptografia, não para evitar divulgação de informações. (Certo ou Errado) Spyware e adware são essencialmente o mesmo tipo de malware, com a única diferença sendo a intenção do atacante.\nErrado. Spyware é projetado para coletar informações, enquanto adware exibe publicidade indesejada. Embora possam estar relacionados, têm propósitos distintos. (Certo ou Errado) Worms necessitam de uma ação do usuário, como abrir um anexo de e-mail, para se propagar.\nErrado. Worms se propagam automaticamente, explorando vulnerabilidades de rede, sem necessidade de ação do usuário. (Certo ou Errado) Fileless malware é mais difícil de detectar e remover porque utiliza ferramentas e processos legítimos do sistema para executar suas atividades maliciosas.\nCerto. Por não deixar arquivos no disco e usar ferramentas legítimas, o fileless malware é mais desafiador para sistemas de detecção tradicionais. 7. Bibliografia e Documentação Oficial# RFCs: Não aplicável especificamente a malwares. Docs (Microsoft, Oracle, AWS): Documentação de segurança e melhores práticas para prevenção contra malware. Manuais do TCU/NBASP: Normativos sobre gestão de TI e segurança da informação que abordam políticas de prevenção contra malwares em ambientes governamentais. Este material é um ponto de partida para aprofundamento em segurança da informação, com foco em malwares, e deve ser complementado com estudos de casos reais e documentação técnica específica.\n"},{"id":43,"href":"/seguranca/2-privacidade-e-seguranca-por-padrao/","title":"2. Privacidade e segurança por padrão","section":"Segurança da Informação","content":"2. Privacidade e segurança por padrão# 1. Especificações Técnicas e Arquitetura# Privacy by Design e Privacy by Default são conceitos fundamentais na proteção de dados pessoais, exigindo que a privacidade seja considerada em todas as etapas do desenvolvimento de sistemas e processos. Privacy by Design refere-se à inclusão da privacidade no design e arquitetura de sistemas e processos, enquanto Privacy by Default significa que as configurações padrão de sistemas e serviços devem ser as mais privativas possíveis, sem que o usuário tenha que fazer ajustes para proteger sua privacidade.\n2. Detalhamento Técnico Avançado (Deep Dive)# Privacy by Design envolve sete princípios fundamentais: ser proativo e não reativo; privacidade como configuração padrão; privacidade incorporada no design; funcionalidade total (soma positiva, não soma zero); segurança de ponta a ponta (proteção total do ciclo de vida dos dados); visibilidade e transparência; e respeito pela privacidade do usuário. Privacy by Default requer que apenas os dados pessoais necessários para a realização do propósito específico sejam coletados e processados, limitando o acesso a esses dados ao mínimo necessário. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Não aplicável diretamente, pois Privacy by Design/Default são mais conceituais e estratégicos do que técnicos. No entanto, implementações podem incluir configurações de privacidade em sistemas de TI, como:\nConfigurações de Firewall: Restringir acessos não autorizados. Protocolos e Regras: Aplicação de HTTPS, utilização de VPNs para garantir a segurança e privacidade dos dados em trânsito. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar a compreensão dos princípios de Privacy by Design e Privacy by Default, exigindo que o candidato identifique se uma determinada prática está alinhada a esses conceitos. Uma pegadinha comum é apresentar uma situação onde a privacidade é adicionada como uma camada posterior ao desenvolvimento, contradizendo o princípio de que a privacidade deve ser considerada desde o início do design do sistema.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica Configuração de privacidade padrão Garante que as configurações iniciais de um sistema promovam a máxima privacidade Essencial para cumprir o princípio de Privacy by Default Avaliação de Impacto à Proteção de Dados (DPIA) Avalia os riscos para a privacidade antes do lançamento de um novo produto ou serviço Ferramenta chave para Privacy by Design 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) Privacy by Design requer que a privacidade seja um adicional opcional em sistemas e processos.\nErrado. Privacy by Design exige que a privacidade seja integrada ao design e arquitetura desde o início. (Certo ou Errado) Privacy by Default significa que as configurações de privacidade de um sistema devem ser ajustadas pelo usuário para garantir a proteção de seus dados.\nErrado. Privacy by Default assegura que as configurações padrão sejam as mais restritivas em termos de privacidade, sem necessidade de ajustes pelo usuário. (Certo ou Errado) Uma Avaliação de Impacto à Proteção de Dados (DPIA) é uma ferramenta recomendada para implementar o princípio de Privacy by Design.\nCerto. A DPIA ajuda a identificar e mitigar riscos de privacidade desde o início do desenvolvimento de um projeto. (Certo ou Errado) A coleta de dados pessoais em excesso, além do necessário para o propósito declarado, está em conformidade com o princípio de Privacy by Default.\nErrado. Privacy by Default exige a coleta e processamento apenas dos dados estritamente necessários para o propósito especificado. (Certo ou Errado) Implementar criptografia de ponta a ponta em um sistema de comunicação é uma prática alinhada ao princípio de segurança de ponta a ponta do Privacy by Design.\nCerto. A criptografia de ponta a ponta protege os dados durante todo o seu ciclo de vida, alinhando-se ao princípio de segurança de ponta a ponta. 7. Bibliografia e Documentação Oficial# RFCs: RFC 6973 - Privacy Considerations for Internet Protocols Docs: NIST Privacy Framework Manuais do TCU/NBASP: TCU - Governança de Tecnologia da Informação "},{"id":44,"href":"/seguranca/1-gestao-de-identidades-e-acesso/","title":"1. Gestão de Identidades e Acesso","section":"Segurança da Informação","content":"1. Gestão de Identidades e Acesso# 1. Especificações Técnicas e Arquitetura# A gestão de identidades e acesso (IAM - Identity and Access Management) é um framework de políticas e tecnologias que garante que as pessoas certas tenham o acesso apropriado aos recursos tecnológicos dentro de uma organização. Principais componentes incluem:\nAutenticação: Processo de verificação da identidade do usuário. Autorização: Processo de conceder ou negar direitos a um recurso. SSO (Single Sign-On): Permite aos usuários acessar múltiplos sistemas com uma única identificação. SAML (Security Assertion Markup Language): Padrão para troca de autenticação e autorização entre diferentes domínios. OAuth2: Framework de autorização que permite aplicações obterem acesso limitado a contas de usuários. OpenID Connect: Camada de identidade construída em cima do OAuth2, adicionando autenticação. 2. Detalhamento Técnico Avançado (Deep Dive)# OAuth2 opera através de um fluxo de autorização onde o cliente solicita um token de acesso ao servidor de autorização, representando o consentimento do usuário. Este token é então usado para acessar recursos no servidor de recursos. SAML é baseado em XML para troca de informações de autenticação e autorização, frequentemente usado em SSO para permitir login cruzado entre diferentes sistemas. OpenID Connect é um protocolo de autenticação simples em cima do OAuth2, adicionando a camada de identidade através de um ID Token. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# OAuth2: # Solicitação de token de acesso OAuth2 curl -X POST https://servidor-autorizacao.com/oauth/token \\ -H \u0026#34;Content-Type: application/x-www-form-urlencoded\u0026#34; \\ -d \u0026#34;grant_type=client_credentials\u0026amp;client_id=CLIENT_ID\u0026amp;client_secret=CLIENT_SECRET\u0026#34; Protocolos e Regras# Fluxo de Autenticação OAuth2: O aplicativo solicita autorização ao usuário. O usuário concede autorização. O aplicativo recebe um código de autorização. O aplicativo solicita um token de acesso usando o código de autorização. O servidor de autorização envia o token de acesso ao aplicativo. O aplicativo usa o token de acesso para acessar a API protegida. Contexto TCU# Na fiscalização ou administração pública, a implementação de SSO, SAML, OAuth2 e OpenID Connect deve seguir rigorosamente as políticas de segurança da informação e privacidade, garantindo que apenas usuários autorizados tenham acesso a informações sensíveis e sistemas críticos.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão detalhada dos fluxos de autenticação e autorização, especialmente diferenças sutis entre OAuth2 e OpenID Connect. Uma pegadinha comum é confundir autenticação com autorização, ou não entender o papel do SAML em ambientes de SSO.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica OAuth2 Token Request Solicita token de acesso Usar client_credentials para apps SAML Assertion Troca de autenticação/autorização Baseado em XML, usado em SSO OpenID Connect ID Token Prova de autenticação Camada em cima do OAuth2 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# OAuth2 utiliza tokens de acesso para autenticar usuários diretamente nos recursos. (Errado, OAuth2 é usado para autorização, não autenticação direta) SAML é um protocolo baseado em JSON para autenticação e autorização. (Errado, SAML usa XML) OpenID Connect permite que um serviço de autenticação forneça informações de identidade através de um ID Token. (Certo) O fluxo de autorização implícita do OAuth2 é recomendado para aplicações web confidenciais. (Errado, o fluxo de autorização implícita é desaconselhado para aplicações confidenciais) Single Sign-On (SSO) pode ser implementado usando SAML para permitir acesso a múltiplos sistemas com uma única credencial de autenticação. (Certo) 7. Bibliografia e Documentação Oficial# OAuth 2.0 Framework: RFC 6749 Security Assertion Markup Language (SAML): SAML Wiki OpenID Connect: OpenID Foundation Este material foi elaborado com foco na precisão técnica e relevância para o contexto de concursos públicos, especialmente para cargos relacionados à TI no TCU, seguindo as diretrizes da banca CEBRASPE.\n"},{"id":45,"href":"/software/8-desenvolvimento-seguro/","title":"8. Desenvolvimento seguro","section":"Engenharia de Software","content":"8. Desenvolvimento Seguro# 1. Especificações Técnicas e Arquitetura# DevSecOps integra práticas de segurança em todas as fases do ciclo de desenvolvimento de software, desde a concepção até a entrega e manutenção, com o objetivo de automatizar e integrar as verificações de segurança de forma contínua. Componentes principais incluem: Integração Contínua (CI), Entrega Contínua (CD), automação de testes de segurança, e monitoramento em tempo real.\n2. Detalhamento Técnico Avançado (Deep Dive)# Conceitos técnicos aprofundados: Em DevSecOps, a segurança é tratada como código, usando políticas como código para automatizar a aplicação de controles de segurança em infraestrutura e aplicações. Regras operacionais, limitações, exceções e edge cases: A implementação de DevSecOps pode ser limitada pela cultura organizacional, pela falta de ferramentas integradas em todas as fases do ciclo de vida do desenvolvimento e pela necessidade de treinamento especializado. Boas práticas e padrões aplicáveis ao contexto de TI e TCU: Utilização de scanners de vulnerabilidades, testes de penetração automatizados, revisão de código automatizada e integração de ferramentas de segurança no pipeline de CI/CD. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# # Exemplo de comando para integrar scanner de vulnerabilidade no pipeline CI pipeline: scan: image: owasp/zap2docker-stable script: - zap-baseline.py -t http://seuwebsite.com -r relatorio.html Protocolos e Regras: A implementação de DevSecOps deve seguir o princípio de \u0026ldquo;segurança por design\u0026rdquo;, garantindo que as considerações de segurança sejam integradas desde o início do desenvolvimento. Exemplos de Output/Logs: O output de um scanner de vulnerabilidade pode incluir a identificação de vulnerabilidades conhecidas, com recomendações para mitigação. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar a compreensão de como a segurança é integrada ao ciclo de vida do desenvolvimento de software em um contexto DevSecOps, incluindo a identificação de ferramentas específicas e a aplicação de políticas de segurança como código. Uma pegadinha comum é confundir a segurança aplicada em DevOps tradicional com a abordagem específica de DevSecOps, que enfatiza a segurança em todas as fases.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova zap-baseline.py Realiza scan de vulnerabilidades Importante para automação de testes de segurança em CI Políticas como código Aplica controles de segurança Fundamental em DevSecOps para integração de segurança Integração de ferramentas no pipeline CI/CD Automatiza testes de segurança Essencial para a prática de DevSecOps 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) A prática de DevSecOps exige que as verificações de segurança sejam realizadas manualmente para garantir a precisão dos resultados.\nErrado. DevSecOps enfatiza a automação das verificações de segurança. (Certo ou Errado) Em DevSecOps, é recomendável realizar testes de penetração apenas após a conclusão do desenvolvimento do software.\nErrado. DevSecOps integra testes de segurança, incluindo testes de penetração, ao longo do ciclo de vida do desenvolvimento. (Certo ou Errado) A utilização de políticas como código permite a aplicação automática de controles de segurança na infraestrutura e nas aplicações.\nCerto. Esta é uma prática fundamental em DevSecOps. (Certo ou Errado) A integração de ferramentas de segurança no pipeline de CI/CD é opcional em uma abordagem DevSecOps.\nErrado. A integração de ferramentas de segurança é um componente essencial do DevSecOps. (Certo ou Errado) DevSecOps pode ser implementado sem qualquer alteração na cultura organizacional ou nos processos existentes.\nErrado. DevSecOps geralmente requer mudanças significativas na cultura organizacional e nos processos. 7. Bibliografia e Documentação Oficial# OWASP ZAP: https://www.zaproxy.org/ Documentação oficial do Terraform sobre políticas como código: https://www.terraform.io/docs/cloud/sentinel/index.html Manual de Boas Práticas DevSecOps do TCU: (Link fictício, pois não existe um manual específico do TCU para DevSecOps, mas seria importante consultar documentos oficiais do TCU para práticas recomendadas em TI). Este material foi desenvolvido com foco na precisão técnica e relevância para o contexto do TCU e estilo de questões da CEBRASPE, visando preparar os candidatos para questões de alto nível técnico e compreensão detalhada de DevSecOps.\n"},{"id":46,"href":"/software/7-linguagens-de-programacao/","title":"7. Linguagens de programação","section":"Engenharia de Software","content":"7. Linguagens de Programação# 1. Especificações Técnicas e Arquitetura# Java é uma linguagem de programação orientada a objetos, projetada para ser portável em qualquer plataforma sem a necessidade de recompilação. Os programas Java são compilados para bytecode, que pode ser executado em qualquer máquina virtual Java (JVM), independentemente da arquitetura do hardware subjacente.\nComponentes Principais:# JVM (Java Virtual Machine): Responsável por executar o bytecode Java. JRE (Java Runtime Environment): Inclui a JVM e as bibliotecas de classes Java necessárias para executar programas Java. JDK (Java Development Kit): Contém o JRE e as ferramentas necessárias para desenvolver programas Java, como o compilador javac. Conceitos Fundamentais:# Portabilidade: Graças à JVM, o código Java pode ser executado em qualquer dispositivo que possua uma JVM compatível. Gerenciamento de Memória Automático: Java realiza coleta de lixo, o que ajuda a prevenir vazamentos de memória e outros problemas relacionados. 2. Detalhamento Técnico Avançado (Deep Dive)# Java é fortemente tipado, suporta tanto programação orientada a objetos quanto funcional. A partir do Java 8, introduziu-se o conceito de expressões lambda e interfaces funcionais, ampliando suas capacidades para suportar programação funcional.\nRegras Operacionais:# Tratamento de Exceções: Java exige que as exceções verificadas sejam capturadas ou declaradas no método que as lança. Sobrecarga e Sobreposição de Métodos: Java permite a sobrecarga de métodos na mesma classe e a sobreposição de métodos em subclasses. Boas Práticas:# Uso de Generics: Para criar classes, interfaces e métodos com tipos de dados genéricos. Padrões de Projeto: Utilização de padrões como Singleton, Factory, e Observer para resolver problemas comuns de design. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:# // Exemplo de Hello World em Java public class HelloWorld { public static void main(String[] args) { System.out.println(\u0026#34;Hello, World!\u0026#34;); } }Protocolos e Regras:# Encapsulamento: Proteger os dados de uma classe usando modificadores de acesso como private, protected, e public. Herança: Java suporta herança simples, permitindo que uma classe herde métodos e atributos de apenas uma superclasse. Exemplos de Output/Logs:# Ao executar o programa HelloWorld, a saída esperada é:\nHello, World!4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar o entendimento de conceitos de orientação a objetos em Java, como encapsulamento, herança e polimorfismo. Uma pegadinha comum é confundir sobrecarga de métodos (ocorre na mesma classe) com sobreposição (ocorre em classes na hierarquia de herança).\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova public static void main(String[] args) Ponto de entrada de um programa Java. A assinatura exata é frequentemente cobrada. System.out.println() Imprime uma mensagem na saída padrão. Útil para debug ou feedback do programa. Modificadores de Acesso Controlam o acesso a classes, métodos e variáveis. private, protected, public têm significados específicos. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# Em Java, o método main pode ser sobrecarregado para suportar diferentes assinaturas. (Certo) Java suporta herança múltipla de classes. (Errado) A partir do Java 8, é possível usar expressões lambda para implementar interfaces que possuem apenas um método abstrato. (Certo) Em Java, todos os métodos de uma interface são abstract por padrão, e não podem ter implementação. (Errado) A coleta de lixo em Java garante que o programa nunca sofrerá com vazamento de memória. (Errado) Gabarito Comentado:# Certo. Embora o método main específico (public static void main(String[] args)) seja o ponto de entrada de um programa Java, nada impede que métodos main sejam sobrecarregados com diferentes assinaturas para testes ou outros propósitos. Errado. Java não suporta herança múltipla de classes para evitar a ambiguidade e a complexidade. No entanto, uma classe pode implementar múltiplas interfaces. Certo. Expressões lambda foram introduzidas no Java 8, permitindo uma implementação mais limpa e concisa de interfaces funcionais. Errado. A partir do Java 8, interfaces podem conter métodos default e static com implementação. Errado. Embora a coleta de lixo ajude a gerenciar a memória, não elimina completamente a possibilidade de vazamentos de memória, especialmente em casos de referências circulares ou uso inadequado de coleções. 7. Bibliografia e Documentação Oficial# The Java® Language Specification Java Platform, Standard Edition \u0026amp; Java Development Kit Version 17 API Specification Effective Java, 3rd Edition, by Joshua Bloch "},{"id":47,"href":"/software/6-testes-e-qualidade-de-codigo/","title":"6. Testes e Qualidade de Código","section":"Engenharia de Software","content":"6. Testes e Qualidade de Código# 1. Especificações Técnicas e Arquitetura# Testes automatizados são essenciais para garantir a qualidade, eficiência e confiabilidade do código em projetos de software. Eles se dividem em três categorias principais: unitários, de integração e de contrato. A análise estática, por sua vez, é realizada por ferramentas como o SonarQube, que avalia o código-fonte para identificar vulnerabilidades, bugs e problemas de estilo de codificação.\nTestes Unitários: Focam em verificar a menor parte testável de um aplicativo, como funções ou métodos, isoladamente. Testes de Integração: Verificam a interação entre diferentes módulos ou serviços para garantir que funcionem juntos conforme esperado. Testes de Contrato: Asseguram que a comunicação entre diferentes sistemas (por exemplo, APIs) respeita um contrato previamente definido. Análise Estática (SonarQube): Ferramenta que analisa o código-fonte para detectar vulnerabilidades, bugs e code smells, promovendo a qualidade do código. 2. Detalhamento Técnico Avançado (Deep Dive)# Testes Automatizados# Isolamento: Fundamental para testes unitários, onde mocks e stubs são utilizados para simular dependências. Integração Contínua (CI): Testes automatizados devem ser integrados ao pipeline de CI para garantir que o código seja testado automaticamente a cada commit. Cobertura de Código: Importante métrica que indica a porcentagem do código fonte testada pelos testes automatizados. Análise Estática com SonarQube# Quality Gates: Conjunto de condições que o código deve atender para ser considerado como passível de deploy. Regras de Codificação: Personalizáveis, permitem definir padrões específicos de qualidade e segurança que o código deve seguir. Integração com CI: SonarQube pode ser integrado ao pipeline de CI para análise contínua. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Exemplo de Teste Unitário com JUnit (Java):\nimport static org.junit.Assert.assertEquals; import org.junit.Test; public class CalculadoraTest { @Test public void testSoma() { Calculadora calc = new Calculadora(); assertEquals(5, calc.soma(2,3)); } }Configuração SonarQube no Pipeline CI (YAML para Jenkins):\npipeline { stages { stage(\u0026#39;SonarQube analysis\u0026#39;) { steps { withSonarQubeEnv(\u0026#39;SonarQube\u0026#39;) { sh \u0026#39;mvn clean verify sonar:sonar\u0026#39; } } } } }Contexto TCU# No TCU, a implementação de testes automatizados e análise estática do código pode ser utilizada para garantir a qualidade e segurança das aplicações desenvolvidas internamente ou por terceiros. A adesão a essas práticas está alinhada com as diretrizes de governança de TI e pode ser um critério de auditoria para avaliar a maturidade dos processos de desenvolvimento de software.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão da aplicabilidade e das diferenças entre os tipos de testes automatizados, além de detalhes sobre configuração e uso do SonarQube. Uma pegadinha comum é afirmar que testes de integração substituem a necessidade de testes unitários, o que é incorreto, pois cada tipo de teste tem seu propósito específico. Outra nuance é a interpretação de métricas de cobertura de código; uma alta cobertura não necessariamente indica um código livre de defeitos. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante Testes Unitários Testa partes isoladas do código Não substitui outros testes Testes de Integração Testa a interação entre módulos Requer ambiente similar ao de produção Testes de Contrato Verifica a aderência a contratos de API Importante para microserviços SonarQube Análise estática do código Integração com CI é crucial 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) Testes de integração são executados em um ambiente isolado para testar individualmente cada função do sistema. (Certo ou Errado) SonarQube pode ser configurado para bloquear a integração de código que não atenda a critérios específicos de qualidade definidos nos Quality Gates. (Certo ou Errado) Testes unitários são suficientes para garantir que o sistema como um todo está funcionando corretamente. (Certo ou Errado) A análise estática do código com SonarQube substitui a necessidade de testes manuais. (Certo ou Errado) Testes de contrato asseguram que as interfaces de comunicação entre diferentes sistemas permaneçam consistentes ao longo do tempo. Gabarito:\nErrado. Testes de integração não são executados em um ambiente isolado para testar funções individualmente; isso descreve testes unitários. Testes de integração verificam a interação entre módulos ou serviços. Certo. SonarQube pode ser configurado com Quality Gates que impedem a integração de código que não atenda a critérios específicos de qualidade. Errado. Testes unitários focam em partes isoladas do código. Para garantir o funcionamento do sistema como um todo, são necessários outros tipos de testes, como os de integração. Errado. A análise estática do código com SonarQube é uma ferramenta poderosa para melhorar a qualidade do código, mas não substitui testes manuais, que podem identificar problemas de usabilidade e outros que a análise estática não detecta. Certo. Testes de contrato verificam a aderência a contratos de API, assegurando que as interfaces de comunicação entre diferentes sistemas permaneçam consistentes. 7. Bibliografia e Documentação Oficial# JUnit 5 User Guide: https://junit.org/junit5/docs/current/user-guide/ SonarQube Documentation: https://docs.sonarqube.org/latest/ Martin Fowler on Continuous Integration: https://martinfowler.com/articles/continuousIntegration.html ISTQB® Glossary of Testing Terms: https://www.istqb.org/glossary.html "},{"id":48,"href":"/software/5-devops-e-ci-cd/","title":"5. DevOps e CI/CD","section":"Engenharia de Software","content":"5. DevOps e CI/CD# 1. Especificações Técnicas e Arquitetura# DevOps é uma abordagem que combina práticas de desenvolvimento de software (Dev) com operações de TI (Ops) para encurtar o ciclo de vida do desenvolvimento de sistemas e fornecer entrega contínua com alta qualidade de software. CI/CD, parte integral do DevOps, refere-se à integração contínua (CI) e entrega ou implantação contínua (CD), facilitando a automação nos estágios de desenvolvimento de software.\nGitHub Actions: Permite a automação de workflows dentro do repositório GitHub, facilitando a CI/CD. Docker/Kubernetes: Docker é uma plataforma de contêineres que permite empacotar aplicações em contêineres, enquanto Kubernetes é um orquestrador de contêineres para gerenciar aplicações em contêineres em larga escala. Monitoramento (Grafana, New Relic): Grafana é uma ferramenta de visualização e análise que permite monitorar e visualizar métricas. New Relic é uma plataforma de observabilidade que oferece análise em tempo real de performance de aplicações. 2. Detalhamento Técnico Avançado (Deep Dive)# GitHub Actions: Utiliza arquivos YAML para definir o workflow de CI/CD. O arquivo .github/workflows/main.yml pode conter definições para build, teste, e deploy. Docker: Utiliza o Dockerfile para definir o ambiente de uma aplicação. Comandos como docker build e docker run são usados para criar e rodar contêineres. Kubernetes: Utiliza manifestos YAML para definir o estado desejado de aplicações em contêineres. Comandos como kubectl apply são usados para aplicar esses manifestos. Grafana/New Relic: Configuração de dashboards em Grafana requer conexão com fontes de dados e definição de queries para visualização. New Relic oferece agentes que são instalados nas aplicações para coletar métricas. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# # Exemplo de GitHub Actions para CI/CD name: CI/CD Pipeline on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Build Docker image run: docker build . --tag my-application:$(date +%s) - name: Deploy to Kubernetes run: kubectl apply -f k8s/# Exemplo de Dockerfile FROM python:3.8-slim COPY . /app WORKDIR /app RUN pip install -r requirements.txt CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;]# Comando para criar um dashboard no Grafana via API curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{ \u0026#34;dashboard\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Performance\u0026#34;, \u0026#34;panels\u0026#34;: [...] } }\u0026#39; http://GRAFANA_HOST/api/dashboards/db4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A banca CEBRASPE pode cobrar a sintaxe exata dos arquivos de configuração do GitHub Actions e Dockerfile, além de comandos específicos do kubectl para Kubernetes. Uma pegadinha comum é confundir as responsabilidades e funcionalidades entre Docker e Kubernetes, ou entre as ferramentas de monitoramento Grafana e New Relic. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova actions/checkout@v2 Checa o repositório Git Essencial para iniciar qualquer workflow no GitHub Actions docker build . --tag my-app Constrói uma imagem Docker Tag é crucial para versionamento e deploy kubectl apply -f k8s/ Aplica configurações no Kubernetes Diretório k8s/ deve conter manifestos YAML válidos Grafana API Cria dashboards via API Requer autenticação e conhecimento da API 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (C) No GitHub Actions, é possível definir workflows dependentes que só são executados após a conclusão bem-sucedida de outros. (E) Docker e Kubernetes são tecnologias mutuamente exclusivas e não podem ser utilizadas em conjunto para gerenciamento de contêineres. (C) Grafana pode ser utilizado para visualizar métricas coletadas tanto por agentes do New Relic quanto por outras fontes de dados, como Prometheus. (E) Arquivos de configuração do Kubernetes não suportam a definição de políticas de auto-scaling para as aplicações. (C) GitHub Actions suporta a execução de jobs em ambientes Windows, Linux e macOS. 7. Bibliografia e Documentação Oficial# GitHub Actions Documentation: https://docs.github.com/en/actions Docker Documentation: https://docs.docker.com/ Kubernetes Documentation: https://kubernetes.io/docs/ Grafana Documentation: https://grafana.com/docs/ New Relic Documentation: https://docs.newrelic.com/ "},{"id":49,"href":"/software/4-persistencia-de-dados/","title":"4. Persistência de Dados","section":"Engenharia de Software","content":"4. Persistência de Dados# 1. Especificações Técnicas e Arquitetura# Persistência de dados refere-se à capacidade de um sistema de manter os dados além da execução do programa, permitindo que esses dados sejam recuperados e utilizados por outras execuções ou sistemas. A persistência pode ser alcançada através de diversos mecanismos e tecnologias, como sistemas de gerenciamento de banco de dados relacional (RDBMS) e NoSQL.\nModelagem Relacional e Normalização# Componentes Principais: Tabelas, colunas, linhas, chaves primárias e chaves estrangeiras. Conceitos Fundamentais: A modelagem relacional baseia-se na teoria matemática de conjuntos e na lógica de predicados. A normalização é um processo para reduzir a redundância e dependência em bancos de dados relacionais, dividido em formas normais (1FN, 2FN, 3FN, etc.). NoSQL (MongoDB, ElasticSearch)# Componentes Principais: Documentos (MongoDB), Índices (ElasticSearch). Conceitos Fundamentais: NoSQL abrange uma ampla gama de tecnologias projetadas para lidar com volumes de dados vastos, estruturas de dados variáveis e necessidades de escalabilidade e desempenho que não são bem atendidas pelos modelos relacionais. Versionamento de Esquemas# Conceitos Fundamentais: O versionamento de esquemas é a prática de gerenciar mudanças nos esquemas de banco de dados, permitindo atualizações seguras e compatibilidade entre diferentes versões de um sistema. 2. Detalhamento Técnico Avançado (Deep Dive)# Normalização# 1FN: Garante que cada coluna contenha valores atômicos, sem repetições de grupos de colunas. 2FN: Além da 1FN, garante que todos os atributos não-chave sejam dependentes da chave primária inteira. 3FN: Além da 2FN, garante que não existam dependências transitivas entre atributos não-chave. NoSQL# MongoDB: Utiliza um modelo baseado em documentos, onde cada documento é um objeto JSON. ElasticSearch: Baseado em índices invertidos, otimizado para buscas rápidas em grandes volumes de dados. Versionamento de Esquemas# Boas Práticas: Utilizar migrações automatizadas, manter versões de esquemas em repositório de controle de versão, testar mudanças de esquema em ambientes isolados antes da aplicação em produção. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# MongoDB:\n# Criar um novo documento db.collection.insertOne({nome: \u0026#34;João\u0026#34;, idade: 30}); # Buscar documentos db.collection.find({idade: {$gt: 25}});SQL Normalização:\n-- Criar tabelas normalizadas (1FN) CREATE TABLE Pessoa ( ID int NOT NULL PRIMARY KEY, Nome varchar(255) NOT NULL, Idade int );Protocolos e Regras# Normalização de Dados:\nA normalização segue um conjunto de regras para estruturar um banco de dados relacional de forma a reduzir a redundância e melhorar a integridade dos dados. NoSQL:\nMongoDB: Suporta operações CRUD (Create, Read, Update, Delete) utilizando a sintaxe de JavaScript. ElasticSearch: Utiliza uma API RESTful para operações de indexação e busca. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das diferenças fundamentais entre bancos de dados relacionais e NoSQL, bem como detalhes específicos da normalização. É comum haver questões que testam o entendimento das formas normais, exigindo a identificação de exemplos que estejam ou não em uma determinada forma normal.\nPegadinhas Comuns:# Confundir as características e usos de bancos de dados NoSQL com os relacionais. Erros na identificação de dependências funcionais e na aplicação das formas normais. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica db.collection.insertOne() Insere um documento no MongoDB Útil para adição rápida de dados CREATE TABLE Cria uma tabela em SQL Base para normalização e estruturação de dados 1FN, 2FN, 3FN Regras de normalização Essencial para design eficiente de DB Queries ElasticSearch Busca e indexação de dados Alta performance em busca de texto 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# Certo ou Errado? Em MongoDB, o comando db.collection.findOne({idade: {$gt: 25}}); retorna o primeiro documento que satisfaz a condição.\nCerto. Este comando busca o primeiro documento na coleção onde a idade é maior que 25. Certo ou Errado? Uma tabela está na 2FN se todos os atributos não-chave são dependentes da chave primária inteira, mas pode conter dependências transitivas.\nErrado. A definição está parcialmente correta para a 2FN, mas a presença de dependências transitivas violaria a 3FN. Certo ou Errado? ElasticSearch utiliza SQL para realizar buscas e operações de indexação.\nErrado. ElasticSearch utiliza uma API RESTful e não SQL. Certo ou Errado? O versionamento de esquemas de banco de dados é uma prática recomendada para permitir a evolução do esquema sem interromper os serviços existentes.\nCerto. O versionamento de esquemas é crucial para a manutenção e evolução segura de aplicações. Certo ou Errado? A normalização até a 3FN é sempre recomendada para todos os bancos de dados, independentemente do contexto de aplicação.\nErrado. Embora a normalização melhore a integridade dos dados e reduza a redundância, em alguns casos, a desnormalização pode ser utilizada para otimizar o desempenho de leitura. 7. Bibliografia e Documentação Oficial# MongoDB Documentation: https://docs.mongodb.com/ ElasticSearch Documentation: https://www.elastic.co/guide/index.html Silberschatz, A., Korth, H.F., Sudarshan, S. \u0026ldquo;Sistema de Banco de Dados\u0026rdquo;. 6. ed. McGraw-Hill. Date, C.J. \u0026ldquo;Introdução a Sistemas de Bancos de Dados\u0026rdquo;. 8. ed. Campus. "},{"id":50,"href":"/software/3-apis-e-integracoes/","title":"3. APIs e Integrações","section":"Engenharia de Software","content":"3. APIs e Integrações# 1. Especificações Técnicas e Arquitetura# RESTful é um estilo arquitetônico para sistemas distribuídos, como a World Wide Web. As principais diretrizes incluem a utilização de métodos HTTP de forma explícita, a não manutenção de estado do cliente (stateless), e uma interface uniforme. O versionamento de APIs RESTful pode ser realizado através da URL, parâmetros de query, cabeçalhos HTTP ou no corpo da requisição.\nOAuth2 é um protocolo de autorização que permite a uma aplicação obter acesso limitado a um serviço HTTP em nome de um usuário. JWT (JSON Web Tokens) é um padrão aberto (RFC 7519) que define uma maneira compacta e independente de transmitir informações de forma segura entre as partes como um objeto JSON. OpenID Connect é uma camada de identidade construída em cima do OAuth2, permitindo autenticação.\n2. Detalhamento Técnico Avançado (Deep Dive)# RESTful APIs devem seguir princípios como a utilização de métodos HTTP (GET, POST, PUT, DELETE) de forma semântica, recursos identificados por URIs, e comunicação sem estado. O versionamento pode ser feito incluindo a versão na URI (/api/v1/resource) ou utilizando cabeçalhos HTTP customizados.\nOAuth2 utiliza fluxos de autorização como o Authorization Code, Implicit, Resource Owner Password Credentials, e Client Credentials, dependendo do cenário de uso. JWTs são usados em OAuth2 como tokens de acesso, permitindo a representação de afirmações entre duas partes. OpenID Connect adiciona uma camada de identidade, fornecendo um ID Token junto ao token de acesso.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# OAuth2 com JWT:\n# Obter token de acesso usando o fluxo de credenciais do cliente curl -X POST \u0026#34;https://authorization-server.com/token\u0026#34; \\ -H \u0026#34;Content-Type: application/x-www-form-urlencoded\u0026#34; \\ -d \u0026#34;grant_type=client_credentials\u0026amp;client_id=YOUR_CLIENT_ID\u0026amp;client_secret=YOUR_CLIENT_SECRET\u0026#34; # Resposta esperada: {\u0026#34;access_token\u0026#34;:\u0026#34;eyJ...\u0026#34;,\u0026#34;token_type\u0026#34;:\u0026#34;Bearer\u0026#34;,\u0026#34;expires_in\u0026#34;:3600}Versionamento de API RESTful:\nVia URI: /api/v1/resource Via cabeçalho HTTP: Accept: application/vnd.myapi.v1+json 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar o entendimento correto dos fluxos de autorização OAuth2 e a aplicação correta dos métodos HTTP em APIs RESTful. Uma pegadinha comum é confundir o fluxo de autorização adequado para um determinado cenário ou a utilização incorreta de status HTTP.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova GET /api/v1/resource Recupera um recurso Uso correto do método GET POST /api/resource Cria um novo recurso Uso correto do método POST OAuth2 Authorization Code Fluxo para apps confidenciais Adequado para servidores de aplicação JWT Representa afirmações entre duas partes Utilizado como token de acesso em OAuth2 OpenID Connect Adiciona autenticação ao OAuth2 Fornece ID Token junto ao token de acesso 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# O OAuth2 permite a emissão de tokens de acesso que podem ser utilizados para autenticar e autorizar usuários em diferentes serviços sem que as credenciais do usuário sejam compartilhadas. (Certo) Em uma API RESTful, o uso do método HTTP DELETE deve ser evitado por questões de segurança. (Errado) JWTs não podem ser utilizados como mecanismo de autenticação em APIs RESTful. (Errado) O versionamento de APIs RESTful deve ser feito exclusivamente através da URL para garantir a compatibilidade com versões anteriores. (Errado) OpenID Connect é uma extensão do OAuth2 que permite a autenticação de usuários, mas não a autorização de acesso a recursos. (Errado) 7. Bibliografia e Documentação Oficial# RFC 6749 (The OAuth 2.0 Authorization Framework): https://tools.ietf.org/html/rfc6749 RFC 7519 (JSON Web Token): https://tools.ietf.org/html/rfc7519 OpenID Connect Core 1.0: https://openid.net/specs/openid-connect-core-1_0.html Fielding, R. T. (2000). Architectural Styles and the Design of Network-based Software Architectures. University of California, Irvine. "},{"id":51,"href":"/software/2-design-e-programacao/","title":"2. Design e Programação","section":"Engenharia de Software","content":"2. Design e Programação# 1. Especificações Técnicas e Arquitetura# Design e programação envolvem a aplicação de padrões de design como os do Gang of Four (GoF) e GRASP para resolver problemas de software de forma eficiente e reutilizável. Concorrência, paralelismo, e multithreading são técnicas usadas para melhorar a performance de programas permitindo que múltiplas operações ou processos ocorram simultaneamente. A programação assíncrona permite que uma operação ocorra independentemente de outras operações principais, melhorando a responsividade do software.\n2. Detalhamento Técnico Avançado (Deep Dive)# Padrões de Design (GoF \u0026amp; GRASP)# GoF: Define soluções reutilizáveis para problemas comuns em design de software. Inclui padrões como Singleton, Observer, Factory, e Strategy. GRASP: Fornece princípios básicos para atribuir responsabilidades em objetos, como baixo acoplamento, alta coesão, e fabricação de informação. Concorrência vs. Paralelismo# Concorrência: Capacidade de um sistema gerenciar múltiplas operações ao mesmo tempo. Não necessariamente executa tarefas ao mesmo tempo, mas pode alternar entre tarefas. Paralelismo: Execução simultânea de múltiplas operações. Requer hardware com múltiplos núcleos de processamento. Multithreading e Programação Assíncrona# Multithreading: Técnica para dividir uma tarefa em múltiplos threads que podem ser executados em paralelo, melhorando a performance do programa. Programação Assíncrona: Permite que tarefas sejam executadas em \u0026ldquo;background\u0026rdquo;, melhorando a responsividade do aplicativo sem bloquear o usuário ou a UI. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Exemplo de Multithreading em Java# public class MultithreadingDemo extends Thread { public void run() { try { // Código para executar em paralelo System.out.println(\u0026#34;Thread \u0026#34; + Thread.currentThread().getId() + \u0026#34; is running\u0026#34;); } catch (Exception e) { // Tratamento de exceção System.out.println(\u0026#34;Exception is caught\u0026#34;); } } } public class Main { public static void main(String[] args) { int n = 8; // Número de threads for (int i = 0; i \u0026lt; n; i++) { MultithreadingDemo object = new MultithreadingDemo(); object.start(); } } }Programação Assíncrona em JavaScript# async function fetchData() { try { let response = await fetch(\u0026#39;https://api.example.com/data\u0026#39;); let data = await response.json(); console.log(data); } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); } } fetchData();4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão dos conceitos de design e programação, especialmente a capacidade de identificar corretamente a aplicação dos padrões de design e as diferenças entre concorrência, paralelismo, e multithreading. Uma pegadinha comum é confundir concorrência com paralelismo, ou não entender a aplicabilidade dos padrões de design em cenários específicos.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova Singleton (GoF) Garante uma única instância Útil para conexões de banco de dados Observer (GoF) Define uma dependência 1:N Importante para eventos e notificações Baixo Acoplamento (GRASP) Reduz dependências entre classes Facilita manutenção e testabilidade Multithreading Executa múltiplas threads em paralelo Melhora a performance em sistemas multicore Programação Assíncrona Executa operações em background Melhora a responsividade sem bloquear a UI 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (C) A programação assíncrona em JavaScript pode ser realizada utilizando as palavras-chave async e await para operações que retornam uma Promise. (E) Em Java, o uso de multithreading não é possível em sistemas operacionais que não suportam paralelismo. (C) O padrão Singleton do GoF é utilizado para garantir que uma classe tenha apenas uma instância e forneça um ponto de acesso global a ela. (E) O padrão Observer é utilizado para garantir que um objeto permaneça em seu estado original, evitando alterações por outros objetos. (C) Concorrência e paralelismo são conceitos que, embora relacionados, referem-se a diferentes estratégias para executar múltiplas tarefas ou processos. 7. Bibliografia e Documentação Oficial# Gamma, E., Helm, R., Johnson, R., \u0026amp; Vlissides, J. (1995). Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley. Bloch, J. (2008). Effective Java (2nd ed.). Addison-Wesley. MDN Web Docs - async function Oracle Java Documentation - Concurrency "},{"id":52,"href":"/software/1-arquitetura-de-software/","title":"1. Arquitetura de Software","section":"Engenharia de Software","content":"1. Arquitetura de Software# 1. Especificações Técnicas e Arquitetura# Arquiteturas de software definem a estrutura fundamental sobre a qual os sistemas são construídos, destacando componentes, suas interconexões e como interagem para cumprir os requisitos do sistema. As arquiteturas mais comuns incluem Monolito, Microserviços e Serverless, cada uma com seus próprios componentes, regras e práticas recomendadas. A comunicação entre serviços é frequentemente realizada através de eventos/mensageria e integrações como API Gateway e Service Mesh, enquanto padrões como CQRS (Command Query Responsibility Segregation) são utilizados para separar a leitura da escrita de dados, otimizando o desempenho e a escalabilidade.\n2. Detalhamento Técnico Avançado (Deep Dive)# Monolito# Conceito: Aplicação como uma unidade única. Limitações: Difícil escalabilidade, acoplamento alto. Boas práticas: Modularização interna para facilitar manutenção. Microserviços# Conceito: Aplicação dividida em serviços menores, independentes. Regras: Comunicação via APIs leves, cada serviço com seu banco de dados. Boas práticas: Deploy independente, domínio bem definido para cada serviço. Serverless# Conceito: Execução de código em resposta a eventos, sem gerenciar servidores. Limitações: Cold start, tempo de execução limitado. Boas práticas: Manter funções leves, utilizar cache para otimizar performance. Eventos/Mensageria# Regras: Comunicação assíncrona, desacoplamento entre produtores e consumidores. Boas práticas: Garantir idempotência, utilizar dead-letter queues para mensagens não processadas. Integração# API Gateway: Ponto de entrada unificado para APIs, autenticação e rate limiting. Service Mesh: Gerenciamento de comunicação entre serviços, oferece resiliência e monitoramento. CQRS: Separação entre comandos (escrita) e queries (leitura), melhora performance e escalabilidade. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Deploy de microserviço com Kubernetes: kubectl apply -f service.yaml kubectl apply -f deployment.yaml Configuração de API Gateway com Terraform: resource \u0026#34;aws_api_gateway_rest_api\u0026#34; \u0026#34;MyDemoAPI\u0026#34; { name = \u0026#34;MyDemoAPI\u0026#34; description = \u0026#34;This is my API for demonstration purposes\u0026#34; }Protocolos e Regras# TLS Handshake: Processo de negociação de criptografia entre cliente e servidor. Normalização de Dados: 1FN elimina grupos repetitivos, 2FN elimina dependências funcionais parciais, 3FN elimina dependências transitivas. Contexto TCU# No TCU, a arquitetura de software é crucial para sistemas de auditoria e fiscalização. Microserviços e serverless são preferidos para escalabilidade e eficiência. A integração via API Gateway e Service Mesh facilita a comunicação segura entre sistemas internos e externos, enquanto CQRS é utilizado em sistemas de grande volume de dados para separar processos de leitura e escrita, otimizando a performance.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar o entendimento prático das arquiteturas, focando em como elas são aplicadas e gerenciadas no dia a dia. É comum haver questões que testam o conhecimento sobre as limitações e desafios de cada arquitetura, assim como as melhores práticas para superá-los. Pegadinhas frequentes incluem confundir características de microserviços com monolitos ou serverless, ou questões que exigem compreensão detalhada de padrões específicos como CQRS.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante kubectl apply -f Deploy de configurações no Kubernetes Usado para microserviços Terraform API Gateway Criação de API Gateway na AWS Ponto de entrada unificado CQRS Separação de leitura e escrita Melhora performance Service Mesh Gerenciamento de comunicação Oferece resiliência e monitoramento 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# Certo ou Errado? No contexto de microserviços, cada serviço deve ter seu próprio banco de dados para evitar acoplamento.\nResposta: Certo. Isso garante a independência e a escalabilidade dos serviços. Certo ou Errado? Serverless é uma arquitetura onde o desenvolvedor deve gerenciar e escalar os servidores conforme a demanda.\nResposta: Errado. Serverless abstrai a gestão de servidores, permitindo que o desenvolvedor foque no código. Certo ou Errado? O padrão CQRS é utilizado para integrar microserviços através de um API Gateway.\nResposta: Errado. CQRS é utilizado para separar operações de leitura e escrita, não para integração direta de microserviços. Certo ou Errado? Uma aplicação monolítica é mais fácil de escalar horizontalmente do que uma arquitetura baseada em microserviços.\nResposta: Errado. Microserviços são mais fáceis de escalar horizontalmente devido à sua independência. Certo ou Errado? Service Mesh é utilizado para facilitar a comunicação entre serviços em uma arquitetura de microserviços, oferecendo recursos como descoberta de serviços, balanceamento de carga e monitoramento.\nResposta: Certo. Service Mesh oferece esses e outros recursos para gerenciar a comunicação entre serviços. 7. Bibliografia e Documentação Oficial# Kubernetes Official Documentation: https://kubernetes.io/docs/ AWS API Gateway Documentation: https://docs.aws.amazon.com/apigateway/ Martin Fowler on Microservices: https://martinfowler.com/articles/microservices.html Serverless Architecture: https://aws.amazon.com/serverless/ CQRS: https://martinfowler.com/bliki/CQRS.html "},{"id":53,"href":"/dados/6-integracao-com-nuvem/","title":"6. Integração com nuvem","section":"Engenharia de Dados","content":"6. Integração com nuvem# 1. Especificações Técnicas e Arquitetura# Azure Data Factory, Service Fabric e Databricks são serviços da Azure que permitem a integração e processamento de dados em larga escala, suportando cenários de ETL, análise de dados e machine learning. O Azure Blob Storage, Amazon S3 e Google Cloud Storage (GCS) são soluções de armazenamento de objetos projetadas para armazenar grandes volumes de dados não estruturados.\nAzure Data Factory: Serviço de integração de dados que facilita a criação, programação e orquestração de fluxos de trabalho de ETL/ELT. Service Fabric: Plataforma de sistemas distribuídos que facilita o desenvolvimento, implantação e gerenciamento de microsserviços e contêineres escaláveis. Databricks: Plataforma de análise baseada em Apache Spark, otimizada para a nuvem Azure, que oferece integração com IA e machine learning. Storage (S3, Blob, GCS): Serviços de armazenamento de objetos que oferecem escalabilidade, disponibilidade de dados, segurança e integração com várias ferramentas de análise e IA. 2. Detalhamento Técnico Avançado (Deep Dive)# Azure Data Factory# Atividades e Pipelines: Compostos por atividades que definem ações de transformação ou movimentação de dados. Pipelines são usados para orquestrar atividades. Linked Services: Conexões a fontes de dados externas. Datasets: Definições de estruturas de dados de entrada ou saída. Service Fabric# Modelo de Programação: Suporta stateless e stateful services, permitindo o desenvolvimento de aplicações altamente disponíveis e escaláveis. Gerenciamento de Cluster: Oferece recursos para o gerenciamento de saúde e monitoramento de clusters. Databricks# Notebooks: Ambiente interativo para desenvolvimento de código com suporte a Python, Scala, SQL e R. Clusters: Gerenciamento de clusters Spark, automatizando a escalabilidade e otimização de recursos. Storage (S3, Blob, GCS)# Durabilidade e Disponibilidade: Projetados para oferecer 99.999999999% de durabilidade e 99.99% de disponibilidade. Segurança: Suporte a políticas de IAM, criptografia em repouso e em trânsito. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Azure Data Factory\n# Criar um pipeline no Azure Data Factory Set-AzDataFactoryV2Pipeline -ResourceGroupName \u0026#34;ResourceGroup\u0026#34; -DataFactoryName \u0026#34;DataFactoryName\u0026#34; -Name \u0026#34;PipelineName\u0026#34; -DefinitionFile \u0026#34;.\\pipeline.json\u0026#34; Service Fabric\n# Conectar ao cluster Service Fabric Connect-ServiceFabricCluster -ConnectionEndpoint \u0026#34;mycluster.azure.com:19000\u0026#34; Databricks\n# Criar um cluster Databricks databricks clusters create --json-file cluster.json Protocolos e Regras# Azure Blob Storage Utiliza o protocolo HTTP/HTTPS para operações de armazenamento. Suporta políticas de retenção e ciclo de vida de objetos. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A banca CEBRASPE pode cobrar detalhes específicos sobre a configuração e operação de serviços de nuvem, como parâmetros de criação de pipelines no Azure Data Factory ou opções de configuração de clusters no Databricks. Uma pegadinha comum é confundir as capacidades de armazenamento de Blob, S3 e GCS, especialmente em termos de consistência de dados e disponibilidade. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova Set-AzDataFactoryV2Pipeline Cria ou atualiza um pipeline no Azure Data Factory Verificar parâmetros como nome do recurso e definição do pipeline Connect-ServiceFabricCluster Conecta a um cluster Service Fabric Necessário especificar o endpoint de conexão do cluster databricks clusters create Cria um cluster no Databricks Importante definir o arquivo JSON com a configuração do cluster 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) O Azure Data Factory suporta a criação de pipelines de dados que podem ser executados em resposta a eventos, como a chegada de novos dados em um Blob Storage.\nResposta: Certo. O Azure Data Factory permite a criação de pipelines orientados a eventos. (Certo ou Errado) O Service Fabric é uma plataforma exclusiva para o gerenciamento de contêineres, não suportando aplicações stateful.\nResposta: Errado. O Service Fabric suporta tanto serviços stateless quanto stateful. (Certo ou Errado) Databricks não permite a integração com serviços de IA e machine learning devido à sua base no Apache Spark.\nResposta: Errado. Databricks oferece ampla integração com IA e machine learning, aproveitando as capacidades do Apache Spark. (Certo ou Errado) Amazon S3, Azure Blob Storage e Google Cloud Storage oferecem a mesma consistência imediata após a escrita de objetos.\nResposta: Errado. As garantias de consistência podem variar entre os serviços. (Certo ou Errado) A criptografia de dados em repouso é uma configuração padrão em todos os serviços de armazenamento de objetos mencionados.\nResposta: Certo. Amazon S3, Azure Blob Storage e Google Cloud Storage suportam criptografia de dados em repouso por padrão. 7. Bibliografia e Documentação Oficial# Azure Data Factory Documentation: https://docs.microsoft.com/en-us/azure/data-factory/ Service Fabric Documentation: https://docs.microsoft.com/en-us/azure/service-fabric/ Databricks Documentation: https://docs.databricks.com/ Amazon S3 Documentation: https://docs.aws.amazon.com/s3/ Azure Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ Google Cloud Storage Documentation: https://cloud.google.com/storage/docs "},{"id":54,"href":"/dados/5-governanca-e-qualidade-de-dados/","title":"5. Governança e Qualidade de Dados","section":"Engenharia de Dados","content":"5. Governança e Qualidade de Dados# 1. Especificações Técnicas e Arquitetura# Governança e qualidade de dados envolvem a gestão estratégica de dados, assegurando sua precisão, disponibilidade, responsabilidade e segurança. Componentes principais incluem:\nLinhagem de Dados: Rastreamento da origem, movimento, características e uso dos dados. Catalogação de Dados: Organização e classificação dos dados para facilitar a busca e o acesso. Validação de Dados: Processo de garantir que os dados atendam a critérios específicos de qualidade e formato. Deduplicação de Dados: Identificação e remoção de cópias exatas ou quase exatas de dados. Metadados: Dados sobre os dados, que descrevem características, conteúdo, qualidade, condição e outras características. Glossários de Dados: Dicionários que definem termos e conceitos de dados relevantes para a organização. Políticas de Acesso: Regras que definem quem pode acessar, modificar ou visualizar determinados conjuntos de dados. 2. Detalhamento Técnico Avançado (Deep Dive)# Linhagem de Dados: Utiliza metadados para rastrear a origem dos dados, transformações aplicadas e onde são utilizados, crucial para a auditoria e conformidade. Catalogação de Dados: Emprega sistemas de gerenciamento de metadados para facilitar a descoberta e o acesso aos dados. Validação de Dados: Inclui verificações de integridade, como a conformidade com expressões regulares, intervalos de valores e unicidade. Deduplicação de Dados: Utiliza algoritmos de correspondência e hashing para identificar duplicatas, melhorando a eficiência do armazenamento e processamento. Metadados: Classificam-se em descritivos, estruturais e administrativos, essenciais para a gestão eficaz dos dados. Glossários de Dados: Facilitam a comunicação e compreensão entre diferentes partes interessadas, promovendo a consistência. Políticas de Acesso: Baseiam-se em princípios de menor privilégio e necessidade de conhecer, essenciais para a segurança dos dados. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Exemplo de Comando/Script:\n-- Validação de Dados com SQL SELECT * FROM tabela WHERE NOT REGEXP_LIKE(campo, \u0026#39;^[0-9]{4}-[0-9]{2}-[0-9]{2}$\u0026#39;);Este comando SQL identifica registros que não atendem ao formato de data YYYY-MM-DD, um exemplo comum de validação de dados.\nContexto TCU:\nA linhagem de dados é crucial para auditorias do TCU, permitindo rastrear a origem e as transformações dos dados para verificar sua integridade e conformidade com as políticas de governança de dados.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar a compreensão de que a deduplicação de dados não se aplica apenas a registros completamente idênticos, mas também a registros que são considerados duplicatas com base em critérios específicos de negócio.\nDica de Prova: Esteja atento a questões que confundem metadados descritivos com estruturais, uma distinção importante na gestão de metadados.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica REGEXP_LIKE(campo, \u0026lsquo;regex\u0026rsquo;) Valida formato de dados com regex Útil para validação de dados em SQL Deduplicação de Dados Remove ou identifica dados duplicados Importante para eficiência de armazenamento Políticas de Acesso Define regras de acesso a dados Crucial para segurança e conformidade 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# A linhagem de dados é utilizada apenas para fins de auditoria interna. (Errado) Metadados estruturais descrevem o conteúdo do dado, como título ou autor. (Errado) A deduplicação de dados pode ser realizada com base em critérios específicos de negócio, além de identificadores únicos. (Certo) Glossários de dados são irrelevantes para a governança de dados, pois servem apenas como documentação auxiliar. (Errado) Políticas de acesso baseadas no princípio de menor privilégio são recomendadas para a gestão de segurança de dados. (Certo) 7. Bibliografia e Documentação Oficial# DAMA-DMBOK (Data Management Body of Knowledge) ISO/IEC 25012:2008 - Data Quality model NIST Special Publication 800-53 (Security and Privacy Controls for Federal Information Systems and Organizations) Este material é baseado em padrões reconhecidos internacionalmente e práticas recomendadas para a governança e qualidade de dados, relevantes para a preparação de concursos públicos, especialmente aqueles aplicados pela CEBRASPE.\n"},{"id":55,"href":"/dados/4-fluxo-de-manipulacao-de-dados/","title":"4. Fluxo de manipulação de dados","section":"Engenharia de Dados","content":"4. Fluxo de manipulação de dados# 1. Especificações Técnicas e Arquitetura# ETL (Extract, Transform, Load) é um processo fundamental na engenharia de dados, envolvendo a extração de dados de diversas fontes, sua transformação conforme necessário (limpeza, agregação, enriquecimento) e o carregamento em um destino final para análise e business intelligence. Pipelines de ETL são críticos para a gestão de dados, suportando versionamento, logging, auditoria, tolerância a falhas e integração contínua/entrega contínua (CI/CD).\nComponentes Principais: Fontes de Dados, Processo de ETL, Destino dos Dados (Data Warehouse/Data Lake). Interconexões: APIs, Conectores de Banco de Dados, Ferramentas de Orquestração (ex: Apache Airflow). Conceitos Fundamentais: Automação de fluxo de dados, garantia de integridade e qualidade dos dados, monitoramento e otimização de performance. 2. Detalhamento Técnico Avançado (Deep Dive)# Versionamento: Uso de sistemas de controle de versão (ex: Git) para manter histórico de alterações nos scripts de ETL e configurações de pipeline. Logging: Registro detalhado de eventos e erros para facilitar a depuração e auditoria. Deve-se logar início/fim de processos, erros, e alterações de dados significativas. Auditoria: Implementação de mecanismos para rastrear quem fez o quê e quando, essencial para conformidade e segurança. Tolerância a Falhas: Estratégias como retry mechanisms, failover processes e uso de checkpoints para garantir a continuidade dos processos em caso de falhas. CI/CD: Automatização da implantação de pipelines de ETL através de ferramentas como Jenkins, GitLab CI/CD, garantindo a entrega contínua de atualizações com mínima intervenção manual. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nGit para versionamento: git add pipeline_etl.py git commit -m \u0026#34;Atualização do processo de transformação\u0026#34; git push origin masterProtocolos e Regras:\nEstratégias de retry para tolerância a falhas: import requests from requests.adapters import HTTPAdapter from requests.packages.urllib3.util.retry import Retry retry_strategy = Retry( total=3, status_forcelist=[429, 500, 502, 503, 504], method_whitelist=[\u0026#34;HEAD\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;OPTIONS\u0026#34;] ) adapter = HTTPAdapter(max_retries=retry_strategy) http = requests.Session() http.mount(\u0026#34;https://\u0026#34;, adapter) http.mount(\u0026#34;http://\u0026#34;, adapter) response = http.get(\u0026#34;https://api.exemplo.com/data\u0026#34;)Contexto TCU:\nA aplicação prática de ETL e pipelines no TCU envolve a coleta de dados de diferentes órgãos para auditoria, análise de conformidade com leis e normativas, e a geração de insights para a melhoria da gestão pública. A implementação de logging e auditoria é essencial para garantir a rastreabilidade e a integridade dos dados manipulados.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das melhores práticas de engenharia de dados, como a importância do versionamento e da auditoria em pipelines de ETL. Uma pegadinha comum é confundir os conceitos de tolerância a falhas com os de performance e otimização, que, embora relacionados, têm focos diferentes.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova git add . e git commit Versionamento de código Importante para rastrear mudanças em pipelines ETL. Retry mechanisms em Python Tolerância a falhas Estratégia essencial para garantir a resiliência do processo ETL. Logging detalhado Auditoria e depuração Fundamental para conformidade e segurança dos dados. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (C) O uso de Git para versionamento de scripts de ETL permite rastrear e reverter mudanças, facilitando a gestão de versões e colaboração entre desenvolvedores. (E) Logging em pipelines de ETL deve ser limitado a erros críticos para economizar espaço de armazenamento. (C) Estratégias de retry e failover são essenciais para a construção de pipelines de ETL tolerantes a falhas. (E) A auditoria em pipelines de ETL é opcional e pode ser negligenciada em ambientes controlados. (C) A integração contínua (CI) e entrega contínua (CD) são práticas recomendadas para a implantação eficiente e segura de pipelines de ETL. Gabarito Comentado:\nCorreto. O versionamento é uma prática fundamental para a gestão eficaz de pipelines de ETL, permitindo controle e colaboração eficiente. Errado. Logging detalhado, incluindo início/fim de processos e alterações significativas, é crucial para a depuração e auditoria, não devendo ser limitado apenas a erros críticos. Correto. Tolerância a falhas é um aspecto crítico da engenharia de pipelines de ETL, garantindo que os processos possam se recuperar de falhas sem intervenção manual. Errado. A auditoria é fundamental para garantir a conformidade, segurança e rastreabilidade dos dados, sendo uma prática obrigatória em ambientes sérios de engenharia de dados. Correto. CI/CD são práticas que permitem a atualização e entrega de pipelines de ETL de maneira rápida, segura e automatizada, sendo altamente recomendadas. 7. Bibliografia e Documentação Oficial# Git documentation: https://git-scm.com/doc Python Requests: https://docs.python-requests.org/en/master/ Apache Airflow: https://airflow.apache.org/docs/ Jenkins: https://www.jenkins.io/doc/ Normativas do TCU sobre auditoria e gestão de dados: https://portal.tcu.gov.br/legislacao/normas-de-auditoria/ "},{"id":56,"href":"/dados/3-conectores-e-integracao/","title":"3. Conectores e integração","section":"Engenharia de Dados","content":"3. Conectores e integração# 1. Especificações Técnicas e Arquitetura# APIs REST/SOAP# REST (Representational State Transfer): Protocolo baseado em HTTP para comunicação web, utilizando métodos como GET, POST, PUT, DELETE para operações CRUD. Utiliza formatos como JSON ou XML para transferência de dados. SOAP (Simple Object Access Protocol): Protocolo baseado em XML para troca de mensagens entre sistemas, independente de linguagem ou plataforma, com suporte a funcionalidades como segurança, transações e mensagens com resposta. Web Services# Componentes: WSDL (Web Services Description Language) para descrição do serviço, UDDI (Universal Description, Discovery, and Integration) para listagem de serviços disponíveis, e SOAP para comunicação. Arquivos Planos# Formatos: CSV (valores separados por vírgula), JSON (JavaScript Object Notation), XML (eXtensible Markup Language), Parquet (formato colunar otimizado para armazenamento). Mensageria# Conceitos: Troca de mensagens de forma assíncrona entre sistemas, utilizando filas ou tópicos para gerenciar o fluxo de mensagens. Segurança# TLS (Transport Layer Security): Protocolo para criptografia e segurança na comunicação entre aplicativos. Autenticação: Métodos como OAuth2, JWT (JSON Web Tokens) para controle de acesso e identificação. 2. Detalhamento Técnico Avançado (Deep Dive)# REST vs SOAP# REST: Mais simples, usa HTTP/HTTPS, sem estado, ideal para web services públicos. SOAP: Mais estruturado, com suporte a transações, segurança avançada, ideal para empresas. Segurança em APIs# TLS: Utiliza handshake para estabelecer uma conexão segura, trocando chaves para criptografia. Autenticação: OAuth2 utiliza tokens de acesso para autenticar e autorizar usuários. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# # Exemplo de curl para API REST curl -X GET \u0026#34;https://api.exemplo.com/v1/recurso\u0026#34; -H \u0026#34;Authorization: Bearer TOKEN_AQUI\u0026#34; # Exemplo de comando para verificar a configuração TLS openssl s_client -connect exemplo.com:443Protocolos e Regras# Handshake TLS: Inicia com ClientHello, seguido por ServerHello, troca de certificados, chave secreta e finaliza com Finished. Processo OAuth2: Inicia com a solicitação de autorização, usuário autentica, servidor autoriza e emite token de acesso. Exemplos de Output/Logs# # Exemplo de resposta de API REST { \u0026#34;id\u0026#34;: 1, \u0026#34;nome\u0026#34;: \u0026#34;Exemplo\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;ativo\u0026#34; }4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar a diferença entre métodos HTTP utilizados em REST (GET para leitura, POST para criação, PUT/PATCH para atualização, DELETE para exclusão) e a estrutura de uma mensagem SOAP (Envelope, Header, Body). Pegadinhas comuns incluem confundir autenticação e autorização, ou não reconhecer a importância da criptografia TLS em APIs públicas. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica curl -X GET Realiza uma requisição HTTP GET Usado para testar endpoints de API openssl s_client -connect Testa a conexão TLS de um servidor Verifica a configuração de segurança 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# ( ) O protocolo SOAP não suporta a transferência de dados em formato JSON. ( ) Em uma arquitetura RESTful, é recomendado o uso de URLs significativas e a manipulação de recursos utilizando os métodos HTTP. ( ) O handshake TLS inicia com a troca de chaves públicas entre o cliente e o servidor. ( ) Arquivos no formato Parquet são otimizados para operações de leitura e escrita sequencial, não sendo adequados para consultas analíticas. ( ) OAuth2 é um protocolo que permite a um serviço terceiro acessar recursos do usuário sem expor suas credenciais de acesso. Gabarito# Certo. SOAP é baseado em XML e não foi projetado nativamente para suportar JSON. Certo. Este é um princípio fundamental do design RESTful. Errado. O handshake TLS começa com ClientHello, não com a troca de chaves públicas diretamente. Errado. Parquet é otimizado para consultas analíticas devido à sua eficiência em operações de leitura. Certo. OAuth2 permite acesso a recursos sem expor credenciais, utilizando tokens de acesso. 7. Bibliografia e Documentação Oficial# RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content RFC 5246 - The Transport Layer Security (TLS) Protocol Version 1.2 RFC 6749 - The OAuth 2.0 Authorization Framework JSON.org - Introdução ao JSON Apache Parquet - Documentação oficial Este material foi elaborado com base nas especificações e documentações oficiais, focando nas exigências técnicas e operacionais para a preparação para concursos do TCU, com ênfase nas questões frequentemente abordadas pela banca CEBRASPE.\n"},{"id":57,"href":"/dados/2-arquitetura-de-bi/","title":"2. Arquitetura de BI","section":"Engenharia de Dados","content":"2. Arquitetura de BI# 1. Especificações Técnicas e Arquitetura# DataWarehouse (DW)# Tecnologia/Norma: Repositório centralizado de dados integrados de diversas fontes. Componentes Principais: Banco de dados central, ETL (Extract, Transform, Load), ferramentas de consulta e análise. Conceitos Fundamentais: Armazenamento de dados históricos, suporte à tomada de decisão, estruturado em esquemas dimensionais (estrela, floco de neve). DataMart# Tecnologia/Norma: Subconjunto de um DataWarehouse focado em uma área específica. Componentes Principais: Banco de dados, ETL, ferramentas de consulta e análise específicas da área. Conceitos Fundamentais: Facilita o acesso a dados relevantes para um departamento específico, implementação mais rápida e barata que um DW completo. DataLake# Tecnologia/Norma: Repositório para armazenamento de grandes volumes de dados brutos em seu formato nativo. Componentes Principais: Plataforma de armazenamento (ex: Hadoop HDFS, Amazon S3), ferramentas de processamento e análise de dados (ex: Apache Spark). Conceitos Fundamentais: Suporta dados estruturados e não estruturados, escalável, análise de big data, machine learning. DataMesh# Tecnologia/Norma: Arquitetura descentralizada focada na democratização dos dados e na responsabilidade compartilhada. Componentes Principais: Domínios de dados auto-soberanos, plataforma de interoperabilidade, governança de dados. Conceitos Fundamentais: Promove a propriedade dos dados pelos domínios de negócio, facilita a descoberta e o acesso aos dados, enfatiza a governança federada. 2. Detalhamento Técnico Avançado (Deep Dive)# DataWarehouse# Conceitos Técnicos Aprofundados: Normalização até 3FN para eliminar redundâncias, seguida de denormalização para otimizar consultas. Regras Operacionais: Utilização de esquemas dimensionais para facilitar análises OLAP. Boas Práticas: Separação do ambiente de ETL do ambiente de consultas para otimizar o desempenho. DataMart# Conceitos Técnicos Aprofundados: Implementação pode seguir o modelo dependente (derivado de um DW existente) ou independente. Regras Operacionais: Foco em uma área específica de negócio para otimizar o desempenho e a relevância dos dados. Boas Práticas: Alinhamento com os requisitos de negócio para garantir a relevância dos dados. DataLake# Conceitos Técnicos Aprofundados: Armazenamento de dados em formato bruto, sem esquema definido até o momento da consulta (schema-on-read). Regras Operacionais: Governança de dados para garantir a qualidade e a segurança dos dados armazenados. Boas Práticas: Catalogação de dados para facilitar a descoberta e o acesso. DataMesh# Conceitos Técnicos Aprofundados: Descentralização da gestão de dados, com domínios de negócio atuando como produtores e consumidores de dados. Regras Operacionais: Interoperabilidade entre domínios para compartilhamento de dados. Boas Práticas: Governança federada para manter a qualidade e a segurança dos dados. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# DataWarehouse# -- Exemplo de query SQL para consulta em um modelo de esquema estrela SELECT f.measure, d.dimension_attribute FROM fact_table f JOIN dimension_table d ON f.dimension_key = d.dimension_key;DataLake# # Exemplo de comando para armazenar dados no Hadoop HDFS hadoop fs -put local_file.txt /path/in/hdfsProtocolos e Regras# DataMesh# Governança Federada: Estabelecimento de políticas de qualidade de dados, segurança e acesso entre domínios. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das diferenças fundamentais entre DataWarehouse, DataMart, DataLake e DataMesh, especialmente em questões que pedem a identificação da solução mais adequada para um cenário descrito. Uma pegadinha comum é confundir DataLake com DataWarehouse, especialmente no que tange à estruturação de dados e ao propósito de uso (análise histórica x big data e análise em tempo real). 5. Tabela de Referência Técnica (Quick Lookup)# Tecnologia O que faz/O que valida Observação Técnica importante DataWarehouse Armazenamento de dados históricos para análise Estruturado, esquemas dimensionais DataMart Foco em departamento específico para análise Pode ser dependente ou independente de um DW DataLake Armazenamento de grandes volumes de dados brutos Suporta dados estruturados e não estruturados DataMesh Arquitetura descentralizada para democratização dos dados Enfatiza governança federada e domínios de dados auto-soberanos 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) DataLakes são recomendados para armazenar dados estruturados em esquemas dimensionais para análise OLAP.\nErrado. DataLakes são recomendados para armazenar grandes volumes de dados brutos, incluindo dados não estruturados, e não são otimizados especificamente para esquemas dimensionais ou análise OLAP. (Certo ou Errado) DataMesh promove a centralização da governança de dados como meio para garantir a qualidade e segurança dos dados.\nErrado. DataMesh promove uma governança federada e descentralizada, com domínios de negócio atuando como produtores e consumidores de dados, responsáveis pela qualidade e segurança dos seus dados. (Certo ou Errado) DataMarts podem ser implementados de forma independente, sem necessidade de um DataWarehouse existente.\nCerto. DataMarts podem seguir um modelo independente, sendo projetados para atender às necessidades específicas de um departamento sem depender de um DataWarehouse. (Certo ou Errado) Em um DataLake, os dados são estruturados e organizados antes de serem armazenados.\nErrado. Em um DataLake, os dados são armazenados em seu formato bruto e a estruturação (schema-on-read) ocorre apenas no momento da consulta ou análise. (Certo ou Errado) A arquitetura de DataWarehouse não suporta o armazenamento de dados não estruturados.\nCerto. Tradicionalmente, DataWarehouses são projetados para armazenar e analisar dados estruturados, seguindo um esquema definido, e não são otimizados para dados não estruturados. 7. Bibliografia e Documentação Oficial# DataWarehouse: Kimball, R., \u0026amp; Ross, M. (2013). The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling. Wiley. DataLake: Dixon, J. (2010). \u0026ldquo;Data Lakes\u0026rdquo; [Blog post]. Retrieved from http://jamesdixon.wordpress.com/ DataMesh: Zhamak, D. (2019). \u0026ldquo;Data Mesh Principles and Logical Architecture\u0026rdquo; [Blog post]. Retrieved from https://martinfowler.com/articles/data-mesh-principles.html Documentação Oficial AWS: https://aws.amazon.com/pt/big-data/datalakes-and-analytics/what-is-a-data-lake/ Documentação Oficial Apache Hadoop: https://hadoop.apache.org/docs/stable/ "},{"id":58,"href":"/dados/1-bancos-de-dados/","title":"1. Bancos de Dados","section":"Engenharia de Dados","content":"1. Bancos de Dados# 1. Especificações Técnicas e Arquitetura# Bancos de dados relacionais, como Oracle e SQL Server, utilizam um modelo baseado em tabelas, onde os dados são armazenados em linhas e colunas, permitindo a execução de operações complexas de consulta e manipulação através da linguagem SQL. Eles seguem o princípio ACID (Atomicidade, Consistência, Isolamento, Durabilidade) para garantir a integridade dos dados.\nBancos de dados NoSQL, como Elasticsearch e MongoDB, são projetados para armazenar, distribuir e acessar dados de maneiras que não se encaixam perfeitamente no modelo relacional. Eles podem ser categorizados em quatro tipos principais: chave-valor, documentos, colunas largas e grafos. Esses bancos de dados são conhecidos por sua alta escalabilidade, performance e flexibilidade na modelagem de dados.\n2. Detalhamento Técnico Avançado (Deep Dive)# Normalização de Dados:# 1FN (Primeira Forma Normal): Garante que os valores em cada coluna de uma tabela sejam atômicos e que a tabela contenha uma chave única. 2FN (Segunda Forma Normal): Além de atender à 1FN, garante que todos os atributos não-chave sejam totalmente funcionais e dependentes da chave primária. 3FN (Terceira Forma Normal): Além de atender à 2FN, todos os seus campos devem ser dependentes apenas da chave primária, eliminando assim as dependências transitivas. Modelagem de Dados NoSQL:# Documentos (MongoDB): Armazenam dados em documentos JSON, facilitando a modelagem de dados semiestruturados. Pesquisa de Texto (Elasticsearch): Otimizado para pesquisas de texto completo, armazenando dados de forma que facilita a indexação e recuperação rápida. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:# SQL Server:\nSELECT * FROM Usuarios WHERE Nome LIKE \u0026#39;%Silva%\u0026#39;;MongoDB:\ndb.usuarios.find({nome: /Silva/});Elasticsearch:\nGET /usuarios/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;nome\u0026#34;: \u0026#34;Silva\u0026#34; } } }Protocolos e Regras:# Transações SQL: O comando BEGIN TRANSACTION inicia uma transação, seguido por uma série de operações SQL, e é finalizado com COMMIT para aplicar as alterações ou ROLLBACK para desfazê-las. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a sintaxe exata em comandos SQL e características específicas dos bancos de dados NoSQL, como a natureza schema-less do MongoDB ou a capacidade de busca full-text do Elasticsearch. Uma pegadinha comum é questionar sobre a aplicação de conceitos de normalização em bancos de dados NoSQL, onde a modelagem de dados é frequentemente denormalizada para otimizar o desempenho.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica SELECT * FROM Seleciona dados de uma tabela SQL padrão, mas evite * em produção db.collection.find() Busca documentos no MongoDB Use índices para melhorar a performance GET /_search Realiza uma busca no Elasticsearch Ajuste o mapeamento para otimizar buscas 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) Em um banco de dados relacional, a normalização até a 3FN é suficiente para eliminar todas as redundâncias de dados. (Certo ou Errado) O MongoDB permite a realização de transações ACID em múltiplas coleções desde a versão 4.0. (Certo ou Errado) No Elasticsearch, o mapeamento de campos não precisa ser definido previamente, pois ele pode inferir o tipo de dados automaticamente. (Certo ou Errado) Consultas que utilizam o comando LIKE no SQL Server são otimizadas automaticamente com o uso de índices. (Certo ou Errado) Em bancos de dados NoSQL, a denormalização é uma prática comum para otimizar a performance de leitura. Gabarito:\nErrado. A normalização até a 3FN reduz muitas redundâncias, mas não todas. A BCNF e outras formas normais podem ser necessárias em alguns casos. Certo. A partir da versão 4.0, o MongoDB introduziu suporte a transações multi-documentos, estendendo as propriedades ACID. Certo. O Elasticsearch pode inferir tipos de dados, mas a definição explícita de mapeamentos é uma prática recomendada para otimizar buscas. Errado. O uso de LIKE, especialmente com wildcards no início da string, pode evitar o uso de índices e degradar a performance. Certo. A denormalização é frequentemente utilizada em bancos de dados NoSQL para otimizar consultas, reduzindo a necessidade de joins. 7. Bibliografia e Documentação Oficial# SQL Server Documentation: https://docs.microsoft.com/en-us/sql/sql-server/ MongoDB Documentation: https://docs.mongodb.com/ Elasticsearch Reference: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Date, C. J. (2003). An Introduction to Database Systems (8th ed.). Addison-Wesley Longman. "},{"id":59,"href":"/infra/7-alta-disponibilidade-e-dr/","title":"7. Alta Disponibilidade e DR","section":"Infraestrutura de TI","content":"7. Alta Disponibilidade e DR# 1. Especificações Técnicas e Arquitetura# Alta Disponibilidade (HA) e Disaster Recovery (DR) são fundamentais para garantir a continuidade dos serviços de TI em caso de falhas ou desastres. HA se concentra em reduzir o tempo de inatividade, enquanto DR foca na recuperação após desastres.\nClusters: Conjuntos de servidores que trabalham juntos para proporcionar maior disponibilidade. Balanceamento de Carga: Distribuição de carga de trabalho entre múltiplos recursos computacionais. Failover: Processo automático de troca para um sistema secundário em caso de falha. Heartbeat: Sinalização periódica entre sistemas para verificar sua disponibilidade. Fencing: Isolamento de um recurso com falha para proteção do cluster. 2. Detalhamento Técnico Avançado (Deep Dive)# Clusters: Utilizam algoritmos de consenso como Raft ou Paxos para gerenciamento de estado e liderança. Balanceamento de Carga: Pode ser implementado em nível de aplicação (ex: HAProxy) ou rede (ex: DNS round-robin). Failover: Requer configuração de prioridades e políticas de saúde para determinar quando e como a troca ocorre. Heartbeat: Implementado via pacotes ICMP ou mensagens específicas de aplicação. Fencing: Pode usar mecanismos de STONITH (Shoot The Other Node In The Head) para garantir a integridade do cluster. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:\nHeartbeat Setup (Linux): apt-get install heartbeat vim /etc/heartbeat/ha.cf Configuração de Failover (Pacemaker): pcs cluster setup --name my_cluster node1 node2 pcs cluster start --all Protocolos e Regras:\nHeartbeat: Utiliza UDP na porta 694 para comunicação entre nós. Fencing: Configuração via pcs requer definição de agentes de fencing compatíveis com o hardware. Exemplos de Output/Logs:\nCluster Status (Pacemaker): pcs status 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A banca pode cobrar a diferença entre balanceamento de carga e alta disponibilidade, que embora relacionados, têm propósitos distintos. Heartbeat e fencing são frequentemente confundidos; o primeiro verifica a disponibilidade, enquanto o segundo isola recursos com falha. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova apt-get install heartbeat Instala o pacote heartbeat no Linux. Importante para configuração de HA. pcs cluster setup Configura um cluster Pacemaker. Essencial para failover e fencing. UDP porta 694 Porta padrão para comunicação heartbeat. Detalhe técnico relevante para configurações de firewall. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# ( ) O balanceamento de carga é uma estratégia que, por si só, garante a alta disponibilidade de um sistema. ( ) O protocolo heartbeat pode ser implementado utilizando tanto UDP quanto TCP, dependendo da configuração do ambiente. ( ) Fencing é um mecanismo utilizado para prevenir a corrupção de dados em um cluster, isolando nós que não respondem corretamente. ( ) Em um ambiente de alta disponibilidade, o failover deve ser manualmente iniciado pelo administrador do sistema. ( ) Clusters que utilizam o algoritmo Paxos necessariamente precisam de um número ímpar de nós para evitar divisão de cérebro (split-brain). Gabarito:\nErrado. O balanceamento de carga distribui o tráfego, mas não garante disponibilidade sem mecanismos de failover. Certo. Embora o UDP seja comum para heartbeat devido à sua simplicidade e baixa sobrecarga, o TCP pode ser utilizado em ambientes que requerem confirmações de entrega. Certo. Fencing é crucial para manter a integridade dos dados, evitando que nós \u0026ldquo;doentes\u0026rdquo; afetem o cluster. Errado. O failover em sistemas de alta disponibilidade é tipicamente automático, sem necessidade de intervenção manual. Certo. O uso de um número ímpar de nós no algoritmo Paxos ajuda a evitar condições de split-brain, garantindo que sempre haja uma maioria clara para decisões de consenso. 7. Bibliografia e Documentação Oficial# Heartbeat: Linux-HA Pacemaker: ClusterLabs Algoritmos de Consenso: \u0026ldquo;Paxos Made Simple\u0026rdquo; - Lamport, L. (2001) Documentação AWS sobre DR: AWS Disaster Recovery "},{"id":60,"href":"/infra/6-monitoramento-gestao-e-automacao/","title":"6. Monitoramento, Gestão e Automação","section":"Infraestrutura de TI","content":"6. Monitoramento, Gestão e Automação# 1. Especificações Técnicas e Arquitetura# Zabbix# Tecnologia/Norma: Ferramenta de monitoramento de rede de código aberto. Componentes Principais: Servidor Zabbix, Agentes Zabbix, Banco de Dados, Web Frontend. Conceitos Fundamentais: Monitoramento distribuído, coleta de métricas, alertas e visualização de dados. New Relic# Tecnologia/Norma: Plataforma de observabilidade baseada em SaaS. Componentes Principais: APM, Infraestrutura, Mobile, Browser, Insights (Analytics). Conceitos Fundamentais: Observabilidade em tempo real, análise de desempenho, monitoramento de aplicações. Grafana# Tecnologia/Norma: Ferramenta de análise e visualização de dados de código aberto. Componentes Principais: Dashboards, Painéis, Datasources. Conceitos Fundamentais: Visualização de dados, métricas e logs, suporte a múltiplas fontes de dados. ITIL v4 (CMDB)# Tecnologia/Norma: Framework de gerenciamento de serviços de TI. Componentes Principais: Práticas de gerenciamento, CMDB (Configuration Management Database). Conceitos Fundamentais: Gestão de ativos e configurações, centralização de informações de infraestrutura. 2. Detalhamento Técnico Avançado (Deep Dive)# Zabbix: Utiliza agentes para monitorar recursos e aplicações remotamente, suporta SNMP e IPMI para dispositivos sem agentes. New Relic: APM utiliza agentes para coletar dados de desempenho de aplicações, suporta linguagens como Java, .NET, PHP, Node.js. Grafana: Integra-se a diversas fontes de dados como Prometheus, Elasticsearch, MySQL, permitindo a criação de dashboards personalizados. ITIL v4 (CMDB): Centraliza informações sobre itens de configuração (CIs), suas relações e dependências, essencial para a gestão de mudanças e incidentes. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Zabbix # Instalação do agente Zabbix no Linux sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install zabbix-agent PowerShell (Automação) # Reiniciar um serviço no Windows Restart-Service -Name \u0026#34;nome_do_serviço\u0026#34; Bash (Automação) # Backup de diretório usando tar tar -czvf backup.tar.gz /diretório/alvoProtocolos e Regras# Grafana: Utiliza o protocolo HTTP/HTTPS para a comunicação entre o servidor Grafana e as fontes de dados. Exemplos de Output/Logs# Zabbix Log Example 2023-01-01 12:00:00.000 [Zabbix server] [ERROR] Cannot connect to the database.Contexto TCU# A utilização de ferramentas como Zabbix, New Relic e Grafana permite ao TCU monitorar a capacidade, disponibilidade e desempenho de seus sistemas, em conformidade com as práticas recomendadas pela ITIL v4, incluindo a gestão eficaz de configurações através do CMDB. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode cobrar a compreensão de como as ferramentas de monitoramento se integram ao gerenciamento de serviços de TI, especialmente no contexto do ITIL v4. Uma pegadinha comum é confundir as capacidades de monitoramento de desempenho (New Relic) com as de visualização de dados (Grafana). 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica sudo apt-get install zabbix-agent Instala o agente Zabbix no Linux Necessário para monitoramento remoto. Restart-Service -Name \u0026quot;nome_do_serviço\u0026quot; Reinicia um serviço no Windows via PowerShell Útil para scripts de automação. tar -czvf backup.tar.gz /diretório/alvo Cria um backup do diretório especificado Importante para procedimentos de backup. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) O Grafana suporta a integração com o Zabbix como fonte de dados para visualização de métricas e logs. (Certo ou Errado) A instalação de um agente New Relic é opcional para monitorar o desempenho de aplicações web. (Certo ou Errado) ITIL v4 desaconselha o uso de CMDB para pequenas organizações devido à sua complexidade e custo de manutenção. (Certo ou Errado) Scripts em Bash e PowerShell podem ser utilizados para automatizar tarefas de monitoramento e gestão de infraestrutura de TI. (Certo ou Errado) O New Relic não pode monitorar aplicações escritas em linguagem Go devido à falta de suporte da plataforma. Gabarito Comentado# Certo. Grafana pode se integrar com Zabbix para visualizar dados de monitoramento, uma prática comum em ambientes de TI. Errado. A instalação de um agente é necessária para que o New Relic colete dados detalhados de desempenho de aplicações web. Errado. ITIL v4 não desaconselha o uso de CMDB em pequenas organizações; a implementação deve ser adaptada ao tamanho e necessidades da organização. Certo. Scripts em Bash e PowerShell são amplamente utilizados para automatizar tarefas de monitoramento e gestão, aumentando a eficiência operacional. Errado. New Relic suporta monitoramento de aplicações em Go, oferecendo insights sobre o desempenho da aplicação. 7. Bibliografia e Documentação Oficial# Zabbix Official Documentation New Relic Documentation Grafana Documentation ITIL v4 Foundation PowerShell Documentation Bash Reference Manual "},{"id":61,"href":"/infra/5-seguranca-de-infraestrutura/","title":"5. Segurança de Infraestrutura","section":"Infraestrutura de TI","content":"5. Segurança de Infraestrutura# 1. Especificações Técnicas e Arquitetura# Hardening: Refere-se ao processo de tornar um sistema mais seguro através da redução de sua superfície de ataque, desabilitando serviços desnecessários, configurando adequadamente os restantes, e aplicando patches e atualizações de segurança. Firewalls (NGFW - Next-Generation Firewall): Dispositivos de segurança de rede que vão além das capacidades dos firewalls tradicionais, incorporando funcionalidades como inspeção profunda de pacotes (DPI), prevenção contra invasões (IPS), e filtragem de aplicativos. IDS/IPS (Sistema de Detecção/Prevenção de Intrusão): Soluções de segurança que monitoram o tráfego de rede para detectar e/ou prevenir atividades maliciosas. Proxies: Servidores que atuam como intermediários para requisições de recursos por parte de um cliente, buscando recursos de outro servidor. NAC (Network Access Control): Tecnologia que permite apenas dispositivos autorizados e em conformidade com a política de segurança a acessarem a rede. VPNs (Virtual Private Networks): Tecnologias que criam um canal seguro sobre uma rede insegura, como a Internet, utilizando protocolos como SSL/TLS. SSL/TLS (Secure Sockets Layer / Transport Layer Security): Protocolos de segurança que fornecem comunicações seguras por uma rede de computadores. PKI (Public Key Infrastructure): Conjunto de políticas, hardware, software e procedimentos necessários para criar, gerenciar, distribuir, usar, armazenar e revogar certificados digitais. Segmentação de Rede: Prática de dividir uma rede em sub-redes menores para melhorar o desempenho e a segurança. 2. Detalhamento Técnico Avançado (Deep Dive)# Hardening: Inclui a desativação de protocolos inseguros (como SSLv3, TLS 1.0), remoção de contas de usuário desnecessárias, e a aplicação de princípios de menor privilégio. NGFW: Utiliza a identificação de aplicativos para permitir ou bloquear tráfego, independentemente da porta ou protocolo. IDS/IPS: O IPS é colocado in-line para bloquear tráfego malicioso identificado, enquanto o IDS opera em modo de detecção, gerando alertas. Proxies: Podem ser transparentes ou não-transparentes, afetando como os clientes configuram suas conexões. NAC: Pode integrar-se com soluções de gerenciamento de identidade para fornecer controle de acesso baseado em função. VPNs: O uso de SSL/TLS para VPNs é comumente referido como SSL VPN. SSL/TLS: A negociação de uma sessão SSL/TLS envolve um handshake que estabelece parâmetros criptográficos. PKI: Envolve o uso de uma Autoridade Certificadora (CA) para emitir certificados digitais. Segmentação de Rede: Pode ser realizada através de VLANs, ACLs, ou firewalls para controlar o tráfego entre sub-redes. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts:# Hardening de SSH em Linux: # Desativar login como root echo \u0026#34;PermitRootLogin no\u0026#34; \u0026gt;\u0026gt; /etc/ssh/sshd_config # Desativar autenticação baseada em senha echo \u0026#34;PasswordAuthentication no\u0026#34; \u0026gt;\u0026gt; /etc/ssh/sshd_config systemctl restart sshd Protocolos e Regras:# Handshake TLS: Cliente envia um \u0026ldquo;ClientHello\u0026rdquo; com versões de TLS suportadas, métodos de criptografia, etc. Servidor responde com um \u0026ldquo;ServerHello\u0026rdquo;, escolhendo a criptografia. Troca de chaves e estabelecimento de sessão segura. Exemplos de Output/Logs:# Logs de IDS: ALERT: \u0026#34;ET SCAN Suspicious inbound to MSSQL port 1433\u0026#34; Contexto TCU:# A aplicação de hardening é fundamental para a segurança de infraestrutura em órgãos governamentais, seguindo diretrizes do TCU para minimizar vulnerabilidades. NGFWs são recomendados para proteger a rede contra ameaças avançadas, com o TCU enfatizando a importância da inspeção profunda de pacotes. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE pode apresentar afirmações que misturam conceitos de IDS e IPS, testando a compreensão do candidato sobre a diferença entre detecção e prevenção. Questões sobre SSL/TLS podem tentar confundir com versões obsoletas e inseguras, como SSLv3. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica PermitRootLogin no Desativa login SSH como root Hardening essencial para segurança Handshake TLS Estabelece sessão segura Importante para VPNs e comunicações seguras ET SCAN Suspicious inbound Alerta de IDS para tráfego suspeito Identificação de possíveis ataques 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (C) A desativação de protocolos inseguros, como SSLv3 e TLS 1.0, é uma prática recomendada no processo de hardening. (E) Um IDS é colocado in-line no fluxo de tráfego para bloquear ativamente tráfego malicioso identificado. (C) NGFWs diferem dos firewalls tradicionais por incorporarem funcionalidades como inspeção profunda de pacotes e prevenção contra invasões. (E) VPNs que utilizam SSL/TLS são comumente referidas como IPSec VPNs. (C) A segmentação de rede pode ser efetivamente realizada através do uso de VLANs, ACLs, ou firewalls. 7. Bibliografia e Documentação Oficial# RFC 5246 - The Transport Layer Security (TLS) Protocol Version 1.2 Documentação oficial do OpenSSL para configuração de TLS: https://www.openssl.org/ Manual de boas práticas de segurança para hardening de sistemas operacionais: https://www.cisecurity.org/ Documentação oficial NGFW da Cisco: https://www.cisco.com/ Normativos e manuais do TCU sobre auditoria e governança de TI: https://portal.tcu.gov.br/ "},{"id":62,"href":"/infra/4-armazenamento-e-backup/","title":"4. Armazenamento e Backup","section":"Infraestrutura de TI","content":"4. Armazenamento e Backup# 1. Especificações Técnicas e Arquitetura# Armazenamento e backup são componentes críticos da infraestrutura de TI, garantindo a disponibilidade, integridade e recuperação de dados. As principais tecnologias envolvidas incluem SAN (Storage Area Network), NAS (Network Attached Storage), DAS (Direct Attached Storage), além de técnicas de RAID (Redundant Array of Independent Disks) e estratégias de backup e recuperação como RPO (Recovery Point Objective), RTO (Recovery Time Objective), snapshots e deduplicação. Oracle RMAN (Recovery Manager) é uma ferramenta específica para backup e recuperação de bancos de dados Oracle.\n2. Detalhamento Técnico Avançado (Deep Dive)# SAN, NAS, DAS# SAN opera em nível de bloco, ideal para ambientes que exigem alto desempenho, como bancos de dados e aplicações críticas. Utiliza iSCSI para transporte sobre IP. NAS opera em nível de arquivo, facilitando o compartilhamento de arquivos em redes, com protocolos como NFS (Linux/Unix) e SMB (Windows). DAS é a conexão direta entre o armazenamento e o servidor, não sendo acessível por outros servidores ou dispositivos na rede. RAID# RAID é um conjunto de técnicas para distribuir dados entre múltiplos discos, visando redundância e/ou desempenho. RAID 0, 1, 5, 6 e 10 são os níveis mais comuns, cada um com suas especificidades de desempenho e tolerância a falhas. Backup/Recuperação# RPO e RTO são métricas críticas na definição de estratégias de backup, indicando, respectivamente, a quantidade máxima de perda de dados aceitável e o tempo máximo para recuperação após um desastre. Snapshots oferecem uma \u0026ldquo;fotografia\u0026rdquo; do estado de um sistema em um determinado momento, úteis para recuperações rápidas. Deduplicação é a técnica de reduzir o espaço necessário para armazenamento de backups, eliminando cópias redundantes de dados. Oracle RMAN# RMAN é a ferramenta de backup e recuperação para bancos de dados Oracle, permitindo backups consistentes, recuperação de desastres e otimização do espaço de armazenamento. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# iSCSI: # Conectar a um alvo iSCSI iscsiadm -m discovery -t sendtargets -p [IP_DO_ALVO] iscsiadm -m node --login NFS: # Montar um compartilhamento NFS mount [IP_DO_SERVIDOR]:/[CAMINHO] /mnt/nfs SMB: # Montar um compartilhamento SMB mount -t cifs -o username=[USUÁRIO],password=[SENHA] //[IP_DO_SERVIDOR]/[RECURSO] /mnt/smb Oracle RMAN: # Backup do banco de dados RMAN\u0026gt; BACKUP DATABASE PLUS ARCHIVELOG; Protocolos e Regras# iSCSI utiliza TCP/IP para transporte, permitindo o uso de infraestrutura de rede existente. NFS e SMB são protocolos de nível de aplicação para sistemas de arquivos distribuídos. RAID níveis e suas regras específicas determinam a configuração de discos para redundância e desempenho. RMAN opera dentro do contexto do banco de dados Oracle, integrando-se com sua arquitetura para otimizar backups. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das diferenças fundamentais entre SAN, NAS e DAS, bem como os protocolos específicos (iSCSI, NFS, SMB) e suas aplicações práticas. RAID: A banca pode apresentar cenários para testar o entendimento sobre a escolha do nível de RAID adequado, baseando-se em requisitos de desempenho e tolerância a falhas. Oracle RMAN: Questões podem focar em comandos específicos e cenários de recuperação, exigindo conhecimento detalhado da sintaxe e opções de configuração. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova iscsiadm Conecta a alvos iSCSI Importante para SAN mount -t nfs Monta compartilhamento NFS Uso comum em NAS mount -t cifs Monta compartilhamento SMB Uso comum em NAS Windows RMAN\u0026gt; BACKUP DATABASE Realiza backup do banco Oracle Fundamental para backup com RMAN 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# Certo ou Errado? O protocolo iSCSI permite que dispositivos de armazenamento sejam conectados a um servidor através da rede local, utilizando a infraestrutura Ethernet existente. Certo ou Errado? RAID 5 requer no mínimo três discos e oferece tanto redundância quanto aumento de desempenho, mas a falha de mais de um disco simultaneamente resulta em perda de dados. Certo ou Errado? NFS e SMB podem ser utilizados indistintamente em ambientes Linux e Windows para compartilhamento de arquivos. Certo ou Errado? RMAN só pode ser utilizado para backup de bancos de dados Oracle, não sendo compatível com outros SGBDs. Certo ou Errado? A deduplicação de dados é uma técnica que pode ser aplicada tanto em backups completos quanto incrementais para reduzir o espaço de armazenamento necessário. Gabarito:\nCerto. Certo. Errado. NFS é mais comum em ambientes Linux/Unix, enquanto SMB é predominante em Windows, apesar de ambos poderem ser utilizados em diferentes sistemas operacionais. Certo. Certo. 7. Bibliografia e Documentação Oficial# RFC 3720 - Internet Small Computer Systems Interface (iSCSI) NFS: Network File System Version 4 Protocol. RFC 7530. SMB: Microsoft SMB Protocol Documentation Oracle RMAN: Oracle Backup and Recovery User\u0026rsquo;s Guide "},{"id":63,"href":"/infra/3-sistemas-operacionais-e-servidores/","title":"3. Sistemas Operacionais e Servidores","section":"Infraestrutura de TI","content":"3. Sistemas Operacionais e Servidores# 1. Especificações Técnicas e Arquitetura# Linux e Windows Server são sistemas operacionais amplamente utilizados em ambientes corporativos e governamentais, oferecendo robustez, segurança e flexibilidade para a gestão de infraestruturas de TI. A virtualização, por meio de tecnologias como KVM e VMware vSphere/ESXi, permite a execução de múltiplos sistemas operacionais em um único hardware físico, otimizando recursos e facilitando a gestão. O Active Directory (AD) e o Lightweight Directory Access Protocol (LDAP) são serviços essenciais para a gestão de usuários e permissões, enquanto as Group Policy Objects (GPOs) permitem a administração centralizada de políticas de segurança e configurações de sistemas Windows.\n2. Detalhamento Técnico Avançado (Deep Dive)# Linux# Sudoers File: Configuração de permissões de sudo para controle granular do acesso de usuários a comandos de administração. SSH Key Management: Uso de chaves SSH para autenticação segura e sem senha entre servidores Linux. Windows Server# Advanced Group Policy Management (AGPM): Permite controle avançado e versionamento de GPOs. PowerShell DSC (Desired State Configuration): Automatiza a configuração de software e a gestão de configurações de sistemas Windows. Virtualização# KVM: Usa extensões de virtualização de hardware (Intel VT ou AMD-V) para oferecer virtualização completa. VMware vSphere/ESXi: Solução de virtualização líder de mercado que oferece gestão centralizada e recursos avançados de alta disponibilidade (HA) e balanceamento de carga (DRS). AD, LDAP# AD: Serviço de diretório da Microsoft que usa LDAP como protocolo base para acessar e gerenciar informações distribuídas. LDAP: Protocolo padrão para serviços de diretório, permitindo a consulta e modificação de diretórios distribuídos de forma segura. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Linux\n# Adicionar usuário ao sudoers echo \u0026#34;usuario ALL=(ALL) NOPASSWD:ALL\u0026#34; | sudo tee /etc/sudoers.d/usuario # Configurar chave SSH ssh-keygen -t rsa -b 4096 -C \u0026#34;comentario\u0026#34; ssh-copy-id usuario@servidor Windows Server (PowerShell)\n# Criar GPO com AGPM Import-Module GroupPolicy New-GPO -Name \u0026#34;NomeGPO\u0026#34; -Comment \u0026#34;GPO criada via PowerShell\u0026#34; # Configurar DSC Configuration ExampleDSC { Node \u0026#34;localhost\u0026#34; { WindowsFeature WebServer { Ensure = \u0026#34;Present\u0026#34; Name = \u0026#34;Web-Server\u0026#34; } } } ExampleDSC Start-DscConfiguration -Path .\\ExampleDSC -Wait -Verbose Protocolos e Regras# TLS Handshake: Processo pelo qual dois dispositivos estabelecem comunicação segura usando TLS, envolvendo a troca de certificados e chaves de criptografia. Normalização de Dados: Processo de organização de dados em um banco de dados de acordo com regras de normalização (1FN, 2FN, 3FN) para reduzir a redundância e melhorar a integridade. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar o entendimento prático e teórico das tecnologias, com ênfase em comandos específicos e suas sintaxes exatas. É comum encontrar questões que testam o conhecimento sobre nuances de implementação e configuração, como detalhes específicos de comandos PowerShell para gestão de GPOs ou a correta sintaxe para adicionar um usuário ao arquivo sudoers no Linux. Uma pegadinha comum é apresentar comandos com pequenos erros de sintaxe ou configurações que não seguem as melhores práticas, esperando que o candidato identifique o erro.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova sudo usermod -aG sudo usuario Adiciona um usuário ao grupo sudo no Linux Lembre-se de que o grupo pode variar entre distribuições. New-GPO -Name \u0026quot;NomeGPO\u0026quot; Cria uma nova GPO no Windows Server via PowerShell Importante para gestão centralizada de políticas. ssh-keygen -t rsa Gera uma nova chave SSH Segurança de conexão entre servidores Linux. Configuration ExampleDSC Define uma configuração desejada no Windows Server Uso de DSC para automação de configurações. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (C) No Linux, o comando sudo usermod -aG sudo usuario é utilizado para adicionar um usuário ao grupo sudo, permitindo-lhe executar comandos como superusuário.\n(E) O VMware vSphere é uma solução de virtualização que não permite a migração ao vivo de máquinas virtuais entre hosts físicos sem interrupção do serviço.\n(C) No Windows Server, o PowerShell DSC (Desired State Configuration) pode ser utilizado para garantir que as configurações de software em servidores sejam mantidas conforme um modelo definido.\n(E) LDAP é um protocolo que permite apenas a leitura de informações em um diretório ativo, sem suportar operações de escrita ou modificação.\n(C) A utilização de GPOs (Group Policy Objects) no Active Directory permite a administração centralizada de políticas de segurança e configurações de sistemas operacionais Windows em um ambiente corporativo.\n7. Bibliografia e Documentação Oficial# Linux\nManuais e documentação oficial disponíveis em: https://www.kernel.org/doc/html/latest/ Windows Server\nDocumentação oficial da Microsoft disponível em: https://docs.microsoft.com/en-us/windows-server/ VMware vSphere/ESXi\nDocumentação oficial disponível em: https://docs.vmware.com/ LDAP\nRFC 4510: https://tools.ietf.org/html/rfc4510 PowerShell DSC\nDocumentação oficial disponível em: https://docs.microsoft.com/en-us/powershell/scripting/dsc/overview/overview Este material foi elaborado com base nas especificações técnicas e melhores práticas atuais, focando nas áreas de conhecimento e habilidades exigidas pela banca CEBRASPE em concursos públicos, especialmente para o TCU.\n"},{"id":64,"href":"/infra/2-redes-e-comunicacao-de-dados/","title":"2. Redes e Comunicação de Dados","section":"Infraestrutura de TI","content":"2. Redes e Comunicação de Dados# 1. Especificações Técnicas e Arquitetura# TCP (Transmission Control Protocol)# Resumo: Protocolo de controle de transmissão que oferece um serviço de entrega de dados ponto a ponto, confiável e orientado à conexão. Componentes Principais: Segmento TCP, Número de Sequência, Número de Confirmação, Flags (SYN, ACK, FIN), Janela de Congestionamento. Conceitos Fundamentais: Garante a entrega de dados na ordem correta através do estabelecimento de uma conexão (handshake de três vias) e controle de fluxo. UDP (User Datagram Protocol)# Resumo: Protocolo de datagrama de usuário que oferece um serviço de entrega de dados sem conexão e com esforço mínimo. Componentes Principais: Datagrama UDP, Portas de Origem e Destino. Conceitos Fundamentais: Não garante a entrega, a ordem ou a integridade dos dados, sendo mais rápido e eficiente para aplicações que toleram perda de dados. 2. Detalhamento Técnico Avançado (Deep Dive)# TLS (Transport Layer Security) e SSL (Secure Sockets Layer)# Conceitos Técnicos Aprofundados: Protocolos de segurança projetados para fornecer comunicações seguras sobre uma rede de computadores. TLS é o sucessor do SSL. Regras Operacionais: Utilizam criptografia assimétrica para a troca de chaves, seguida de criptografia simétrica para a comunicação. Boas Práticas: Sempre utilizar a versão mais recente (TLS 1.3) para garantir as melhores práticas de segurança. OSPF (Open Shortest Path First)# Conceitos Técnicos Aprofundados: Protocolo de roteamento baseado em estado de link que usa o algoritmo de Dijkstra para calcular o caminho mais curto. Regras Operacionais: Divisão de uma rede em áreas OSPF para otimizar o tráfego e a escalabilidade. Boas Práticas: Configurar áreas de stub e NSSA (Not So Stubby Area) para reduzir o número de rotas propagadas. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# Configuração OSPF em um roteador Cisco:\nrouter ospf 1 network 192.168.1.0 0.0.0.255 area 0Verificação de sessão TLS com OpenSSL:\nopenssl s_client -connect www.exemplo.com:443Protocolos e Regras# Handshake TLS:\nClientHello: O cliente envia uma lista de versões de TLS suportadas, métodos de criptografia e outros parâmetros. ServerHello: O servidor escolhe a configuração e envia de volta ao cliente. Certificate: O servidor envia seu certificado para autenticação. Key Exchange: Troca de chaves para estabelecer uma chave simétrica. Finished: Mensagens para verificar o início da sessão segura. Exemplos de Output/Logs# Log de conexão OSPF:\n%OSPF-5-ADJCHG: Process 1, Nbr 192.168.1.2 on GigabitEthernet0/1 from LOADING to FULL, Loading Done4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE frequentemente testa o conhecimento sobre a diferença entre TLS e SSL, enfatizando a importância de conhecer as versões e suas vulnerabilidades. Uma pegadinha comum é afirmar que o UDP garante a entrega de dados, o que é incorreto. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica router ospf 1 Inicia a configuração do OSPF Usado em roteadores Cisco openssl s_client -connect Inicia uma sessão TLS Verifica a configuração TLS 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo/Errado) O protocolo TLS utiliza criptografia assimétrica durante toda a sessão de comunicação para garantir a segurança dos dados. (Certo/Errado) Em uma configuração OSPF, todos os roteadores dentro da mesma área devem ter o mesmo valor de custo para garantir o balanceamento de carga. (Certo/Errado) O protocolo ICMP é utilizado primariamente para reportar erros na entrega de pacotes IP. (Certo/Errado) VLANs podem ser configuradas para segmentar redes lógicas sem a necessidade de hardware adicional. (Certo/Errado) O protocolo SFTP utiliza o mesmo canal de comando e dados do FTP para transferência de arquivos. Gabarito:\nErrado. O TLS utiliza criptografia assimétrica apenas para a troca de chaves no início da sessão. Após isso, a comunicação é criptografada usando criptografia simétrica. Errado. O valor de custo em OSPF é utilizado para determinar o melhor caminho; não é necessário que todos os roteadores na mesma área tenham o mesmo valor de custo. Certo. O ICMP é utilizado para enviar mensagens de erro e operacionais sobre a rede. Certo. VLANs permitem a segmentação de redes lógicas independentemente da localização física dos dispositivos, sem necessidade de hardware adicional. Errado. O SFTP (SSH File Transfer Protocol) utiliza o SSH para transferir arquivos, garantindo uma conexão segura, diferentemente do FTP que separa os canais de comando e dados. 7. Bibliografia e Documentação Oficial# RFC 791 - Internet Protocol RFC 793 - Transmission Control Protocol RFC 768 - User Datagram Protocol RFC 5246 - The Transport Layer Security (TLS) Protocol Version 1.2 RFC 8446 - The Transport Layer Security (TLS) Protocol Version 1.3 Cisco OSPF Design Guide - https://www.cisco.com/c/en/us/support/docs/ip/open-shortest-path-first-ospf/7039-1.html OpenSSL Documentation - https://www.openssl.org/docs/ "},{"id":65,"href":"/infra/1-arquitetura-infraestrutura-de-ti/","title":"1. Arquitetura Infraestrutura de TI","section":"Infraestrutura de TI","content":"1. Arquitetura Infraestrutura de TI# 1. Especificações Técnicas e Arquitetura# Arquitetura de infraestrutura de TI abrange o design, a organização e a implementação dos componentes de hardware e software que constituem o ambiente de tecnologia de uma organização. Inclui considerações sobre topologias físicas e lógicas, data centers (on-premises, cloud, híbrida), infraestrutura hiperconvergente, e arquiteturas escaláveis, tolerantes a falhas e redundantes.\n2. Detalhamento Técnico Avançado (Deep Dive)# Topologias Físicas e Lógicas# Topologia Física: Refere-se à disposição física real dos dispositivos na rede. Topologia Lógica: Descreve como os dados são efetivamente transmitidos entre esses dispositivos, independentemente de sua disposição física. Data Center (on-premises, cloud, híbrida)# On-premises: Localizado fisicamente na propriedade da organização. Cloud: Hospedado em servidores de um provedor de serviços, acessível via internet. Híbrida: Combinação de on-premises e cloud, permitindo flexibilidade e escalabilidade. Infraestrutura Hiperconvergente# Combina computação, armazenamento e redes em uma única solução para reduzir a complexidade e melhorar a eficiência. Arquitetura Escalável, Tolerante a Falhas e Redundante# Escalável: Capacidade de aumentar recursos sem prejudicar o desempenho. Tolerante a Falhas: Capaz de continuar operando mesmo na ocorrência de falhas parciais. Redundante: Existência de componentes duplicados que garantem a continuidade das operações em caso de falha. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Comandos/Scripts# # Exemplo de comando para verificar a conectividade de rede (Topologia Lógica) ping 192.168.1.1Protocolos e Regras# Handshake TLS: Processo pelo qual duas partes iniciam uma sessão de comunicação segura. Exemplos de Output/Logs# PING 192.168.1.1 (192.168.1.1): 56 data bytes 64 bytes from 192.168.1.1: icmp_seq=0 ttl=64 time=1.123 msContexto TCU# A fiscalização de infraestruturas de TI pelo TCU envolve a verificação da conformidade com padrões de segurança, eficiência e escalabilidade, especialmente em ambientes de cloud híbrida e infraestruturas hiperconvergentes.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão profunda das diferenças entre topologias físicas e lógicas, bem como a aplicação prática de conceitos de infraestrutura hiperconvergente e arquiteturas escaláveis. Uma pegadinha comum é confundir a capacidade de escalabilidade com a tolerância a falhas, sendo que são conceitos complementares, mas distintos.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica ping \u0026lt;IP\u0026gt; Verifica a conectividade com o host Útil para testar a topologia lógica Handshake TLS Inicia uma comunicação segura Essencial para segurança de dados 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo/Errado) A infraestrutura hiperconvergente não suporta a escalabilidade horizontal. (Certo/Errado) Em uma arquitetura híbrida, os dados não podem ser movidos entre o ambiente on-premises e a cloud. (Certo/Errado) Uma topologia lógica em anel implica necessariamente em uma disposição física em anel dos dispositivos. (Certo/Errado) A redundância é uma estratégia eficaz apenas para sistemas on-premises, não sendo aplicável em ambientes de cloud. (Certo/Errado) A tolerância a falhas em um data center pode ser garantida exclusivamente por meio de software, sem a necessidade de hardware redundante. Gabarito Comentado# Errado. A infraestrutura hiperconvergente pode ser projetada para suportar tanto a escalabilidade vertical quanto a horizontal, dependendo da configuração e das necessidades do negócio. Errado. Uma das principais vantagens da arquitetura híbrida é a flexibilidade para mover dados e aplicações entre ambientes on-premises e cloud, conforme necessário. Errado. A topologia lógica refere-se ao modo como os dados são transmitidos entre os dispositivos, independentemente de sua disposição física. Errado. A redundância é uma estratégia que pode ser aplicada tanto em ambientes on-premises quanto em cloud, sendo fundamental para a continuidade dos negócios em qualquer cenário. Errado. Embora o software desempenhe um papel crucial na tolerância a falhas, o hardware redundante é frequentemente necessário para garantir a alta disponibilidade e a continuididade operacional. 7. Bibliografia e Documentação Oficial# RFCs relevantes para TLS e protocolos de rede. Documentação AWS sobre arquiteturas escaláveis e hiperconvergentes. Manuais do TCU sobre fiscalização de TI e NBASP (Normas Brasileiras de Auditoria do Setor Público). "},{"id":66,"href":"/auditoria/6-execucao-da-auditoria/","title":"6. Execução da auditoria","section":"Auditoria Governamental","content":"6. Execução da auditoria# 1. Especificações Técnicas e Arquitetura# A execução da auditoria governamental envolve a aplicação de uma série de técnicas e procedimentos com o objetivo de avaliar a gestão pública, identificar possíveis desvios e propor melhorias. Os componentes principais dessa fase incluem a elaboração de programas de auditoria, a geração e manutenção de papéis de trabalho, a execução de testes e a aplicação de técnicas específicas de auditoria.\nProgramas de Auditoria: Guias detalhados que orientam os auditores sobre o que será auditado, como e em que sequência. Papéis de Trabalho: Documentação que registra as evidências coletadas, os procedimentos aplicados e as conclusões alcançadas. Testes de Auditoria: Procedimentos específicos realizados para obter evidências sobre as informações auditadas. Técnicas de Auditoria: Métodos aplicados para coletar e analisar evidências (ex: inspeção, observação, confirmação). 2. Detalhamento Técnico Avançado (Deep Dive)# Papéis de Trabalho: Devem ser suficientemente detalhados para permitir a um auditor independente entender a natureza, o timing e a extensão dos procedimentos de auditoria aplicados, bem como as conclusões alcançadas. Testes de Auditoria: Podem ser de natureza substantiva (para obter evidências sobre a validade das informações) ou de controle (para testar a eficácia dos controles internos). Técnicas de Auditoria: A escolha da técnica depende do objetivo da auditoria, da natureza da informação auditada e dos riscos identificados. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Contexto TCU: Na prática da fiscalização, o TCU aplica esses conceitos seguindo as diretrizes do seu Manual de Auditoria Governamental (MAG) e das normas internacionais de auditoria (ISSAI), adaptando-os às especificidades do setor público brasileiro. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão sobre a aplicabilidade e a importância dos papéis de trabalho, bem como a capacidade de distinguir entre os diferentes tipos de testes e técnicas de auditoria. Uma pegadinha comum é apresentar afirmações que confundem os propósitos dos testes substantivos e de controle. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica Programas de Auditoria Orientam a execução da auditoria Essenciais para a sistematização do trabalho Papéis de Trabalho Documentam o processo de auditoria Devem permitir a reconstituição da auditoria Testes Substantivos Obtem evidências sobre a validade das informações Foco na veracidade dos dados Testes de Controle Testam a eficácia dos controles internos Foco na prevenção e detecção de erros 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) Os papéis de trabalho devem ser elaborados de forma a permitir apenas ao auditor que os elaborou compreender os procedimentos realizados e as conclusões alcançadas.\nErrado. Os papéis de trabalho devem ser elaborados de forma a permitir que um auditor independente compreenda os procedimentos realizados e as conclusões alcançadas. (Certo ou Errado) Testes de controle são aplicados para obter evidências sobre a eficácia dos controles internos da entidade auditada.\nCerto. Os testes de controle visam avaliar a eficácia dos controles internos. (Certo ou Errado) A escolha das técnicas de auditoria é irrelevante, desde que as evidências necessárias sejam coletadas.\nErrado. A escolha das técnicas de auditoria é fundamental e deve considerar o objetivo da auditoria, a natureza da informação auditada e os riscos identificados. (Certo ou Errado) Os programas de auditoria são documentos flexíveis que podem ser alterados a qualquer momento, sem necessidade de justificativa.\nErrado. Embora possam ser ajustados, as mudanças nos programas de auditoria devem ser devidamente justificadas. (Certo ou Errado) Testes substantivos são realizados para testar a eficácia dos controles internos da entidade auditada.\nErrado. Testes substantivos são realizados para obter evidências sobre a validade das informações, não sobre a eficácia dos controles internos. 7. Bibliografia e Documentação Oficial# Manual de Auditoria Governamental do TCU. Normas Internacionais de Entidades Fiscalizadoras Superiores (ISSAI). Este material foi elaborado com base nas diretrizes e práticas recomendadas pelo Tribunal de Contas da União (TCU) e pelas normas internacionais de auditoria governamental, visando preparar os candidatos para questões específicas da banca CEBRASPE em concursos públicos.\n"},{"id":67,"href":"/auditoria/5-planejamento-de-auditoria/","title":"5. Planejamento de auditoria","section":"Auditoria Governamental","content":"5. Planejamento de auditoria# 1. Especificações Técnicas e Arquitetura# O planejamento de auditoria governamental envolve a definição do escopo, a determinação da materialidade, a avaliação do risco, a consideração da relevância e a aplicação de técnicas de amostragem. Esses elementos são cruciais para a eficácia e eficiência da auditoria, orientando a alocação de recursos e a profundidade das análises.\nEscopo: Define o alcance e os limites da auditoria, incluindo o período a ser auditado e as áreas de interesse. Materialidade: Refere-se à importância relativa de um item ou erro que pode influenciar as decisões dos usuários das informações auditadas. Risco: Avaliação da possibilidade de ocorrência de um evento que possa impactar o alcance dos objetivos da auditoria. Relevância: Determina a importância de uma informação ou evento para a tomada de decisão no contexto da auditoria. Amostragem: Técnica utilizada para selecionar uma parte do universo auditado, de modo a permitir uma avaliação sobre o todo sem a necessidade de examinar cada item individualmente. 2. Detalhamento Técnico Avançado (Deep Dive)# Materialidade: O conceito de materialidade é aplicado para determinar o nível de detalhe e profundidade da auditoria. É importante que o auditor defina critérios de materialidade que sejam quantitativos e qualitativos, considerando as particularidades do objeto auditado.\nRisco de Auditoria: Compreende o risco inerente, o risco de controle e o risco de detecção. A avaliação desses riscos é fundamental para o planejamento da auditoria, pois influencia diretamente na definição de procedimentos de auditoria a serem aplicados.\nAmostragem em Auditoria: A seleção de amostras deve ser feita de maneira que seja representativa do universo auditado. Existem métodos de amostragem estatística e não estatística, cada um com suas regras e aplicações específicas.\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Contexto TCU: Na prática da fiscalização ou administração pública, o TCU aplica esses conceitos para assegurar que as auditorias sejam realizadas de forma eficiente e eficaz. Por exemplo, ao definir o escopo de uma auditoria, o TCU considera os aspectos de maior relevância e risco para a gestão pública, focando em áreas onde a probabilidade de encontrar irregularidades é maior ou onde o impacto dessas irregularidades seria mais significativo.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar o entendimento dos candidatos sobre como esses conceitos são aplicados na prática da auditoria governamental, especialmente em relação ao planejamento. É comum encontrar questões que testam o conhecimento sobre a aplicação de técnicas de amostragem, a definição de materialidade e a avaliação de riscos. Uma pegadinha comum é apresentar afirmações que confundem conceitos de risco inerente e risco de controle, ou que sugerem procedimentos de amostragem não alinhados com os princípios de representatividade e objetividade.\n5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova Definição de Escopo Define limites e foco da auditoria Fundamental para a eficiência da auditoria Critérios de Materialidade Estabelece o que é significativo na auditoria Varia conforme o contexto e objetivos da auditoria Avaliação de Risco Identifica potenciais obstáculos Inclui risco inerente, de controle e de detecção Técnicas de Amostragem Seleciona partes do universo auditado Deve ser representativa e adequada ao objetivo da auditoria Consideração de Relevância Determina importância de informações Ajuda a focar nos pontos que realmente importam na auditoria 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# A definição de materialidade em uma auditoria governamental é exclusivamente quantitativa. (Errado) O risco de detecção aumenta à medida que a eficácia dos procedimentos de auditoria aplicados diminui. (Certo) Na amostragem não estatística, a seleção das amostras baseia-se exclusivamente no julgamento do auditor, sem necessidade de critérios objetivos. (Errado) A relevância de uma informação é determinada exclusivamente pelo seu valor monetário. (Errado) O escopo da auditoria deve ser flexível e permitir alterações significativas em qualquer fase da auditoria. (Errado) 7. Bibliografia e Documentação Oficial# Normas Brasileiras de Contabilidade Aplicadas ao Setor Público (NBC TSP) Manual do TCU sobre Auditoria Governamental Instrução Normativa TCU nº 78/2018, que dispõe sobre a organização e a apresentação das demonstrações contábeis da União. Esses documentos fornecem uma base sólida para o entendimento e aplicação dos conceitos de planejamento de auditoria no contexto do TCU e são essenciais para a preparação para concursos públicos na área de auditoria governamental.\n"},{"id":68,"href":"/auditoria/4-normas-de-auditoria/","title":"4. Normas de auditoria","section":"Auditoria Governamental","content":"4. Normas de Auditoria# 1. Especificações Técnicas e Arquitetura# As Normas de Auditoria Governamental (NAGs) do TCU, as Normas da INTOSAI (Organização Internacional de Entidades Fiscalizadoras Superiores) e o NBASP (Normas Brasileiras de Auditoria do Setor Público) constituem o conjunto de diretrizes e procedimentos que orientam a execução das auditorias governamentais. Essas normas visam garantir a qualidade, a eficiência e a eficácia dos trabalhos de auditoria, promovendo a accountability, a transparência e a melhoria da gestão pública.\nNormas de Auditoria do TCU: Focam em diretrizes específicas para a realização de auditorias pelo Tribunal de Contas da União, abrangendo aspectos como planejamento, execução e relatório de auditoria. Normas da INTOSAI: São diretrizes internacionais que visam promover uma linguagem e práticas de auditoria comuns entre as entidades fiscalizadoras superiores ao redor do mundo. NBASP: Constituem o conjunto de normas voltadas para a auditoria do setor público brasileiro, harmonizadas com as práticas internacionais. 2. Detalhamento Técnico Avançado (Deep Dive)# Normas de Auditoria do TCU# Planejamento de Auditoria: Inclui a identificação de riscos, definição de objetivos, escopo e metodologia. Execução de Auditoria: Envolve a coleta de evidências, análise de dados e avaliação dos controles internos. Relatório de Auditoria: Deve apresentar os resultados, conclusões e recomendações de forma clara e objetiva. Normas da INTOSAI# ISSAI 3000: Define os princípios fundamentais de auditorias de desempenho. ISSAI 4000: Estabelece as diretrizes para auditorias de conformidade. NBASP# NBC TASP 100: Estabelece os princípios gerais de auditoria aplicáveis ao setor público. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Contexto TCU:\nNa prática, a aplicação das normas de auditoria no TCU envolve a utilização de ferramentas de análise de dados, como ACL ou IDEA, para a realização de testes de auditoria. A elaboração de relatórios de auditoria deve seguir os padrões definidos nas normas, garantindo que as evidências coletadas e as conclusões sejam apresentadas de maneira clara e fundamentada. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão das diferenças entre as normas de auditoria, especialmente em relação ao seu campo de aplicação (TCU, INTOSAI, NBASP). Uma pegadinha comum é afirmar que as normas de auditoria do TCU e as NBASP são completamente distintas, quando na verdade elas são complementares e muitas vezes harmonizadas com as normas internacionais da INTOSAI. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica importante para a prova ISSAI 3000 Princípios de auditorias de desempenho Importante para entender o escopo e objetivos das auditorias de desempenho. NBC TASP 100 Princípios gerais de auditoria do setor público Destaca a importância da ética e da independência na auditoria pública. Normas de Auditoria do TCU Diretrizes específicas para auditorias pelo TCU Foco na aplicabilidade direta nas auditorias do Tribunal. 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) As Normas da INTOSAI são aplicáveis apenas às auditorias de conformidade e não se aplicam a auditorias de desempenho. (Certo ou Errado) O NBASP é um conjunto de normas que não possui qualquer alinhamento ou harmonização com as diretrizes internacionais estabelecidas pela INTOSAI. (Certo ou Errado) Uma das etapas fundamentais da execução de uma auditoria, conforme as normas do TCU, é a avaliação dos controles internos da entidade auditada. (Certo ou Errado) Segundo as normas de auditoria do TCU, o relatório de auditoria não precisa necessariamente apresentar recomendações, desde que os resultados sejam claramente expostos. (Certo ou Errado) As normas de auditoria governamental do TCU, INTOSAI e NBASP são mutuamente exclusivas e não se complementam. Gabarito Comentado:\nErrado. As Normas da INTOSAI cobrem uma ampla gama de auditorias, incluindo auditorias de desempenho. Errado. O NBASP é harmonizado com as diretrizes internacionais da INTOSAI, visando a uniformidade e a qualidade das auditorias no setor público. Certo. A avaliação dos controles internos é uma etapa crucial para identificar riscos e avaliar a eficácia da gestão. Errado. O relatório de auditoria deve incluir, além dos resultados e conclusões, recomendações para a melhoria da gestão e correção de falhas identificadas. Errado. As normas do TCU, INTOSAI e NBASP são complementares e visam garantir a eficácia e a qualidade das auditorias governamentais. 7. Bibliografia e Documentação Oficial# INTOSAI: Normas da INTOSAI TCU: Normas de Auditoria do TCU NBASP: Normas Brasileiras de Auditoria do Setor Público "},{"id":69,"href":"/auditoria/3-tipos-de-auditoria/","title":"3. Tipos de auditoria","section":"Auditoria Governamental","content":"3. Tipos de auditoria# 1. Especificações Técnicas e Arquitetura# Auditoria de Conformidade# Objetivo: Verificar a aderência às leis, regulamentos, contratos e normas internas. Componentes Principais: Normas legais, procedimentos internos, documentação de auditoria. Conceitos Fundamentais: A auditoria de conformidade busca assegurar que a organização está seguindo as diretrizes estabelecidas por órgãos reguladores e normas internacionais, além de cumprir com os contratos e legislações aplicáveis. Auditoria Operacional# Objetivo: Avaliar a eficiência, eficácia e economia das operações. Componentes Principais: Processos operacionais, recursos (humanos, materiais, financeiros), resultados. Conceitos Fundamentais: Centra-se na avaliação dos processos internos, visando otimizar o uso de recursos e melhorar a gestão e desempenho organizacional. Auditoria Financeira# Objetivo: Examinar a fidedignidade das informações financeiras. Componentes Principais: Demonstrações financeiras, registros contábeis, documentos de suporte. Conceitos Fundamentais: Foca na verificação da precisão dos registros financeiros e na apresentação adequada das posições financeiras da entidade. 2. Detalhamento Técnico Avançado (Deep Dive)# Auditoria de Conformidade: Envolve a revisão detalhada de documentos, contratos, e registros para assegurar a aderência às normas aplicáveis. Atenção especial deve ser dada à legislação recente e às mudanças em normas internacionais.\nAuditoria Operacional: Requer uma análise profunda dos processos de negócio, incluindo mapeamento de processos, identificação de gargalos operacionais e avaliação de indicadores de desempenho (KPIs). Boas práticas incluem a aplicação de metodologias de melhoria contínua como Lean e Six Sigma.\nAuditoria Financeira: Demanda um conhecimento técnico avançado em princípios de contabilidade, análise de demonstrações financeiras, e técnicas de amostragem. É crucial a compreensão das normas de contabilidade aplicáveis (CPCs no Brasil, IFRS internacionalmente).\n3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Contexto TCU: Na prática da fiscalização, o TCU aplica estes tipos de auditoria para assegurar a boa gestão dos recursos públicos, a conformidade com a legislação e a eficiência das operações governamentais. Exemplos incluem auditorias em contratos de grande vulto, avaliações de programas de governo e inspeções em entidades administrativas. 4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a compreensão clara dos objetivos e características de cada tipo de auditoria. Uma pegadinha comum é apresentar uma afirmação que mistura conceitos de diferentes tipos de auditoria, exigindo do candidato a capacidade de discernir entre eles. 5. Tabela de Referência Técnica (Quick Lookup)# Tipo de Auditoria O que faz/O que valida Observação Técnica importante para a prova Conformidade Verifica aderência às normas e leis Foco em legislação e regulamentos aplicáveis Operacional Avalia eficiência e eficácia dos processos Importância de KPIs e metodologias de melhoria contínua Financeira Examina precisão das informações financeiras Conhecimento em CPCs e IFRS é essencial 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# (Certo ou Errado) A auditoria operacional foca exclusivamente na avaliação da legalidade dos atos de gestão.\nResposta: Errado. A auditoria operacional visa avaliar a eficiência, eficácia e economia das operações, não se limitando apenas à legalidade. (Certo ou Errado) Em uma auditoria financeira, o auditor deve verificar se as demonstrações financeiras estão em conformidade com os princípios contábeis geralmente aceitos.\nResposta: Certo. A auditoria financeira tem como um de seus principais objetivos assegurar que as demonstrações financeiras refletem adequadamente a posição financeira da entidade, de acordo com os princípios contábeis. (Certo ou Errado) A auditoria de conformidade é realizada para identificar oportunidades de melhoria nos processos operacionais da entidade.\nResposta: Errado. O objetivo principal da auditoria de conformidade é verificar a aderência às leis, regulamentos, contratos e normas internas, e não especificamente identificar melhorias operacionais. (Certo ou Errado) Na auditoria operacional, o uso de indicadores de desempenho (KPIs) é irrelevante para a avaliação dos processos.\nResposta: Errado. Os indicadores de desempenho (KPIs) são fundamentais na auditoria operacional para medir a eficiência, eficácia e economia dos processos auditados. (Certo ou Errado) A auditoria financeira pode incluir testes de controles internos para avaliar a eficácia dos mesmos na prevenção e detecção de erros e fraudes.\nResposta: Certo. Embora o foco principal da auditoria financeira seja a precisão das informações financeiras, a avaliação dos controles internos é uma parte importante do processo para garantir a confiabilidade dessas informações. 7. Bibliografia e Documentação Oficial# Normas Brasileiras de Contabilidade Aplicadas ao Setor Público (NBC TSP) International Financial Reporting Standards (IFRS) Lei nº 14.133/2021 Instrução Normativa TCU nº 01/2019 Manual do TCU sobre Auditoria Governamental Este material é um guia avançado para a preparação em auditorias governamentais, com foco nos tipos de auditoria e na forma como são aplicados e cobrados em concursos públicos, especialmente pelo TCU e pela banca CEBRASPE.\n"},{"id":70,"href":"/auditoria/1-conceito-finalidade-objetivo-abrangencia-e-atuac/","title":"1. Conceito, finalidade, objetivo, abrangência e atuação","section":"Auditoria Governamental","content":"Auditoria Governamental: Auditoria Interna e Externa# 1. Especificações Técnicas e Arquitetura# A auditoria governamental é uma atividade de avaliação independente e objetiva, destinada a adicionar valor e melhorar as operações de uma organização. Ela ajuda a organização a alcançar seus objetivos por meio de uma abordagem sistemática e disciplinada para avaliar e melhorar a eficácia dos processos de gestão de riscos, controle e governança.\nAuditoria Interna: Realizada por profissionais vinculados à própria entidade, tem como foco principal a avaliação da eficácia dos controles internos, processos e sistemas, visando à melhoria contínua. Auditoria Externa: Realizada por entidades independentes, como o Tribunal de Contas da União (TCU) no Brasil, foca na conformidade com leis, regulamentos e na fidedignidade das informações financeiras. 2. Detalhamento Técnico Avançado (Deep Dive)# Auditoria Interna# Objetivos: Avaliar a adequação e eficácia dos controles internos, contribuir para a melhoria dos processos operacionais e apoiar a administração na gestão de riscos. Limitações: Pode haver limitações de acesso a informações sensíveis ou restritas, além de potenciais conflitos de interesse, visto que os auditores internos são empregados da entidade. Auditoria Externa# Objetivos: Verificar a conformidade das demonstrações financeiras com os princípios contábeis, leis e regulamentos aplicáveis, e avaliar a eficácia do sistema de controle interno quanto à elaboração e apresentação das demonstrações financeiras. Limitações: A auditoria externa está sujeita à disponibilidade e à qualidade das informações fornecidas pela entidade auditada e pode ser influenciada pela complexidade das operações da entidade. 3. Implementação e Operação (O \u0026ldquo;Mão na Massa\u0026rdquo;)# Contexto TCU# No âmbito do TCU, a auditoria interna e externa são regidas por diferentes normativos e diretrizes, como a Lei nº 8.443/1992 e a IN TCU nº 84/2020, que estabelecem os procedimentos de auditoria governamental a serem seguidos. A auditoria interna nas entidades da administração pública federal deve alinhar-se aos objetivos estratégicos e seguir as diretrizes do Sistema de Controle Interno do Poder Executivo Federal, conforme o Decreto nº 3.591/2000.\n4. Análise CEBRASPE (Foco em Pegadinhas e Nuances)# A CEBRASPE costuma cobrar a distinção entre auditoria interna e externa, enfatizando suas finalidades, objetivos e abrangências. É comum encontrar questões que testam o conhecimento do candidato sobre as normativas específicas que regem as atividades de auditoria no contexto governamental brasileiro, como as leis e instruções normativas mencionadas.\nPegadinhas Comuns:# Confundir os objetivos da auditoria interna com os da auditoria externa. Ignorar as limitações inerentes a cada tipo de auditoria. Não conhecer as normativas específicas que regem a auditoria no contexto do TCU. 5. Tabela de Referência Técnica (Quick Lookup)# Comandos/Regras O que faz/O que valida Observação Técnica Lei nº 8.443/1992 Estabelece normas para a organização e funcionamento do TCU Base legal para auditoria externa IN TCU nº 84/2020 Define procedimentos de auditoria governamental Normativo específico para auditorias realizadas pelo TCU Decreto nº 3.591/2000 Regulamenta o sistema de controle interno do Poder Executivo Federal Diretrizes para auditoria interna nas entidades federais 6. Simulado Técnico (Estilo CEBRASPE – Certo ou Errado)# A auditoria interna tem como um de seus objetivos a avaliação da conformidade das demonstrações financeiras com os princípios contábeis aplicáveis. (Errado) O TCU, como órgão de controle externo, realiza auditorias para verificar a legalidade e legitimidade dos atos de gestão dos responsáveis sujeitos à sua jurisdição. (Certo) A IN TCU nº 84/2020 é um normativo que estabelece os procedimentos de auditoria interna no âmbito do Poder Executivo Federal. (Errado) O Decreto nº 3.591/2000 aplica-se exclusivamente à auditoria externa realizada pelo TCU. (Errado) A Lei nº 8.443/1992 é a base legal que estabelece normas para a organização e funcionamento do Tribunal de Contas da União, incluindo a realização de auditorias externas. (Certo) 7. Bibliografia e Documentação Oficial# Lei nº 8.443/1992 - Lei Orgânica do TCU IN TCU nº 84/2020 - Instrução Normativa TCU Decreto nº 3.591/2000 - Decreto sobre o Sistema de Controle Interno do Poder Executivo Federal Este material foi elaborado com foco na precisão técnica e na especificidade das demandas da banca CEBRASPE, visando preparar os candidatos para questões de auditoria governamental no concurso do TCU.\n"}]